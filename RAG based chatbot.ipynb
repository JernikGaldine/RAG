{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whSsjXfmaqGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678a2594-8168-4dc0-aa3a-11c479b25158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m174.1/232.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.10.2-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20221105 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.19.0-py3-none-manylinux_2_17_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (3.2.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n",
            "Installing collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20221105 pdfplumber-0.10.2 pypdfium2-4.19.0\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n",
            "  Downloading transformers-4.33.0-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=be806db11d540e487b3356c4419728a0b4f8d8f0dba4db76a23d4edb2d9488e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, huggingface-hub, transformers, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.33.0\n"
          ]
        }
      ],
      "source": [
        "# Download the necessary packages\n",
        "# PyPDF2: A library to extract text from PDF files.\n",
        "# pdfplumber: A library to extract text and other information from PDF files.\n",
        "# sentence-transformers: A library for generating sentence embeddings using transformer models.\n",
        "!pip install PyPDF2\n",
        "!pip install pdfplumber\n",
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPnsXjsOPmQz",
        "outputId": "a85e4a15-ca68-42cf-fe15-f6f96a22d7d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Collecting bytesbufio\n",
            "  Downloading bytesbufio-1.0.3-py3-none-any.whl (3.8 kB)\n",
            "Installing collected packages: bytesbufio\n",
            "Successfully installed bytesbufio-1.0.3\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "# Download the necessary packages\n",
        "# Import the nltk library, which provides natural language processing tools.\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "# Import the io module to work with input/output operations.\n",
        "import io\n",
        "\n",
        "# Download the necessary data for sentence tokenization.\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Install the 'requests' library, which allows sending HTTP requests.\n",
        "!pip install requests\n",
        "\n",
        "# Install the 'bytesbufio' library, which provides a buffered reader for bytes.\n",
        "!pip install bytesbufio\n",
        "\n",
        "# Install the 'nltk' library (again), which seems to be redundant as it was already imported above.\n",
        "!pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the 'drive' module from the 'google.colab' library to mount Google Drive in Colab.\n",
        "# Mount the Google Drive to the '/content/drive' directory in the Colab environment.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_L7At55GS2H",
        "outputId": "d6db410f-9b1a-43cf-f321-dad743062fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary packages\n",
        "import nltk\n",
        "import requests\n",
        "import pdfplumber\n",
        "import os\n",
        "import io  # Add the missing 'io' import\n",
        "from nltk import sent_tokenize\n",
        "import re\n",
        "\n",
        "# Downloads the necessary data for sentence tokenization using the NLTK library.\n",
        "# This data includes pre-trained models for sentence segmentation in multiple languages.\n",
        "nltk.download('punkt')\n",
        "\n",
        "# A function that takes a URL (http_link) as input and sends an HTTP GET request to that URL\n",
        "def extract_text_from_http_link(http_link):\n",
        "    response = requests.get(http_link)\n",
        "    return response.content\n",
        "\n",
        "# List of 5 different URLs\n",
        "urls = [\n",
        "    'https://arxiv.org/pdf/2104.07186.pdf',\n",
        "    'https://arxiv.org/pdf/2106.14807.pdf',\n",
        "    'https://arxiv.org/pdf/2301.03266.pdf',\n",
        "    'https://arxiv.org/pdf/2303.07678.pdf'\n",
        "]\n",
        "\n",
        "# The text variable is used to store the extracted text from all the PDF documents.\n",
        "text = ''\n",
        "\n",
        "\n",
        "for idx, url in enumerate(urls):\n",
        "    print(f\"Downloading and parsing Paper {idx + 1}...\")\n",
        "    pdf_content = extract_text_from_http_link(url)\n",
        "\n",
        "    # The code iterates through each URL, downloads the PDF content,\n",
        "    # then uses pdfplumber to extract the text from each page of the PDF document.\n",
        "    # It also applies preprocessing by removing non-printable characters from the extracted text.\n",
        "    with pdfplumber.open(io.BytesIO(pdf_content)) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "\n",
        "            # Preprocessing: Remove non-printable characters\n",
        "            page_text = re.sub(r'[^\\x00-\\x7F]', '', page_text)\n",
        "\n",
        "            # Append the page text to the overall text\n",
        "            text += page_text\n",
        "\n",
        "# Preprocessing: Sentence tokenization and removing unnecessary characters\n",
        "sentences = sent_tokenize(text)\n",
        "processed_text = ' '.join(sentences)\n",
        "\n",
        "# Save the preprocessed text to a file\n",
        "file_path = '/content/drive/MyDrive/chatgpt/fai.txt'\n",
        "\n",
        "# Make sure the directory exists before writing the file\n",
        "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(processed_text)\n",
        "\n",
        "print(\"Text extraction and preprocessing completed. Saved to\", file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKwOH3Xwoz4o",
        "outputId": "7b5e4635-efb7-4829-80f7-c800915af13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and parsing Paper 1...\n",
            "Downloading and parsing Paper 2...\n",
            "Downloading and parsing Paper 3...\n",
            "Downloading and parsing Paper 4...\n",
            "Text extraction and preprocessing completed. Saved to /content/drive/MyDrive/chatgpt/fai.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Download the  package, This command installs the tabula-py library,\n",
        " # which is used for extracting tables from PDF documents. It provides functionalities\n",
        " # to parse tables from PDF files and convert them into pandas DataFrames.\n",
        "!pip install tabula-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_q8JqVplIVV",
        "outputId": "5db29117-2bc9-4c1d-916a-d8ca13aeb767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tabula-py\n",
            "  Downloading tabula_py-2.7.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tabula-py) (1.23.5)\n",
            "Requirement already satisfied: distro in /usr/lib/python3/dist-packages (from tabula-py) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->tabula-py) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.25.3->tabula-py) (1.16.0)\n",
            "Installing collected packages: tabula-py\n",
            "Successfully installed tabula-py-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bJfkGetogUT",
        "outputId": "9ead8c9a-3041-4e99-c42e-5c0b3b832a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.3-cp310-none-manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.3 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.3 PyMuPDFb-1.23.3\n"
          ]
        }
      ],
      "source": [
        " # Download the  package\n",
        " # This command installs the PyMuPDF library, which is used for working with PDF files.\n",
        " # It allows you to read, write, and manipulate PDF documents\n",
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd_JLBpmr8uL",
        "outputId": "b72a2dcf-97dc-4e23-b763-f19548b0f070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m61.4/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "# Download the  package for interacting with the OpenAI API\n",
        "\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Download the package\n",
        " # This command installs the python-dotenv library, which helps read variables from .env files. .env files are used to store environment variables\n",
        " # the python-dotenv library makes it easy to load them into your Python script.\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUzuKvgxSsDU",
        "outputId": "b6fa62db-c3e7-4c22-ce7f-c1c8e4aff99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Download the necessary package\n",
        " # This command installs the langchain library, which is used for setting up language chains and utilizing natural language processing functionalities.\n",
        " # Language chains enable the chaining of multiple NLP models to process and analyze text data\n",
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUQ8bSNXTrIU",
        "outputId": "a9787f3f-a4fa-410c-b846-966d4d7c7d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.281-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.21 (from langchain)\n",
            "  Downloading langsmith-0.0.33-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.2.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.14 langchain-0.0.281 langsmith-0.0.33 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Download the necessary package\n",
        " # This command installs the unstructured library, which is used for working with unstructured data. Unstructured data refers to data\n",
        " # that does not have a predefined data model or organization, such as text, images, or audio.\n",
        "!pip install unstructured"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GygM1rWEV94D",
        "outputId": "e0147828-b3d1-4c57-fee9-ca42c6229f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured\n",
            "  Downloading unstructured-0.10.12-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.11.2)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.5.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.4.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2023.7.22)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (4.7.1)\n",
            "Installing collected packages: filetype, python-magic, emoji, unstructured\n",
            "Successfully installed emoji-2.8.0 filetype-1.2.0 python-magic-0.4.27 unstructured-0.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Download the necessary package\n",
        " # This command installs the chromadb library, which provides functionalities to set up a Chroma vector store for text data.\n",
        " # Chroma is a vectorization technique used for representing text data as vectors in NLP tasks.\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3ZYyGJ-WNwr",
        "outputId": "db9b7f6f-989e-4ab3-825b-c983162a70bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.4.9-py3-none-any.whl (421 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/421.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/421.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m419.8/421.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.9/421.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Collecting pydantic<2.0,>=1.9 (from chromadb)\n",
            "  Downloading pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chroma-hnswlib==0.7.2 (from chromadb)\n",
            "  Downloading chroma-hnswlib-0.7.2.tar.gz (31 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fastapi<0.100.0,>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.7.1)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.3)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.5)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (2.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.20.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.1.3)\n",
            "Building wheels for collected packages: chroma-hnswlib, pypika\n",
            "  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.2-cp310-cp310-linux_x86_64.whl size=2285660 sha256=f57bef1b1d31102c1188caaafc2b537f4c80b2912d2dd7187bea8197c72c1ff7\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/2b/0d/ee457f6782f75315bb5828d5c2dc5639d471afbd44a830b9dc\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=1f27d0787ee33d3f14c73561825dee76660e0be5a6402d4dd2fb2fd7c4c8fd35\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built chroma-hnswlib pypika\n",
            "Installing collected packages: pypika, monotonic, websockets, uvloop, pydantic, pulsar-client, overrides, humanfriendly, httptools, h11, chroma-hnswlib, bcrypt, backoff, watchfiles, uvicorn, starlette, posthog, coloredlogs, onnxruntime, fastapi, chromadb\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.2.1\n",
            "    Uninstalling pydantic-2.2.1:\n",
            "      Successfully uninstalled pydantic-2.2.1\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.0.1 chroma-hnswlib-0.7.2 chromadb-0.4.9 coloredlogs-15.0.1 fastapi-0.99.1 h11-0.14.0 httptools-0.6.0 humanfriendly-10.0 monotonic-1.6 onnxruntime-1.15.1 overrides-7.4.0 posthog-3.0.2 pulsar-client-3.3.0 pydantic-1.10.12 pypika-0.48.9 starlette-0.27.0 uvicorn-0.23.2 uvloop-0.17.0 watchfiles-0.20.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Download the necessary package\n",
        " # This command installs the tiktoken library, which is used for counting tokens in a text.\n",
        " # Tokenization is the process of breaking text into individual units or tokens, and the tiktoken library helps count the number of tokens in a given text.\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVsGHzVgWtsT",
        "outputId": "f01c4f87-377d-4c3a-915b-ac8ba5ec88d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.7 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Download  or upgrade the 'pillow' library to version 6.2.2\n",
        "!pip install --upgrade pillow==6.2.2\n"
      ],
      "metadata": {
        "id": "q--qnAe5iyk0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "0467dcfa-4362-4104-cc03-99128a10879c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow==6.2.2\n",
            "  Downloading Pillow-6.2.2.tar.gz (37.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.8/37.8 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pillow\n",
            "  Building wheel for pillow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pillow: filename=Pillow-6.2.2-cp310-cp310-linux_x86_64.whl size=1067612 sha256=7e045c6f4ffab145cd916c4415460a06ff906b036a0209416b05e528bfe99b8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/f0/14/4aa5f8e874837feee51602ab9acc027d9186e7f3cd6752cb89\n",
            "Successfully built pillow\n",
            "Installing collected packages: pillow\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bokeh 3.2.2 requires pillow>=7.1.0, but you have pillow 6.2.2 which is incompatible.\n",
            "dopamine-rl 4.0.6 requires Pillow>=7.0.0, but you have pillow 6.2.2 which is incompatible.\n",
            "imageio 2.31.1 requires pillow>=8.3.2, but you have pillow 6.2.2 which is incompatible.\n",
            "pdfplumber 0.10.2 requires Pillow>=9.1, but you have pillow 6.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pillow-6.2.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Download or upgrade the 'Pillow' library to the latest version\n",
        "!pip install --upgrade Pillow\n"
      ],
      "metadata": {
        "id": "Iez-0PJCrqXT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "c2c41620-9916-4a35-f7ea-90f44bf5dcc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (6.2.2)\n",
            "Collecting Pillow\n",
            "  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 6.2.2\n",
            "    Uninstalling Pillow-6.2.2:\n",
            "      Successfully uninstalled Pillow-6.2.2\n",
            "Successfully installed Pillow-10.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required modules and classes\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain import OpenAI\n",
        "\n",
        "# Load environment variables from a .env file (if present)\n",
        "load_dotenv()\n",
        "\n",
        "# Commented out lines for database setup (not in use)\n",
        "# dburi = os.getenv(\"DATABASE_URL\")\n",
        "# db = SQLDatabase.from_uri(dburi)\n",
        "\n",
        "#  OpenAI API key\n",
        "openai_api_key = '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'\n",
        "\n",
        "# Create an instance of OpenAIEmbeddings using the provided API key\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "\n",
        "# Define a DirectoryLoader to load text documents from a specific directory\n",
        "# The DirectoryLoader will load all .txt files present in the directory and its subdirectories\n",
        "loader = DirectoryLoader('/content/drive/MyDrive/chatgpt', glob=\"**/*.txt\")\n",
        "\n",
        "# Load the documents using the DirectoryLoader\n",
        "documents = loader.load()\n",
        "\n",
        "# Print the loaded documents\n",
        "print(documents)\n",
        "\n",
        "# Define a CharacterTextSplitter to split the documents into smaller chunks\n",
        "# Each chunk will have a maximum size of 2500 characters and no overlap between chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=2500, chunk_overlap=0)\n",
        "\n",
        "# Split the documents into smaller text chunks using the CharacterTextSplitter\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# Print the split texts\n",
        "print(texts)\n",
        "\n",
        "# Create a Chroma vector store from the split texts and the OpenAI embeddings\n",
        "vecstore = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "# Create a RetrievalQA chain for question-answering\n",
        "# Use the OpenAI model with the provided API key as the Language Model (llm)\n",
        "# Use 'QA' as the chain type for question-answering\n",
        "# Set the Chroma vector store as the retriever for answering questions based on similarity\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(openai_api_key=openai_api_key),\n",
        "    chain_type='stuff',\n",
        "    retriever=vecstore.as_retriever()\n",
        ")\n",
        "\n",
        "# Define a function 'query' to ask questions and get answers using the RetrievalQA chain\n",
        "def query(q):\n",
        "    print(\"Query:\", q)\n",
        "    # Use the qa.run() method to get the answer to the provided question\n",
        "    print(\"Answer:\", qa.run(q))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HwFijTRinTy",
        "outputId": "d7505ee3-258c-4f8a-c494-0915a4e6b2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='', metadata={'source': '/content/drive/MyDrive/chatgpt/full.txt'}), Document(page_content='', metadata={'source': '/content/drive/MyDrive/chatgpt/f3.txt'}), Document(page_content='', metadata={'source': '/content/drive/MyDrive/chatgpt/f4.txt'}), Document(page_content='', metadata={'source': '/content/drive/MyDrive/chatgpt/f5.txt'}), Document(page_content='COIL: Revisit Exact Lexical Match in Information Retrieval\\n\\nwith Contextualized Inverted List\\n\\nLuyuGao,ZhuyunDai,JamieCallan\\n\\nLanguageTechnologiesInstitute\\n\\nCarnegieMellonUniversity\\n\\n{luyug, zhuyund, callan}@cs.cmu.edu\\n\\nAbstract the-artintextrankingwithhugeperformanceleap\\n\\n(NogueiraandCho,2019;DaiandCallan,2019b). Classicalinformationretrievalsystemssuchas\\n\\nThough the idea of soft matching all tokens is\\n\\nBM25 rely on exact lexical match and carry\\n\\ncarriedthroughthedevelopmentofneuralIRmod-\\n\\nout search efficiently with inverted list index. 1202\\n\\nRecent neural IR models shifts towards soft els, seeing the success brought by deep LMs, we\\n\\nsemantic matching all query document terms, takeastepbackandask: howmuchgaincanweget\\n\\nbut they lose the computation efficiency of ifweintroducecontextualizedrepresentationsback\\n\\nexact match systems. This paper presents\\n\\ntolexicalexactmatchsystems? Inotherwords,can rpA\\n\\nCOIL, a contextualized exact match retrieval\\n\\nwebuildasystemthatstillperformsexactquery-\\n\\narchitecturethatbringssemanticlexicalmatch-\\n\\ndocumenttokenmatchingbutcomputematching\\n\\ning. COIL scoring is based on overlapping\\n\\n51\\n\\nsignalswithcontextualizedtokenrepresentations\\n\\nquery document tokens contextualized repre-\\n\\nsentations. The new architecture stores con- insteadofheuristics? Thismayseemaconstraint\\n\\ntextualized token representations in inverted onthemodel,butexactlexicalmatchproducemore ]RI.sc[\\n\\nlists, bringing together the efficiency of exact explainableandcontrolledpatternsthansoftmatch-\\n\\nmatch and the representation power of deep ing. It also allows search to focus on only the\\n\\nlanguage models. Our experimental results\\n\\nsubset of documents that have overlapping terms\\n\\nshow COIL outperforms classical lexical re-\\n\\nwithquery,whichcanbedoneefficientlywithin-\\n\\ntrieversandstate-of-the-artdeepLMretrievers\\n\\n1v68170.4012:viXra\\n\\nvertedlistindex. Meanwhile,usingdensecontex-\\n\\nwithsimilarorsmallerlatency.1\\n\\ntualized token representations enables the model\\n\\n1 Introduction to handle semantic mismatch, which has been a\\n\\nlong-standingprobleminclassiclexicalsystems. Widelyused,bag-of-words(BOW)informationre-\\n\\nToanswerthequestion,weproposeanewlexi-\\n\\ntrieval (IR) systems such as BM25 rely on exact\\n\\ncalmatchingschemethatusesvectorsimilarities\\n\\nlexicalmatch2betweenqueryanddocumentterms. betweenquery-documentoverlappingtermcontex-\\n\\nRecentstudyinneuralIRtakesadifferentapproach\\n\\ntualized representations to replace heuristic scor-\\n\\nandcomputesoftmatchingbetweenallqueryand\\n\\ning used in classical systems. We present COn-\\n\\ndocumenttermstomodelcomplexmatching. textualizedInvertedList(COIL),anewexactlex-\\n\\nTheshifttosoftmatchinginneuralIRmodels\\n\\nicalmatchretrievalarchitecturearmedwithdeep\\n\\nattemptstoaddressvocabularymismatchproblems,\\n\\nLM representations. COIL processes documents\\n\\nthat query and the relevant documents use differ-\\n\\nwithdeepLMofflineandproducesrepresentations\\n\\nent terms, e.g. cat v.s. kitty, for the same con-\\n\\nforeachdocumenttoken. Therepresentationsare\\n\\ncept(Huangetal.,2013;Guoetal.,2016;Xiong\\n\\ngroupedbytheirsurfacetokensintoinvertedlists. etal.,2017). Laterintroductionofcontextualized\\n\\nAt search time, we build representation vectors\\n\\nrepresentations(Petersetal.,2018)fromdeeplan-\\n\\nfor query tokens and perform contextualized ex-\\n\\nguagemodels(LM)furtheraddresssemanticmis-\\n\\nact match: use each query token to look up its\\n\\nmatch, that the same term can refer to different\\n\\nown inverted list and compute vector similarity\\n\\nconcepts, e.g., bank of river vs. bank in finance. with document vectors stored in the inverted list\\n\\nFine-tuneddeepLMrerankersproducetokenrep-\\n\\nasmatchingscores. COILenablesefficientsearch\\n\\nresentationsbasedoncontextandachievestate-of-\\n\\nwithrich-in-semanticmatchingbetweenqueryand\\n\\n1Our code is available at https://github.com/\\n\\ndocument. luyug/COIL. 2Exactmatchuptomorphologicalchanges. Our contributions include 1) introduce a novelretrieval architecture, contextualized inverted Deep LM Based Ranker and Retriever Deep\\n\\nlists (COIL) that brings semantic matching into LM made a huge impact on neural IR. Fine-\\n\\nlexical IR systems, 2) show matching signals in- tuned Transformer (Vaswani et al., 2017) LM\\n\\nducedfromexactlexicalmatchcancapturecom- BERT(Devlinetal.,2019)achievedstate-of-the-\\n\\nplicatedmatchingpatterns,3)demonstrateCOIL artrerankingperformanceforpassagesanddocu-\\n\\nsignificantly outperform classical and deep LM ments (Nogueira and Cho, 2019; Dai and Callan,\\n\\naugmentedlexicalretrieversaswellasstate-of-the- 2019b). As illustrated in Figure 1a, the common\\n\\nartdenseretrieversontworetrievaltasks. approach is to feed the concatenated query docu-\\n\\nment text through BERT and use BERTs [CLS]\\n\\noutput token to produce a relevance score. The\\n\\n2 RelatedWork\\n\\ndeepLMrerankersaddressedbothvocabularyand\\n\\nsemanticmismatchbycomputingfullcrossatten-\\n\\nLexicalRetriever ClassicalIRsystemsrelyon\\n\\ntionbetweencontextualizedtokenrepresentations. exact lexical match retrievers such as Boolean\\n\\nLighter deep LM rankers are developed (MacA-\\n\\nRetrieval, BM25 (Robertson and Walker, 1994)\\n\\nvaneyetal.,2020;Gaoetal.,2020),buttheircross\\n\\nandstatisticallanguagemodels(LaffertyandZhai,\\n\\nattentionoperationsarestilltooexpensiveforfull-\\n\\n2001). This type of retrieval model can process\\n\\ncollectionretrieval. queriesveryquicklybyorganizingthedocuments\\n\\nLater research therefore resorted to augment-\\n\\ninto inverted index, where each distinct term has\\n\\ninglexicalretrievalwithdeepLMsbyexpanding\\n\\naninvertedlistthatstoresinformationaboutdocu-\\n\\nthe document surface form to narrow the vocab-\\n\\nmentsitappearsin. Nowadays,theyarestillwidely\\n\\nulary gap, e.g., DocT5Query (Nogueira and Lin,\\n\\nused in production systems. However, these re-\\n\\n2019),oralteringtermweightstoemphasizeimpor-\\n\\ntrievalmodelsfallshortofmatchingrelatedterms\\n\\ntantterms,e.g.,DeepCT(DaiandCallan,2019a). (vocabularymismatch)ormodelingcontextofthe\\n\\nSmartlycombiningdeepLMretrieverandreranker\\n\\nterms (semantic mismatch). Much early effort\\n\\ncanofferadditivegainforendperformance(Gao\\n\\nwasputintoimprovingexactlexicalmatchretriev-\\n\\netal.,2021a). Theseretrievershoweverstillsuffer\\n\\ners,suchasmatchingn-grams(MetzlerandCroft,\\n\\nfromvocabularyandsemanticmismatchastradi-\\n\\n2005)orexpandingquerieswithtermsfromrelated\\n\\ntionallexicalretrievers. documents(LavrenkoandCroft,2001). However,\\n\\nthesemethodsstilluseBOWframeworkandhave Anotherlineofresearchcontinuestheworkon\\n\\nlimitedcapabilityofmodelinghumanlanguages. singlevectorrepresentationandbuilddenseretriev-\\n\\ners, as illustrated in Figure 1b. They store docu-\\n\\nment vectors in a dense index and retrieve them\\n\\nNeural Ranker In order to deal with vocab-\\n\\nthrough Nearest Neighbours search. Using deep\\n\\nulary mismatch, neural retrievers that rely on\\n\\nLMs,denseretrievershaveachievedpromisingre-\\n\\nsoft matching between numerical text represen-\\n\\nsults on several retrieval tasks (Karpukhin et al.,\\n\\ntations are introduced. Early attempts compute\\n\\n2020). Laterresearchesshowthatdenseretrieval\\n\\nsimilarity between pre-trained word embedding\\n\\nsystems can be further improved by better train-\\n\\nsuch as word2vec (Mikolov et al., 2013) and\\n\\ning(Xiongetal.,2020;Gaoetal.,2021b). GLoVe(Penningtonetal.,2014)toproducematch-\\n\\ningscore(Gangulyetal.,2015;Diazetal.,2016). Singlevectorsystemshavealsobeenextended\\n\\nOnemorerecentapproachencodesqueryanddoc- to multi-vector representation systems. Poly-\\n\\numenteachintoavectorandcomputesvectorsim- encoder (Humeau et al., 2020) encodes queries\\n\\nilarity(Huangetal.,2013). Laterresearchesreal- into a set of vectors. Similarly, Me-BERT (Luan\\n\\nized the limited capacity of a single vector to en- etal.,2020)representsdocumentswithasetofvec-\\n\\ncodefine-grainedinformationandintroducedfull tors. AconcurrentworkColBERT(Figure1c)use\\n\\ninteraction models to perform soft matching be- multiplevectorstoencodebothqueriesanddocu-\\n\\ntween all term vectors (Guo et al., 2016; Xiong ments(KhattabandZaharia,2020). Inparticular,it\\n\\net al., 2017). In these approaches, scoring is representsadocumentswithallitstermsvectors\\n\\nbased onlearned neuralnetworks andthe hugely andaquerywithanexpandedsetoftermvectors. increased computation cost limited their use to It then computesall-to-all (Cartesian) soft match\\n\\nrerankingatopcandidatelistgeneratedbyalexical betweenthetokens. ColBERTperformsinteraction\\n\\nretriever. asdotproductfollowedpoolingoperations,whichscore\\n\\nscore\\n\\nCLS bank account SEP bank river bank\\n\\nCLS bank account SEP bank river bank CLS bank account CLS bank river bank\\n\\nCLS bank account SEP bank river bank CLS bank account CLS bank river bank\\n\\nCLS bank account SEP bank river bank CLS bank account CLS bank river bank\\n\\n(a)Cross-AttentionModel(e.g.,BERTreranker) (b)DenseRetrievers(e.g.,DPR)\\n\\nscore sum\\n\\ndot max\\n\\nmax max max max max\\n\\nCLS bank account EXP EXP CLS bank river bank CLS bank account CLS bank river bank\\n\\nCLS bank account EXP EXP CLS bank river bank CLS bank account CLS bank river bank\\n\\nCLS bank account EXP EXP CLS bank river bank CLS bank account CLS bank river bank\\n\\n(c)ColBERT:All-to-AllMatch (d)COIL:ContextualizedExactMatch\\n\\nFigure1: Anillustrationofreranking/retrievalmechanismswithdeepLM,includingourproposedmodel,COIL. BBMM2255 docid [1 2 3 4 .............C] matrix\\n\\nBank do tc f:i d 1: 1 do tc f:i d 1: 3 do tc f:i d 1: 6 .... ssccoorriinngg Bank CLS vectors ... product CLS\\n\\ndocid: 1 docid: 2 docid: 4 docid: 5\\n\\nRiver tf: 1 tf: 1 tf: 1 tf: 2 .... docid [1 3 6 7]\\n\\nmatrix\\n\\nAccount Bank vectors product\\n\\nBank\\n\\ndocid: 3 docid: 9\\n\\nAccount\\n\\ntf: 2 tf: 1 BM25 docid [1 2 4 5 5 9]\\n\\nscoring River vectors\\n\\nAccount\\n\\nTraditional Inverted Lists Query\\n\\ndocid [3 3 9]\\n\\nFigure 2: An illustration of traditional inverted lists. Account vectors matrix\\n\\nproduct\\n\\nThe inverted list maps a term to the list of documents\\n\\nwherethetermoccurs. Retrieverlooksupqueryterms\\n\\ninverted lists and scores those documents with stored Contextualized Inverted Lists Query\\n\\nstatisticssuchastermfrequency(tf). Figure 3: COILs index and retrieval architecture. COIL-tok relies on the exact token matching (lower). COIL-fullincludesinadditionCLSmatching(upper). allowsittoalsoleverageadenseindextodofull\\n\\ncorpusretrieval. However,sinceColBERTencodes\\n\\nadocumentwithalltokens,itaddsanotherorder 3.1 Preliminaries\\n\\nofmagnitudeofindexcomplexitytoallaforemen-\\n\\nClassic lexical retrieval system relies on overlap-\\n\\ntionedmethods: documenttokensinthecollection\\n\\npingquerydocumenttermsundermorphological\\n\\nneed to be stored in a single huge index and con-\\n\\ngeneralizationlikestemming,inotherwords,exact\\n\\nsideredatquerytime. Consequently,ColBERTis\\n\\nlexical match, to score query document pair. A\\n\\nengineeringandhardwaredemanding. scoring function is defined as a sum of matched\\n\\ntermscores. Thescoresareusuallybasedonstatis-\\n\\n3 Methodologies\\n\\ntics like term frequency (tf). Generally, we can\\n\\nwrite,\\n\\nInthissection,wefirstprovidesomepreliminaries\\n\\nonexactlexicalmatchsystems. Thenwediscuss (cid:88)\\n\\ns =  (h (q,t),h (d,t)) (1)\\n\\nt q d\\n\\nCOILscontextualizedexactmatchdesignandhow\\n\\ntqd\\n\\nitssearchindexisorganized. Wealsogiveacom-\\n\\nparisonbetweenCOILandotherpopularretrievers. whereforeachoverlappingtermtbetweenqueryq\\n\\nanddocumentd,functionsh andh extractterm\\n\\nq dinformation and a term scoring function  com- where Wntn lm is a matrix that maps the LMs\\n\\nt tok\\n\\nbines them. A popular example is BM25, which n dimension output into a vector of lower di-\\n\\nlm\\n\\ncomputes, mension n . We down project the vectors as we\\n\\nt\\n\\n(cid:88) hypothesizethatitsufficestouselowerdimension\\n\\ns = idf(t)hBM25(q,t)hBM25(d,t)\\n\\nBM25 q d tokenvectors. Weconfirmthisinsection5. Simi-\\n\\ntqd larly,weencodeadocumentdsj-thtokend with:\\n\\nj\\n\\ntf (1+k )\\n\\nhB qM25(q,t) = tt f,q 22 (2)\\n\\nt,q +k v jd = W tokLM(d,j)+b tok (4)\\n\\ntf (1+k )\\n\\nhBM25(d,t) = t,d 1 Wethendefinethecontextualizedexactlexical\\n\\nd |d|\\n\\ntf +k (1b+b )\\n\\nt,d 1 avgdl match scoring function between query document\\n\\nbasedonvectorsimilaritiesbetweenexactmatched\\n\\nwhere tf refers to term frequency of term t in\\n\\nt,d\\n\\nquerydocumenttokenpairs:\\n\\ndocument d, tf refers to the term frequency in\\n\\nt,q\\n\\nquery,idf(t)isinversedocumentfrequency,andb, s (q,d) = (cid:88) max(vq(cid:124) vd) (5)\\n\\nk ,k arehyper-parameters. tok i j\\n\\n1 2 dj=qi\\n\\nqiqd\\n\\nOne key advantage of exact lexical match sys-\\n\\ntemsliesinefficiency. Withsummationoverexact Notethat,importantly,thesummationgoesthrough\\n\\nmatches,scoringofeachquerytermonlygoesto onlyoverlappingterms,q  qd. Foreachquery\\n\\ni\\n\\ndocumentsthatcontainmatchingterms. Thiscan tokenq ,wefindsallsametokensd inthedocu-\\n\\ni j\\n\\nbedoneefficientlyusinginvertedlistindexing(Fig- ment, computes their similarity with q using the\\n\\ni\\n\\nure 2). The inverted list maps back from a term contextualized tokenvectors. Themaximumsim-\\n\\nto a list of documents where the term occurs. To ilarities are picked for query token q . Max op-\\n\\ni\\n\\ncompute Equation 1, the retriever only needs to erator is adopted to capture the most important\\n\\ntraverse the subset of documents in query terms signal(Kim,2014). Thisfitsinthegenerallexical\\n\\ninvertedlistsinsteadofgoingovertheentiredocu- matchformulation,withh givingrepresentation\\n\\nq\\n\\nmentcollection. forq ,h givingrepresentationsforalld = q ,and\\n\\ni t j i\\n\\nWhilerecentneuralIRresearchmainlyfocuses  computedotsimilaritiesbetweenqueryvector\\n\\nt\\n\\non breaking the exact match bottleneck with soft withdocumentvectorsandmaxpoolthescores. matchingoftext,wehypothesizethatexactmatch Aswithclassiclexicalsystems,s definedin\\n\\ntok\\n\\nitself can be improved by replacing semantic in-\\n\\nEquation5doesnottakeintoaccountsimilarities\\n\\ndependentfrequency-basedscoringwithsemantic\\n\\nbetweenlexical-differentterms,thusfacesvocabu-\\n\\nrich scoring. In the rest of this section, we show\\n\\nlarymismatch. ManypopularLMs(Devlinetal.,\\n\\nhowtomodifytheexactlexicalmatchframework\\n\\n2019; Yang et al., 2019; Liu et al., 2019) use a\\n\\nwith contextualized term representations to build\\n\\nspecialCLStokentoaggregatesequencerepresen-\\n\\neffectiveandefficientretrievalsystems. WeprojecttheCLSvectoswithWncn\\n\\ntation. lm\\n\\ncls\\n\\ntorepresenttheentirequeryordocument,\\n\\n3.2 ContextualizedExactLexicalMatch\\n\\nInstead of term frequency, we desire to encode vq = W LM(q,CLS)+b\\n\\ncls cls cls\\n\\n(6)\\n\\nthesemanticsoftermstofacilitatemoreeffective\\n\\nvd = W LM(d,CLS)+b\\n\\nmatching. Inspiredbyrecentadvancementsindeep cls cls cls\\n\\nLM,weencodebothqueryanddocumenttokens Thesimilaritybetweenvq andvd provideshigh-\\n\\ncls cls\\n\\nintocontextualizedvectorrepresentationsandcarry\\n\\nlevelsemanticmatchingandmitigatestheissueof\\n\\noutmatchingbetweenexactlexicalmatchedtokens. vocabularymismatch. ThefullformofCOILis:\\n\\nFigure1dillustratesthescoringmodelofCOIL. In this work, we use a Transformer language s (q,d) = s (q,d)+vq (cid:124) vd (7)\\n\\nfull tok cls cls\\n\\nmodel3 as the contextualization function. We en-\\n\\ncodeaqueryq withthelanguagemodel(LM)and In the rest of the paper, we refer to systems with\\n\\nrepresent its i-th token by projecting the corre- CLSmatchingCOIL-fullandwithoutCOIL-tok. spondingoutput: COILsscoringmodel(Figure1d)isfullydiffer-\\n\\nentiable. Followingearlierwork(Karpukhinetal.,\\n\\nvq = W LM(q,i)+b (3)\\n\\ni tok tok 2020),wetrainCOILwithnegativeloglikelihood\\n\\n3Weusedthebase,uncasedvariantofBERT. definedoverqueryq,apositivedocumentd+ andasetofnegativedocuments{d,d,..d..}asloss. serveinparallel. Thescoresarethencombinedby\\n\\n1 2 l\\n\\nEquation5torankthedocuments. Readerscanfinddetailedillustrationfiguresin\\n\\nexp(s(q,d+))\\n\\nL = log theAppendixA,forindexbuildingandquerying,\\n\\nexp(s(q,d+))+(cid:80) exp(s(q,d))\\n\\nl Figure4andFigure5,respectively. l\\n\\n(8)\\n\\n3.4 ConnectiontoOtherRetrievers\\n\\nFollowingKarpukhinetal. (2020),weuseinbatch\\n\\nnegativesandhardnegativesgeneratedbyBM25. Deep LM based Lexical Index Models like\\n\\nDetailsarediscussedinimplementation,section4. DeepCT (Dai and Callan, 2019a, 2020) and\\n\\nDocT5Query(NogueiraandLin,2019)altertf\\n\\nt,d\\n\\n3.3 IndexandRetrievalwithCOIL indocumentswithdeepLMBERTorT5. Thisis\\n\\nCOILpre-computesthedocumentrepresentations similartoaCOIL-tokwithtokendimensionn t = 1.\\n\\nandbuildsupasearchindex,whichisillustratedin Asingledegreeoffreedomhowevermeasuresmore\\n\\nFigure3. Documentsinthecollectionareencoded ofatermimportancethansemanticagreement. offlineintotokenandCLSvectors. Formally,for\\n\\nDense Retriever Dense retrievers (Figure 1b)\\n\\na unique token t in the vocabulary V, we collect\\n\\nareequivalenttoCOIL-fullsCLSmatching. COIL\\n\\nitscontextualizedvectorsfromallofitsmentions\\n\\nmakes up for the lost token-level interactions in\\n\\nfromdocumentsincollectionC,buildingtokents\\n\\ndenseretrieverwithexactmatchingsignals. contextualizedinvertedlist:\\n\\nColBERT ColBERT (Figure 1c) computes rel-\\n\\nIt = {v jd | d j = t,d  C}, (9) evance by soft matching all query and document\\n\\ntermscontextualizedvectors. where vd is the BERT-based token encoding de-\\n\\nfined inj Equation 4. We define search index to s(q,d) = (cid:88) max (vq(cid:124) vd) (10)\\n\\ni j\\n\\nqi[cls;q;exp]dj[cls;d]\\n\\nstore inverted lists for all tokens in vocabulary,\\n\\nI = {It | t  V}. ForCOIL-full,wealsobuildan\\n\\nwhere interactions happen among query q, docu-\\n\\nindexfortheCLStokenIcls = {vd | d  C}. cls mentd,clsandsetofqueryexpansiontokensexp. As shown in Figure 3, in this work we im-\\n\\nTheall-to-allmatchcontrastsCOILthatonlyuses\\n\\nplement COILs by stacking vectors in each in-\\n\\nverted list It into a matrix Mnt|Ik|, so that sim- exactmatch. Itrequiresadenseretrievaloverall\\n\\ndocument tokens representations as opposed to\\n\\nilarity computation that traverses an inverted list\\n\\nCOILwhichonlyconsidersquerysoverlappingto-\\n\\nand computes vector dot product can be done ef-\\n\\nkens,andarethereforemuchmorecomputationally\\n\\nficiently as one matrix-vector product with opti-\\n\\nexpensivethanCOIL. mizedBLAS(Blackfordetal.,2002)routineson\\n\\nCPUorGPU.Allvd vectorscanalsobeorganized\\n\\ncls 4 ExperimentMethodologies\\n\\nin a similarfashioninto matrix M and queried\\n\\ncls\\n\\nwith matrix product. The matrix implementation Datasets Weexperimentwithtwolargescalead\\n\\nhereisanexhaustiveapproachthatinvolvesallvec- hoc retrieval benchmarks from the TREC 2019\\n\\ntors in an inverted list. As a collection of dense Deep Learning (DL) shared task: MSMARCO\\n\\nvectors,itisalsopossibletoorganizeeachinverted passage (8M English passages of average length\\n\\nlistasanapproximatesearchindex(Johnsonetal., around60tokens)andMSMARCOdocument(3M\\n\\n2017;Guoetal.,2019)tofurtherspeedupsearch. Englishdocumentsofaveragelengtharound900\\n\\nWhen a query q comes in, we encode every of tokens)4. For each, we train models with the\\n\\nits token into vectors vq . The vectors are sent to MSMARCO Train queries, and record results on\\n\\ni\\n\\nthesubsetofCOILinvertedliststhatcorresponds MSMARCO Dev queries and TREC DL 2019\\n\\nquery tokens J = {It | t  q}. where the matrix test queries. We report mainly full-corpus re-\\n\\nproduct described above is carried out. This is trieval results but also include the rerank task on\\n\\nefficientas|J| << |I|,havingonlyasmallsubset MSMARCO Dev queries where we use neural\\n\\nof all inverted lists to be involved in search. For scorestoreorderBM25retrievalresultsprovided\\n\\nCOIL-full,wealsouseencodedCLSvectorsvq byMSMAROorganizers. Officialmetricsinclude\\n\\ncls\\n\\nto query the CLS index to get the CLS matching\\n\\n4Both datasets can be downloaded from https://\\n\\nscores. Thescoringoverdifferentinvertedlistscan microsoft.github.io/msmarco/MRR@1KandNDCG@10ontestandMRR@10 overcontextualizedinvertedlists,b)scattertomap\\n\\nonMSMARCODev. Wealsoreportrecallforthe tokenscoresbacktodocuments,andc)sorttorank\\n\\ndevqueriesfollowingpriorwork(DaiandCallan, the documents. Illustration can be found in the\\n\\n2019a;NogueiraandLin,2019). appendix,Figure5. Compared Systems Baselines include 1) tradi- 5 Results\\n\\ntionalexactmatchsystemBM25,2)deepLMaug-\\n\\nThis section studies the effectiveness of COIL\\n\\nmentedBM25systemsDeepCT(DaiandCallan,\\n\\nand how vector dimension in COIL affects the\\n\\n2019a)andDocT5Query(NogueiraandLin,2019),\\n\\neffectiveness-efficiencytradeoff. Wealsoprovide\\n\\n3) dense retrievers, and 4) soft all-to-all retriever\\n\\nqualitativeanalysisoncontextualizedexactmatch. ColBERT.ForDeepCTandDocT5Query,weuse\\n\\nthe rankings provided by the authors. For dense\\n\\n5.1 MainResults\\n\\nretrievers, we report two dense retrievers trained\\n\\nTable 1 reports various systems performance on\\n\\nwith BM25 negatives or with mixed BM25 and\\n\\nthe MARCO passage collection. COIL-tok ex-\\n\\nrandomnegatives,publishedinXiongetal.(2020). act lexical match only system significantly out-\\n\\nHoweversincethesesystemsusearobustversion\\n\\nperforms all previous lexical retrieval systems. of BERT, RoBERTa (Liu et al., 2019) as the LM\\n\\nWith contextualized term similarities, COIL-tok\\n\\nandtraindocumentretrieveralsoonMSMARCO\\n\\nachievesaMRRof0.34comparedtoBM25sMRR\\n\\npassageset,weinadditionreproduceathirddense\\n\\n0.18. DeepCT and DocT5Query, which also use\\n\\nretriever,thatusestheexactsametrainingsetupas\\n\\ndeepLMslikeBERTandT5,areabletobreakthe\\n\\nCOIL.Alldenseretrieversuse768dimensionem-\\n\\nlimitofheuristictermfrequenciesbutarestilllim-\\n\\nbedding. ForColBERT,wereportitspublishedre-\\n\\nitedbysemanticmismatchissues. WeseeCOIL-\\n\\nsults(availableonlyonpassagecollection). BERT\\n\\ntokoutperformsbothsystemsbyalargemargin. rerankerisaddedinthereranktask. COIL-tokalsorankstopofthecandidatelistbet-\\n\\nWeinclude2COILsystems: 1)COIL-tok,the\\n\\nter than dense retrieves. It prevails in MRR and\\n\\nexacttokenmatchonlysystem,and2)COLL-full,\\n\\nNDCG while performs on par in recall with the\\n\\nthemodelwithbothtokenmatchandCLSmatch. best dense system, indicating that COILs token\\n\\nlevelinteractioncanimproveprecision. Withthe\\n\\nImplementation We build our models with Py-\\n\\nCLSmatchingadded,COIL-fullgainstheability\\n\\ntorch (Paszke et al., 2019) based on huggingface\\n\\nto handle mismatched vocabulary and enjoys an-\\n\\ntransformers (Wolf et al., 2019). COILs LM is\\n\\nother performance leap, outperforming all dense\\n\\nbasedonBERTsbasevariant. COILsystemsuse\\n\\nretrievers. tokendimensionn = 32andCOIL-fulluseCLS\\n\\nt\\n\\ndimension n = 768 as default, leading to 110M COIL-fullachievesaverynarrowperformance\\n\\nc\\n\\ngaptoColBERT.RecallthatColBERTcomputes\\n\\nparameters. WeaddaLayerNormalizationtoCLS\\n\\nall-to-allsoftmatchesbetweenalltokenpairs. For\\n\\nvector when useful. All models are trained for 5\\n\\nretrieval,itneedstoconsiderforeachquerytoken\\n\\nepochswithAdamWoptimizer,alearningrateof\\n\\nall mentions of all tokens in the collection (MS-\\n\\n3e-6, 0.1 warm-up ratio, and linear learning rate\\n\\nMARCOpassagecollectionhasaround500Mto-\\n\\ndecay, which takes around 12 hours. Hard neg-\\n\\nkenmentions). COIL-fullisabletocapturematch-\\n\\natives are sampled from top 1000 BM25 results. ingpatternsaseffectivelywithexactmatchsignals\\n\\nEach query uses 1 positive and 7 hard negatives;\\n\\nfromonlyquerytokensmentionsandasingleCLS\\n\\neachbatchuses8queriesonMSMARCOpassage\\n\\nmatchingtobridgethevocabularygap. and4onMSMARCOdocument. Documentsare\\n\\ntruncated to the first 512 tokens to fit in BERT. Weobserveasimilarpatterninthereranktask. We conduct validation on randomly selected 512 COIL-tok is already able to outperform dense re-\\n\\nqueriesfromcorrespondingtrainset. Latencynum- triever and COIL-full further adds up to perfor-\\n\\nbers are measured on dual Xeon E5-2630 v3 for mancewithCLSmatching,beingon-parwithCol-\\n\\nCPU and RTX 2080 ti for GPU. We implement BERT.Meanwhile,previousBERTrerankershave\\n\\nlittleperformanceadvantageoverCOIL5.Inprac-\\n\\nCOILs inverted lists as matrices as described in\\n\\nsubsection3.3,usingNumPy(Harrisetal.,2020) tice, we found BERT rerankers to be much more\\n\\nonCPUandPytorchonGPU.Weperforma)aset\\n\\n5CloseperformancebetweenCOILandBERTrerankers\\n\\nof matrix products to compute token similarities ispartiallyduetothebottleneckofBM25candidates.Table1: MSMARCOpassagecollectionresults. Resultsnotapplicablearedenotedandnoavailablen.a..\\n\\nMSMARCOPassageRanking\\n\\nDevRerank DevRetrieval DL2019Retrieval\\n\\nModel MRR@10 MRR@10 Recall@1K NDCG@10 MRR@1K\\n\\nLexicalRetriever\\n\\nBM25  0.184 0.853 0.506 0.825\\n\\nDeepCT  0.243 0.909 0.572 0.883\\n\\nDocT5Query  0.278 0.945 0.642 0.888\\n\\nBM25+BERTreranker 0.347\\n\\nDenseRetriever\\n\\nDense(BM25neg) n.a. 0.299 0.928 0.600 n.a. Dense(rand+BM25neg) n.a. 0.311 0.952 0.576 n.a. Dense(ourtrain) 0.312 0.304 0.932 0.635 0.898\\n\\nColBERT 0.349 0.360 0.968 n.a. n.a. COIL-tok 0.336 0.341 0.949 0.660 0.915\\n\\nCOIL-full 0.348 0.355 0.963 0.704 0.924\\n\\nTable2: MSMARCOdocumentcollectionresults. Resultsnotapplicablearedenotedandnoavailablen.a..\\n\\nMSMARCODocumentRanking\\n\\nDevRerank DevRetrieval DL2019Retrieval\\n\\nModel MRR@10 MRR@10 Recall@1K NDCG@10 MRR@1K\\n\\nLexicalRetriever\\n\\nBM25  0.230 0.886 0.519 0.805\\n\\nDeepCT  0.320 0.942 0.544 0.891\\n\\nDocT5Query  0.288 0.926 0.597 0.837\\n\\nBM25+BERTreranker 0.383\\n\\nDenseRetriever\\n\\nDense(BM25neg) n.a. 0.299 0.928 0.600 n.a. Dense(rand+BM25neg) n.a. 0.311 0.952 0.576 n.a. Dense(ourtrain) 0.358 0.340 0.883 0.546 0.785\\n\\nCOIL-tok 0.381 0.385 0.952 0.626 0.921\\n\\nCOIL-full 0.388 0.397 0.962 0.636 0.913\\n\\nexpensive, requiring over 2700 ms for reranking 5.2 AnalysisofDimensionality\\n\\ncomparedtoaround10msinthecaseofCOIL. ThesecondexperimenttestshowvaryingCOILs\\n\\nTable2reportstheresultsonMSMARCOdocu-\\n\\ntokendimensionn andCLSdimensionn affect\\n\\nmentcollection. Ingeneral,weobserveasimilar t c\\n\\nmodeleffectivenessandefficiency. Werecordre-\\n\\npattern as with the passage case. COIL systems\\n\\ntrievalperformanceandlatencyonMARCOpas-\\n\\nsignificantlyoutperformbothlexicalanddensesys-\\n\\nsagecollectioninTable3. temsinMRRandNDCGandretainasmalladvan-\\n\\ntage measured in recall. The results suggest that InCOIL-fullsystems,reducingCLSdimension\\n\\nCOILcanbeapplicabletolongerdocumentswith from 768 to 128 leads to a small drop in perfor-\\n\\naconsistentadvantageineffectiveness. mance on the Dev set, indicating that a full 768\\n\\ndimensionmaynotbenecessaryforCOIL.Keep-\\n\\nTheresultsindicateexactlexicalmatchmecha-\\n\\ning CLS dimension at 128, systems with token\\n\\nnismcanbegreatlyimprovedwiththeintroduction\\n\\ndimension32and8haveverysmallperformance\\n\\nofcontextualizedrepresentationinCOIL.COILs\\n\\ndifference,suggestingthattoken-specificsemantic\\n\\ntoken-level match also yields better fine-grained\\n\\nconsumesmuchfewerdimensions. Similarpattern\\n\\nsignalsthandenseretrieversglobalmatchsignal. inn isalsoobservedinCOIL-tok(n = 0). COIL-fullfurthercombinesthelexicalsignalswith t c\\n\\ndenseCLSmatch,formingasystemthatcandeal OntheDL2019queries,weobservethatreduc-\\n\\nwithbothvocabularyandsemanticmismatch,be- ingdimensionactuallyachievesbetterMRR.We\\n\\ningaseffectiveasall-to-allsystem. believe this is due to a regulatory effect, as theTable3: PerformanceandlatencyofCOILsystemswithdifferentrepresentationdimensions. Resultsnotapplica-\\n\\nblearedenotedandnoavailablen.a.. Heren denotesCOILCLSdimensionandn tokenvectordimension. c t\\n\\n: ColBERTuseapproximatesearchandquantization. WeexcludeI/Otimefrommeasurements. DevRetrieval DL2019Retrieval Latency/ms\\n\\nModel MRR@10 Recall@1K NDCG@10 MRR CPU GPU\\n\\nBM25 0.184 0.853 0.506 0.825 36 n.a. Dense 0.304 0.932 0.635 0.898 293 32\\n\\nColBERT 0.360 0.968 n.a. n.a. 458*\\n\\nCOIL\\n\\nn n\\n\\nc t\\n\\n768 32 0.355 0.963 0.704 0.924 380 41\\n\\n128 32 0.350 0.953 0.692 0.956 125 23\\n\\n128 8 0.347 0.956 0.694 0.977 113 21\\n\\n0 32 0.341 0.949 0.660 0.915 67 18\\n\\n0 8 0.336 0.940 0.678 0.953 55 16\\n\\nTable4:SamplequerydocumentpairswithsimilarityscoresproducedbyCOIL.Tokensinexaminationarecolored\\n\\nblue. Numbersinbracketsarequery-documentvectorsimilaritiescomputedwithvectorsgeneratedbyCOIL. QueryToken COILContextualizedExactMatchScore Relevance\\n\\nCabinet [16.28] (government) A cabinet [16.75] is a body of high-\\n\\n+\\n\\nwhatisacabinetingovt rankingstateofficials,typicallyconsistingofthetopleadersofthe.... Cabinet[7.23]is20x60andtopis28x72.....Ihada2cmgranitecounter-\\n\\n\\n\\ntopinstalledwitha10inchoverhangononesideanda14inch....\\n\\nPriorityPass[11.61]isanindependentairportloungeaccessprogram.A\\n\\n+\\n\\nwhatisprioritypass membershipprovidesyouwithaccesstotheirnetworkofover700....\\n\\nSnoqualmiePass[7.98]isamountainpass[6.83]thatcarriesInterstate\\n\\n\\n\\n90throughtheCascadeRangeintheU.S.StateofWashington....\\n\\nNJSTARTis[1.25]aself-serviceonlineplatformthatallowsvendorsto\\n\\n+\\n\\nwhatisnjstart manageforms,certifications,submitproposals,accesstraining....\\n\\nContractawardeeswillreceivetheirBlanketP.O.onceitis[-0.10]con-\\n\\n\\n\\nverted,anddetailsregardingthatprocesswillalsobesent...\\n\\ntestquerieswerelabeleddifferentlyfromtheMS- 5.3 CaseStudy\\n\\nMARCOtrain/devqueries(Craswelletal.,2020). COILdiffersfromallpreviousembedding-based\\n\\nmodelsinthatitdoesnotuseasingleunifiedem-\\n\\nWe also record CPU and GPU search latency\\n\\nbeddingspace. Instead,foraspecifictoken,COIL\\n\\nin Table 3. Lowering COIL-fulls CLS dimen-\\n\\nlearnsanembeddingspacetoencodeandmeasure\\n\\nsionfrom768to128givesabigspeedup,making\\n\\nthe semantic similarity of the token in different\\n\\nCOIL faster than DPR system. Further dropping\\n\\ncontexts. Inthissection,weshowexampleswhere\\n\\ntokendimensionsprovidesomeextraspeedup. The\\n\\nCOILdifferentiatesdifferentsensesofawordun-\\n\\nCOIL-toksystemsrunfasterthanCOIL-full,witha\\n\\nder different contexts. In Table 4, we show how\\n\\nlatencyofthesameorderofmagnitudeasthetradi-\\n\\nthetokensimilarityscoresdifferacrosscontextsin\\n\\ntionalBM25system. Importantly,lowerdimension\\n\\nrelevantandirrelevantquerydocumentpairs. COILsystemsstillretainaperformanceadvantage\\n\\nover dense systems while being much faster. We Thefirstquerylooksforcabinetinthecontext\\n\\nincludeColBERTslatencyreportedintheoriginal of govt (abbreviation for government). The\\n\\npaper,whichwasoptimizedbyapproximatesearch twodocumentsbothincludequerytoken\"cabinet\"\\n\\nand quantization. All COIL systems have lower but of a different concept. The first one refers to\\n\\nlatencythanColBERTeventhoughourcurrentim- the government cabinet and the second to a case\\n\\nplementationdoesnotusethoseoptimizationtech- orcupboard. COILmanagestomatchcabinetin\\n\\nniques. Wehowevernotethatapproximatesearch the query to cabinet in the first document with\\n\\nandquantizationareapplicabletoCOIL,andleave amuchhigherscore. Inthesecondquery,\"pass\"\\n\\nthestudyofspeedingupCOILtofuturework. inbothdocumentsrefertotheconceptofpermis-sion. However, through contextualization, COIL WithourCOILsystemsshowingviablesearch\\n\\ncapturesthevariationofthesameconceptandas- latency, we believe this paper makes a solid step\\n\\nsignsahigherscoretopassinthefirstdocument. towardsbuildingnext-generationindexthatstores\\n\\nStop words like it, a, and the are com- semantics. Attheintersectionoflexicalandneural\\n\\nmonlyremovedinclassicexactmatchIRsystems systems,efficientalgorithmsproposedforbothcan\\n\\nas they are not informative on their own. In the pushCOILtowardsreal-worldsystems. third query, on the other hand, we observe that\\n\\nCOILisabletodifferentiateisinanexplanatory\\n\\nsentenceandisinapassiveform,assigningthe\\n\\nfirsthigherscoretomatchquerycontext. All examples here show that COIL can go be-\\n\\nyond matching token surface form and introduce\\n\\nrichcontextinformationtoestimatematching. Dif-\\n\\nferencesinsimilarityscoresacrossmentionsunder\\n\\ndifferentcontextsdemonstratehowCOILsystems\\n\\ngainstrengthoverlexicalsystems. 6 ConclusionandFutureWork\\n\\nExactlexicalmatchsystemshavebeenwidelyused\\n\\nfordecadesinclassicalIRsystemsandprovetobe\\n\\neffectiveandefficient. Inthispaper,wepointout\\n\\nacriticalproblem,semanticmismatch,thatgener-\\n\\nally limits all IR systems based on surface token\\n\\nfor matching. To fix semantic mismatch, we in-\\n\\ntroducecontextualizedexactmatchtodifferentiate\\n\\nthesametokenindifferentcontexts,providingef-\\n\\nfective semantic-aware token match signals. We\\n\\nfurtherproposecontextualizedinvertedlist(COIL)\\n\\nsearch index which swaps token statistics in in-\\n\\nvertedlistswithcontextualizedvectorrepresenta-\\n\\ntionstoperformeffectivesearch. Ontwolarge-scaleadhocretrievalbenchmarks,\\n\\nwe find COIL substantially improves lexical re-\\n\\ntrieval and outperforms state-of-the-art dense re-\\n\\ntrievalsystems. Theseresultsindicatelargehead-\\n\\nroomofthesimple-but-efficientexactlexicalmatch\\n\\nscheme. When the introduction of contextualiza-\\n\\ntionhandlestheissueofsemanticmismatch,exact\\n\\nmatchsystemgainsthecapabilityofmodelingcom-\\n\\nplicatedmatchingpatternsthatwerenotcaptured\\n\\nbyclassicalsystems. Vocabulary mismatch in COIL can also be\\n\\nlargely mitigated with a high-level CLS vector\\n\\nmatching. The full system performs on par with\\n\\nmore expensive and complex all-to-all match re-\\n\\ntrievers. Thesuccessofthefullsystemalsoshows\\n\\nthatdenseretrievalandCOILsexacttokenmatch-\\n\\ninggivecomplementaryeffects,withCOILmaking\\n\\nupdensesystemslosttokenlevelmatchingsignals\\n\\nanddensesolvingthevocabularymismatchproba-\\n\\nblyforCOIL.References ECIR2021,VirtualEvent,March28-April1,2021,\\n\\nProceedings,PartI. S.Blackford,J.Demmel,J.Dongarra,I.Duff,S.Ham-\\n\\nmarling, Greg Henry, M. Hroux, L. Kaufman, An-\\n\\nJ. Guo, Y. Fan, Qingyao Ai, and W. Croft. 2016. A\\n\\ndrewLumsdaine,A.Petitet,R.Pozo,K.Remington,\\n\\ndeeprelevancematchingmodelforad-hocretrieval. andC.Whaley.2002. Anupdatedsetofbasiclinear\\n\\nProceedingsofthe25thACMInternationalonCon-\\n\\nalgebra subprograms (blas). ACM Transactions on\\n\\nference on Information and Knowledge Manage-\\n\\nMathematicalSoftware,28. ment. Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel\\n\\nCampos, and Ellen M Voorhees. 2020. Overview R.Guo,PhilipY.Sun,E.Lindgren,QuanGeng,David\\n\\nofthetrec2019deeplearningtrack. arXivpreprint Simcha, Felix Chern, and S. Kumar. 2019. Accel-\\n\\narXiv:2003.07820. eratinglarge-scaleinferencewithanisotropicvector\\n\\nquantization. arXiv: Learning. Zhuyun Dai and J. Callan. 2019a. Context-aware sen-\\n\\ntence/passage term importance estimation for first Charles R. Harris, K. Jarrod Millman, Stfan J\\n\\nstageretrieval. ArXiv,abs/1910.10687. vanderWalt,RalfGommers,PauliVirtanen,David\\n\\nCournapeau, Eric Wieser, Julian Taylor, Sebas-\\n\\nZhuyunDaiandJ.Callan.2020. Context-awaredocu- tian Berg, Nathaniel J. Smith, Robert Kern, Matti\\n\\nmenttermweightingforad-hocsearch. Proceedings Picus, Stephan Hoyer, Marten H. van Kerkwijk,\\n\\nofTheWebConference2020. MatthewBrett,AllanHaldane,JaimeFernndezdel\\n\\nRo, Mark Wiebe, Pearu Peterson, Pierre Grard-\\n\\nZhuyunDaiandJamieCallan.2019b. Deepertextun-\\n\\nMarchant, Kevin Sheppard, Tyler Reddy, Warren\\n\\nderstanding for IR with contextual neural language\\n\\nWeckesser, Hameer Abbasi, Christoph Gohlke, and\\n\\nmodeling. InProceedingsofthe42ndInternational\\n\\nTravisE.Oliphant.2020. Arrayprogrammingwith\\n\\nACM SIGIR Conference on Research and Develop-\\n\\nNumPy. Nature. ment in Information Retrieval, SIGIR 2019, Paris,\\n\\nFrance,July21-25,2019,pages985988.ACM. Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng,\\n\\nAlex Acero, and Larry Heck. 2013. Learning deep\\n\\nJ.Devlin,Ming-WeiChang,KentonLee,andKristina\\n\\nstructured semantic models for web search using\\n\\nToutanova.2019. Bert: Pre-trainingofdeepbidirec-\\n\\nclickthroughdata. InProceedingsofthe22ndACM\\n\\ntional transformers for language understanding. In\\n\\ninternational conference on Information & Knowl-\\n\\nNAACL-HLT. edgeManagement. Fernando Diaz, Bhaskar Mitra, and Nick Craswell. 2016. Query expansion with locally-trained word Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux,\\n\\nembeddings. In Proceedings of the 54th Annual and J. Weston. 2020. Poly-encoders: Architec-\\n\\nMeeting of the Association for Computational Lin- turesandpre-trainingstrategiesforfastandaccurate\\n\\nguistics. multi-sentencescoring. InICLR. Debasis Ganguly, Dwaipayan Roy, Mandar Mitra, J. Johnson, M. Douze, and H. Jgou. 2017. Billion-\\n\\nand Gareth J. F. Jones. 2015. Word embedding scale similarity search with gpus. ArXiv,\\n\\nbased generalized language model for information abs/1702.08734. retrieval. In Proceedings of the 38th International\\n\\nACM SIGIR Conference on Research and Develop- V. Karpukhin, Barlas Oguz, Sewon Min, Patrick\\n\\nmentinInformationRetrieval. Lewis, Ledell Yu Wu, Sergey Edunov, Danqi\\n\\nChen, and W. Yih. 2020. Dense passage re-\\n\\nLuyuGao,ZhuyunDai,andJamieCallan.2020. Mod-\\n\\ntrievalforopen-domainquestionanswering. ArXiv,\\n\\nularized transfomer-based ranking framework. In\\n\\nabs/2004.04906. Proceedings of the 2020 Conference on Empirical\\n\\nMethods in Natural Language Processing, EMNLP\\n\\nO. Khattab and M. Zaharia. 2020. Colbert: Efficient\\n\\n2020, Online, November 16-20, 2020. Association\\n\\nandeffectivepassagesearchviacontextualizedlate\\n\\nforComputationalLinguistics. interactionoverbert. Proceedingsofthe43rdInter-\\n\\nnational ACM SIGIR Conference on Research and\\n\\nLuyuGao,ZhuyunDai,andJamieCallan.2021a. Re-\\n\\nDevelopmentinInformationRetrieval. think training of BERT rerankers in multi-stage re-\\n\\ntrieval pipeline. In Advances in Information Re-\\n\\ntrieval-43rdEuropeanConferenceonIRResearch, Yoon Kim. 2014. Convolutional neural networks for\\n\\nECIR2021,VirtualEvent,March28-April1,2021, sentenceclassification. InEMNLP. Proceedings,PartII. JohnLaffertyandChengxiangZhai.2001. Document\\n\\nLuyuGao,ZhuyunDai,TongfeiChen,ZhenFan,Ben- languagemodels,querymodels,andriskminimiza-\\n\\njamin Van Durme, and Jamie Callan. 2021b. Com- tionforinformationretrieval. InProceedingsofthe\\n\\nplementlexicalretrievalmodelwithsemanticresid- 24th Annual International ACM SIGIR Conference\\n\\nual embeddings. In Advances in Information Re- on Research and Development in Information Re-\\n\\ntrieval-43rdEuropeanConferenceonIRResearch, trieval.VictorLavrenkoandW.BruceCroft.2001. Relevance- model for probabilistic weighted retrieval. In Pro-\\n\\nbasedlanguagemodels. InProceedingsofthe24th ceedings of the 17th Annual International ACM-\\n\\nAnnualInternationalACMSIGIRConferenceonRe- SIGIRConferenceonResearchandDevelopmentin\\n\\nsearchandDevelopmentinInformationRetrieval. InformationRetrieval. Y. Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\\n\\nJoshi, Danqi Chen, Omer Levy, M. Lewis, Luke Uszkoreit,LlionJones,AidanN.Gomez,L.Kaiser,\\n\\nZettlemoyer, and Veselin Stoyanov. 2019. Roberta: andIlliaPolosukhin.2017. Attentionisallyouneed. A robustly optimized bert pretraining approach. InNIPS. ArXiv,abs/1907.11692. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien\\n\\nChaumond, ClementDelangue, AnthonyMoi, Pier-\\n\\nYi Luan, Jacob Eisenstein, Kristina Toutanova, and\\n\\nric Cistac, Tim Rault, Rmi Louf, Morgan Funtow-\\n\\nM. Collins. 2020. Sparse, dense, and atten-\\n\\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\\n\\ntional representations for text retrieval. ArXiv,\\n\\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\\n\\nabs/2005.00181. Teven Le Scao, Sylvain Gugger, Mariama Drame,\\n\\nQuentin Lhoest, and Alexander M. Rush. 2019. SeanMacAvaney,F.Nardini,R.Perego,N.Tonellotto,\\n\\nHuggingfacestransformers: State-of-the-artnatural\\n\\nNazliGoharian,andO.Frieder.2020. Efficientdoc-\\n\\nlanguageprocessing. ArXiv,abs/1910.03771. umentre-rankingfortransformersbyprecomputing\\n\\ntermrepresentations. Proceedingsofthe43rdInter-\\n\\nChenyan Xiong, Zhuyun Dai, J. Callan, Zhiyuan Liu,\\n\\nnational ACM SIGIR Conference on Research and\\n\\nandR.Power.2017. End-to-endneuralad-hocrank-\\n\\nDevelopmentinInformationRetrieval. ing with kernel pooling. Proceedings of the 40th\\n\\nInternational ACM SIGIR Conference on Research\\n\\nDonaldMetzlerandW.BruceCroft.2005. Amarkov\\n\\nandDevelopmentinInformationRetrieval. randomfieldmodelfortermdependencies. InSIGIR\\n\\n2005: Proceedingsofthe28thAnnualInternational\\n\\nLee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang,\\n\\nACM SIGIR Conference on Research and Develop-\\n\\nJ.Liu,P.Bennett,JunaidAhmed,andArnoldOver-\\n\\nmentinInformationRetrieval. wijk.2020. Approximatenearestneighbornegative\\n\\ncontrastive learning for dense text retrieval. ArXiv,\\n\\nTomas Mikolov, Ilya Sutskever, Kai Chen, G. S. Cor-\\n\\nabs/2007.00808. rado,andJ.Dean.2013. Distributedrepresentations\\n\\nofwordsandphrasesandtheircompositionality. In Z. Yang, Zihang Dai, Yiming Yang, J. Carbonell,\\n\\nNIPS. R. Salakhutdinov, and Quoc V. Le. 2019. Xlnet:\\n\\nGeneralizedautoregressivepretrainingforlanguage\\n\\nRodrigoNogueiraandKyunghyunCho.2019. Passage understanding. InNeurIPS. re-rankingwithbert. ArXiv,abs/1901.04085. Rodrigo Nogueira and Jimmy Lin. 2019. From\\n\\ndoc2querytodoctttttquery. Adam Paszke, Sam Gross, Francisco Massa, Adam\\n\\nLerer, James Bradbury, Gregory Chanan, Trevor\\n\\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\\n\\nAntiga, Alban Desmaison, Andreas Kopf, Edward\\n\\nYang, ZacharyDeVito, MartinRaison, AlykhanTe-\\n\\njani,SasankChilamkurthy,BenoitSteiner,LuFang,\\n\\nJunjie Bai, and Soumith Chintala. 2019. Py-\\n\\ntorch: An imperative style, high-performance deep\\n\\nlearning library. In H. Wallach, H. Larochelle,\\n\\nA.Beygelzimer,F.d\\'Alch-Buc,E.Fox,andR.Gar-\\n\\nnett, editors, Advances in Neural Information Pro-\\n\\ncessingSystems32.CurranAssociates,Inc. Jeffrey Pennington, R. Socher, and Christopher D.\\n\\nManning.2014. Glove:Globalvectorsforwordrep-\\n\\nresentation. InEMNLP. MatthewE.Peters,MarkNeumann,MohitIyyer,Matt\\n\\nGardner, Christopher Clark, Kenton Lee, and Luke\\n\\nZettlemoyer.2018. Deepcontextualizedwordrepre-\\n\\nsentations. ArXiv,abs/1802.05365. Stephen E Robertson and Steve Walker. 1994. Some\\n\\nsimple effective approximations to the 2-poissonA Appendix\\n\\nA.1 IndexBuildingIllustration\\n\\nThe following figure demonstrates how the document \"apple pie baked ...\" is indexed by COIL. The\\n\\ndocumentisfirstprocessedbyafine-tuneddeepLMtoproduceforeachtokenacontextualizedvector. Thevectorsofeachterm\"apple\"and\"juice\"arecollectedtothecorrespondinginvertedlistindexalong\\n\\nwiththedocumentidforlookup. Document #10 - apple pie baked ...\\n\\napple pie baked\\n\\nLM\\n\\nu apple v pie w baked\\n\\n10\\n\\nuv\\n\\n10\\n\\napple\\n\\nvv\\n\\n10\\n\\npie\\n\\nwv\\n\\nbaked\\n\\nFigure4: COILIndexBuildingofdocument\"applepiebaked...\"A.2 SearchIllustration\\n\\nThefollowingfiguredemonstrateshowthequery\"applejuice\"isprocessedbyCOIL.Contextualized\\n\\nvectorsofeachterm\"apple\"and\"juice\"gotothecorrespondinginvertedlistindexconsistingofalookup\\n\\nidarrayandamatrixstackedfromdocumenttermvectors. Foreachindex,amatrixvectorproductisrun\\n\\ntoproduceanarrayofscores. Afterwardsamax-scatterofscoresfollowedbyasortproducesthefinal\\n\\nranking. Noteforeachindex,weshowonlyoperationsforasubsetofvectors(3vectors)intheindex\\n\\nmatrix. Query: apple juice\\n\\nIndex Index\\n\\napple juice\\n\\n677 579\\n\\nv u v w\\n\\nMatrix Vector Product\\n\\nxyz Score pqr Score\\n\\n677 Idx 579 Idx\\n\\nxyz Score pqr Score\\n\\nMax Scatter\\n\\nSort\\n\\nSorting\\n\\nFigure5: COILSearchofquery\"applejuice\".A Few Brief Notes on DeepImpact, COIL, and a Conceptual\\n\\nFramework for Information Retrieval Techniques\\n\\nJimmyLin and XueguangMa\\n\\nDavidR.CheritonSchoolofComputerScience\\n\\nUniversityofWaterloo\\n\\nAbstract Dense Sparse\\n\\nSupervised DPR,ANCE DeepImpact,COIL\\n\\nUnsupervised LSI,LDA BM25,tfidf\\n\\nRecentdevelopmentsinrepresentationallearn-\\n\\ningforinformationretrievalcanbeorganized Table 1: Our conceptual framework for organizing re-\\n\\ninaconceptualframeworkthatestablishestwo centdevelopmentsininformationretrieval. 1202\\n\\npairsofcontrasts:sparsevs.denserepresenta-\\n\\ntionsandunsupervisedvs.learnedrepresenta-\\n\\ntions. Sparse learned representations can fur- et al., 2021), can be understood as learned dense\\n\\nther be decomposed into expansion and term\\n\\nrepresentations for retrieval. This is formulated nuJ\\n\\nweighting components. This framework al-\\n\\nas a representational learning problem where the\\n\\nlowsustounderstandtherelationshipbetween\\n\\ntaskistolearn(transformer-based)encodersthat\\n\\nrecently proposed techniques such as DPR, 82\\n\\nmapqueriesanddocumentsintodensefixed-width\\n\\nANCE,DeepCT,DeepImpact,andCOIL,and\\n\\nfurthermore, gaps revealed by our analysis vectors(768dimensionsistypical)inwhichinner\\n\\n]RI.sc[\\n\\npoint to low hanging fruit in terms of tech- productsbetweenqueriesandrelevantdocuments\\n\\nniquesthathaveyettobeexplored.Wepresent aremaximized,basedonsupervisionsignalsfrom\\n\\nanoveltechniquedubbeduniCOIL,asimple\\n\\na large dataset such as the MS MARCO passage\\n\\nextensionofCOILthatachievestoourknowl-\\n\\nrankingtestcollection(Bajajetal.,2018). SeeLin\\n\\nedge the current state-of-the-art in sparse re-\\n\\netal.(2020)forasurvey. trieval on the popular MS MARCO passage 1v70841.6012:viXra\\n\\nDense retrieval techniques are typically com-\\n\\nranking dataset. Our implementation using\\n\\nthe Anserini IR toolkit is built on the Lucene paredagainstabag-of-wordsexactmatchranking\\n\\nsearch library and thus fully compatible with modelsuchasBM25,whichinthiscontextcanbe\\n\\nstandardinvertedindexes. understood as unsupervised sparse retrieval. Al-\\n\\nthough it may be unnatural to describe BM25 in\\n\\n1 Introduction\\n\\nthisway,itistechnicallyaccurate:eachdocument\\n\\nisrepresentedbyasparsevectorwhereeachdimen-\\n\\nWepresentanovelconceptualframeworkforun-\\n\\nsioncorrespondstoauniqueterminthevocabulary,\\n\\nderstandingrecentdevelopmentsininformationre-\\n\\nandthescoringfunctionassignsaweighttoeachdi-\\n\\ntrievalthatorganizestechniquesalongtwodimen-\\n\\nmension. Aswithdenseretrieval,querydocument\\n\\nsions. Thefirstdimensionestablishesthecontrast\\n\\nscoresarecomputedviainnerproducts. between sparse and dense vector representations\\n\\nfor queries and documents.1 The second dimen- Whataboutlearnedsparseretrieval? Themost\\n\\nsionestablishesthecontrastbetweenunsupervised prominentrecentexampleofthisintheliterature\\n\\nandlearned(supervised)representations. Figure1 is DeepCT (Dai and Callan, 2019), which uses\\n\\nillustratesourframework. atransformertolearntermweightsbasedonare-\\n\\ngressionmodel,withthesupervisionsignalcoming\\n\\nRecentproposalsfordenseretrieval,exemplified\\n\\nfromtheMSMARCOpassagerankingtestcollec-\\n\\nbyDPR(Karpukhinetal.,2020)andANCE(Xiong\\n\\ntion.2 DeepCThasaninterestingquirk:intruth,\\n\\net al., 2021), but also encompassing many other\\n\\nit only learns the term frequency (tf) component\\n\\ntechniques (Gao et al., 2021b; Hofsttter et al.,\\n\\nof term weights, but still relies on the remaining\\n\\n2020;Quetal.,2021;Hofsttteretal.,2021;Lin\\n\\n1Consistent with parlance in information retrieval, we use 2Learningsparserepresentationsisbynomeansanewidea. documentthroughoutthispaperinagenericsensetoreferto TheearliestexampleweareawareofisWilbur(2001),who\\n\\ntheunitofretrievedtext.Tobemoreprecise,ourexperiments attemptedtolearnglobaltermweightsusingTRECdata,but\\n\\nareinfactfocusedonpassageretrieval. theidealikelydatesbackevenfurther.parts of the BM25 scoring function via the gen- LDA(WeiandCroft,2006),whichhavebeenprevi-\\n\\nerationofpseudo-documents. Thisapproachalso ouslyexplored. Thus,allquadrantsinourproposed\\n\\nhas a weakness: it only assigns weights to terms conceptualframeworkarepopulatedwithknown\\n\\nthat are already present in the document, which examplesfromtheliterature. limits retrieval to exact match. This is an impor-\\n\\n2 CommentsandObservations\\n\\ntantlimitationthatisaddressedbytheuseofdense\\n\\nrepresentations,whicharecapableofcapturingse-\\n\\nBasedonthisframework,wecanmakeanumberof\\n\\nmanticmatches. interestingobservationsthathighlightobviousnext\\n\\nThesetwoissueswereresolvedbytherecently steps in the development of retrieval techniques. proposedDeepImpactmodel(Malliaetal.,2021), Wediscussasfollows:\\n\\nwhichalsobelongsinthefamilyoflearnedsparse Choiceofbases. Retrievaltechniquesusinglearned\\n\\nrepresentations. DeepImpactbroughttogethertwo denserepresentationsandlearnedsparserepresen-\\n\\nkeyideas:theuseofdocumentexpansiontoiden- tations present an interesting contrast. Nearly all\\n\\ntify dimensions in the sparse vector that should recentproposalstakeadvantageoftransformers,so\\n\\nhavenon-zeroweightsandatermweightingmodel thataspectofthedesignisnotasalientdifference. basedonapairwiselossbetweenrelevantandnon- Thecriticalcontrastisthebasisofthevectorrep-\\n\\nrelevant texts with respect to a query. Expansion resentations:Insparseapproaches,thebasisofthe\\n\\ntermswereidentifiedbydoc2queryT5(Nogueira vectorspaceremainsfixedtothecorpusvocabulary,\\n\\nandLin,2019),asequence-to-sequencemodelfor and thus techniques such as DeepCT, COIL, and\\n\\ndocumentexpansionthatpredictsqueriesforwhich DeepImpactcanbeunderstoodastermweighting\\n\\na text would be relevant. Since the DeepImpact models. In dense approaches, the model is given\\n\\nscoringmodeldirectlypredictstermweightsthat the freedom to choose a new basis derived from\\n\\nare then quantized, it would be more accurate to transformerrepresentations. Thischangeinbasis\\n\\ncall these weights learned impacts, since query allowstheencodertorepresentthemeaningof\\n\\ndocumentscoresaresimplythesumofweightsof textsinrelativelysmallfixed-widthvectors(com-\\n\\ndocumenttermsthatarefoundinthequery. Calling paredtosparsevectorsthatmayhavemillionsof\\n\\ntheseimpactscoresdrawsanexplicitconnectionto dimensions). This leads us to the next important\\n\\nathreadofresearchininformationretrievaldating observation:\\n\\nbacktwodecades(Anhetal.,2001). Expansions for sparse representation. Without\\n\\nTherecentlyproposedCOILarchitecture(Gao someformofexpansion,learnedsparserepresen-\\n\\netal.,2021a)presentsaninterestingcaseforthis tations remain limited to (better) exact matching\\n\\nconceptualframework. Wheredoesitbelong? The between queries and documents. The nature of\\n\\nauthors themselves describe COIL as a new ex- sparserepresentationsmeansthatitisimpractical\\n\\nactlexicalmatchretrievalarchitecturearmedwith to consider non-zero weights for all elements in\\n\\ndeepLMrepresentations. COILproducesrepre- thevector(i.e.,thevocabularyspace). Thus,docu-\\n\\nsentations for each document token that are then mentexpansionservesthecriticalroleofproposing\\n\\ndirectly stored in the inverted index, where the a set of candidate terms that should receive non-\\n\\nterm frequency usually goes in an inverted list. zeroweights;sincethenumberofcandidateterms\\n\\nAlthough COIL is perhaps best described as the is small compared to the vocabulary size, the re-\\n\\nintellectualdescendantofColBERT(Khattaband sultingvectorremainssparse. Withoutexpansion,\\n\\nZaharia,2020),anotherwaytothinkaboutitwithin learnedsparserepresentationscannotaddressthe\\n\\nourconceptualframeworkisthatinsteadofassign- vocabularymismatchproblem(Furnasetal.,1987),\\n\\ningscalarweightstotermsinaquery,thescoring becausedocumenttermsnotpresentinthequery\\n\\nmodelassignseachtermavectorweight. Query cannotcontributeanyscore. ForDeepImpact,this\\n\\nevaluation in COIL involves accumulating inner expansion is performed bydoc2queryT5, but in\\n\\nproductsinsteadofscalarweights. principlewecanimagineothermethodsalso. This\\n\\nOur conceptual framework highlights a final leadsustothenextimportantobservation:\\n\\nclassoftechniques:unsuperviseddenserepresen- RelatingDeepCT,DeepImpact,andCOIL.Theup-\\n\\ntations. Whilethereislittleworkinthisspaceof shot of the above analysis is that retrieval tech-\\n\\nlate,itdoesdescribetechniquessuchasLSI(Deer- niques based on learned sparse representations\\n\\nwester et al., 1990; Atreya and Elkan, 2010) and should be divided into an expansion model andSparseRepresentations MRR@10 Notes\\n\\nTermWeighting Expansion\\n\\n(1a) BM25 None 0.184 copiedfrom(NogueiraandLin,2019)\\n\\n(1b) BM25 doc2queryT5 0.277 copiedfrom(NogueiraandLin,2019)\\n\\n(2a) DeepCT None 0.243 copiedfrom(DaiandCallan,2019)\\n\\n(2b) DeepCT doc2queryT5 ? nopubliclyreportedfigure\\n\\n(2c) DeepImpact None ? nopubliclyreportedfigure\\n\\n(2d) DeepImpact doc2queryT5 0.326 copiedfrom(Malliaetal.,2021)\\n\\n(2e) COIL-tok(d=32) None 0.341 copiedfrom(Gaoetal.,2021a)\\n\\n(2f) COIL-tok(d=32) doc2queryT5 0.361 ourexperiment\\n\\n(2g) uniCOIL None 0.315 ourexperiment\\n\\n(2h) uniCOIL doc2queryT5 0.352 ourexperiment\\n\\nDenseRepresentations MRR@10 Notes\\n\\n(3a) ColBERT 0.360 copiedfrom(KhattabandZaharia,2020)\\n\\n(3b) ANCE 0.330 copiedfrom(Xiongetal.,2021)\\n\\n(3c) DistillBERT 0.323 copiedfrom(Hofsttteretal.,2020)\\n\\n(3d) RocketQA 0.370 copiedfrom(Quetal.,2021)\\n\\n(3e) TAS-B 0.347 copiedfrom(Hofsttteretal.,2021)\\n\\n(3f) TCT-ColBERTv2 0.359 copiedfrom(Linetal.,2021)\\n\\nDenseSparseHybrids MRR@10 Notes\\n\\n(4a) CLEAR 0.338 copiedfrom(Gaoetal.,2021b)\\n\\n(4b) COIL-full 0.355 copiedfrom(Gaoetal.,2021a)\\n\\n(4c) TCT-ColBERTv2+BM25(1a) 0.369 copiedfrom(Linetal.,2021)\\n\\n(4d) TCT-ColBERTv2+doc2queryT5(1b) 0.375 copiedfrom(Linetal.,2021)\\n\\n(4e) TCT-ColBERTv2+DeepImpact(2d) 0.378 ourexperiment\\n\\n(4f) TCT-ColBERTv2+uniCOIL(2h) 0.378 ourexperiment\\n\\n(4g) TCT-ColBERTv2+COIL(2f) 0.382 ourexperiment\\n\\nTable2: ResultsonthedevelopmentqueriesoftheMSMARCOpassagerankingtask. a term weighting model. For example, DeepCT andhenceunsupervised. Learnedsparseretrieval\\n\\nperformsnoexpansionandusesaregression-based techniques are shown in row group (2). Separat-\\n\\nscoringmodel. DeepImpactperformsdocumentex- ing the term weighting component from the ex-\\n\\npansionandusesapairwisescoringmodel. COIL pansion component allows us to identify gaps in\\n\\nperformsnoexpansionandusesascoringmodel modelconfigurationsthatwouldbeinterestingto\\n\\nthatgeneratesacontextualizedweightvector(in- explore. For example, in row (2a), DeepCT pro-\\n\\nsteadofascalarweight). Thisbreakdownsuggests posed a regression-based term weighting model,\\n\\nanumberofobviousexperimentsthathelpusun- but performed no expansion. However, the term\\n\\nderstand the contributions of these components, weightingmodelcanbeappliedtoexpandeddoc-\\n\\nwhichwereportnext. uments, as in row (2b); to our knowledge, this\\n\\nconfigurationhasnotbeenpubliclyreported. 3 Experiments\\n\\nSimilarly,DeepImpactcombineddoc2queryT5\\n\\nOurproposedconceptualframeworkcanbeused asanexpansionmodelandatermweightingmodel\\n\\nto organize results from the literature, which are trained with pairwise loss. To better understand\\n\\nshown in Table 2 on the development queries of the contributions of each component, we could\\n\\ntheMSMARCOpassagerankingtask(Bajajetal., run the term weighting model without document\\n\\n2018). Someoftheseentriesrepresentfiguresdi- expansion, as outlined in row (2c). This ablation\\n\\nrectlycopiedfrompreviouspapers(withreferences experimentwasnotreportedinMalliaetal. (2021),\\n\\nshown),whileothersarenovelexperimentalcondi- butwouldbeinterestingtoconduct. tionsthatwereport. In row (2e) we report the published results of\\n\\nThefirstmainblockofthetableshowsretrieval COIL-tok(tokendimensiond = 32),whichisthe\\n\\nwith sparse representations. Row (1a) shows the sparsecomponentinthefullCOILmodel(which\\n\\nBM25baseline,androw(1b)providestheeffective- is a densesparse hybrid). Through the lens of\\n\\nnessofdoc2queryT5expansion. Inbothcases,the ourconceptualframework,anumberofextensions\\n\\ntermweightsarefromtheBM25scoringfunction, becomeimmediatelyobvious. COILcanbecom-binedwithdoc2queryT5. Usingsourcecodepro- that ColBERT (Khattab and Zaharia, 2020) uses\\n\\nvided by the authors,3 we trained such a model themoreexpressiveMaxSimoperatortocompare\\n\\nfrom scratch, using the same hyperparameters as queryanddocumentrepresentations;allothertech-\\n\\ntheauthors. Thisvariantleadstoanearlytwo-point niquesuseinnerproducts. gainineffectiveness,asshowninrow(2f). ThefinalblockofTable2presentstheresultsof\\n\\nInanotherinterestingextension,ifwereducethe densesparse hybrids. Lin et al. (2021) reported\\n\\ntokendimensionofCOILtoone,themodeldegen- the results of densesparse hybrids when TCT-\\n\\nerates into producing scalar weights, which then ColBERTv2, row (3f), is combined with BM25,\\n\\nbecomesdirectlycomparabletoDeepCT,row(2a) row (1a), and doc2queryT5, row (1b). To this,\\n\\nandtheno-expansionvariantofDeepImpact,row weaddedfusionwithDeepImpact,uniCOIL,and\\n\\n(2c). Thesecomparisonsisolatetheeffectsofdiffer- COIL-tok(d = 32). Forafaircomparison,wefol-\\n\\nenttermweightingmodels. Wedubthisvariantof lowedthesametechniqueforcombiningdenseand\\n\\nCOILuniCOIL,ontopofwhichwecanalsoadd sparseresultsasLinetal. (2021),whichisfromMa\\n\\ndoc2queryT5,whichproducesafaircomparison etal.(2021). Foreachqueryq,weusedthecorre-\\n\\ntoDeepImpact,row(2d). Theoriginalformulation sponding dense and sparse techniques to retrieve\\n\\nof COIL, even with a token dimension of one, is top-1kdocuments. Thefinalfusionscoreofeach\\n\\nnot directly amenable to retrieval using inverted documentiscalculatedbys +s . Since\\n\\ndense sparse\\n\\nindexes because weights can be negative. To ad- therangeofthetwodifferentscoresarequitediffer-\\n\\ndress this issue, we added a ReLU operation on ent,wefirstnormalizedthescoresintorange(0,1). theoutputtermweightsofthebaseCOILmodelto The wastunedintherange(0, 2)withasimple\\n\\nforcethemodeltogeneratenon-negativeweights. linesearchonasubsetoftheMSMARCOpassage\\n\\nOnceagain, weretrainedthemodelfromscratch trainingset. using the same hyperparameters provided by the With these hybrid combinations, we are able\\n\\nauthors. Whenencodingthecorpus,wequantized toachieve,toourknowledge,thehighestreported\\n\\nthese weights into 8 bits to obtain impact scores; scoresontheMSMARCOpassagerankingtaskfor\\n\\nqueryweightsaresimilarlyquantized. Afterthese single-stagetechniques(i.e.,noreranking). Note\\n\\nmodifications,uniCOILisdirectlycompatiblewith that, as before, uniCOIL is compatible with stan-\\n\\ninvertedindexes. Ourexperimentalresultsarere- dardinvertedindexes,unlikeCOIL-tok,whichre-\\n\\nportedwiththeAnserinitoolkit(Yangetal.,2017, quirescustominfrastructure. 2018),whichisbuiltonLucene. ItisnosurprisethatuniCOILwithoutdoc2query 4 NextSteps\\n\\nT5,row(2g),islesseffectivethanCOIL-tok(d =\\n\\nInmostrecentwork,denseretrievaltechniquesare\\n\\n32),row(2e). However,uniCOILwithdoc2query\\n\\ncomparedtoBM25andexperimentsshowthatthey\\n\\nT5,row(2h),outperformsCOIL-tokwithoutneed-\\n\\nhandily win. However, this is not a fair compari-\\n\\ning any specialized retrieval infrastructurethe\\n\\nson, sinceBM25isunsupervised, whereasdense\\n\\nweightsarejustimpactscores,likeinDeepImpact. retrieval techniques exploit supervised relevance\\n\\nTheseresultssuggestthatcontextualizedweight\\n\\nsignals from large datasets. A more appropriate\\n\\nvectorsinCOILarentnecessarytoachievegood\\n\\ncomparison would be between learned dense vs.\\n\\neffectivenessaddingexpansionappearssufficient\\n\\nsparse representationsand there, no clear win-\\n\\ntomakeupforthelostexpressivityofweightvec-\\n\\nner emerges at present. However, it seems clear\\n\\ntors, as shown in row (2h) vs. row (2e). To our\\n\\nthattheyarecomplementary,ashybridapproaches\\n\\nknowledge, our uniCOIL model, row(2h), repre-\\n\\nappeartobemoreeffectivethaneitheralone. sents the state of the art in sparse retrieval using\\n\\nAn important point to make here is that neu-\\n\\nlearned impact weights, beating DeepImpact by\\n\\nral networks, particularly transformers, have not\\n\\naroundtwopoints. madesparserepresentationsobsolete. Bothdense\\n\\nThe second main block of Table 2 provides a\\n\\nandsparselearnedrepresentationsclearlyexploit\\n\\nnumberofcomparabledenseretrievalresultsfrom\\n\\ntransformersthe trick is that the latter class of\\n\\ntheliterature. Thehighestscorethatweareaware\\n\\ntechniquesthenprojectsthelearnedknowledge\\n\\nofisRocketQA(Quetal.,2021),whoseeffective-\\n\\nback into the sparse vocabulary space. This al-\\n\\nness beatsall knownsparse configurations. Note\\n\\nlowsustoreusedecadesofinnovationininverted\\n\\n3https://github.com/luyug/COIL indexes (e.g., integer coding techniques to com-pressinvertedlists)andefficientqueryevaluation Indexing by latent semantic analysis. Journal of\\n\\nalgorithms (e.g., smart skipping to reduce query theAssociationforInformationScience,41(6):391\\n\\n407.\\n\\nlatency): for example, the Lucene index used in\\n\\nour uniCOIL experiments is only 1.3 GB, com- George W. Furnas, Thomas K. Landauer, Louis M.\\n\\npared to 40 GB for COIL-tok, 26 GB for TCT- Gomez, and Susan T. Dumais. 1987. The vo-\\n\\ncabularyprobleminhuman-systemcommunication. ColBERTv2,and154GBforColBERT.Wenote,\\n\\nCommunicationsoftheACM,30(11):964971.\\n\\nhowever,thatwithdenseretrievaltechniques,fixed-\\n\\nwidth vectors can be approximated with binary Luyu Gao, Zhuyun Dai, and Jamie Callan. 2021a. hashcodes,yieldingfarmorecompactrepresenta- COIL: Revisit exact lexical match in information\\n\\nretrieval with contextualized inverted list. In Pro-\\n\\ntionswithsacrificingmucheffectiveness(Yamada\\n\\nceedingsofthe2021ConferenceoftheNorthAmer-\\n\\netal.,2021). Onceagain,noclearwinneremerges ican Chapter of the Association for Computational\\n\\natpresent. Linguistics: Human Language Technologies, pages\\n\\nThecompletedesignspaceofmoderninforma- 30303042.\\n\\ntionretrievaltechniquesrequiresproperaccounting\\n\\nLuyuGao,ZhuyunDai,TongfeiChen,ZhenFan,Ben-\\n\\nofthetradeoffsbetweenoutputquality(effective- jamin Van Durme, and Jamie Callan. 2021b. Com-\\n\\nness),time(querylatency),andspace(indexsize). plementing lexical retrieval with semantic residual\\n\\nembedding. In Proceedings of the 43rd European\\n\\nHere, we have only focused on the first aspect. Conference on Information Retrieval (ECIR 2021),\\n\\nLearned representations for information retrieval\\n\\nPartI,pages146160. areclearlythefuture, buttheadvantagesanddis-\\n\\nadvantages of dense vs. sparse approaches along Sebastian Hofsttter, Sophia Althammer, Michael\\n\\nSchrder, Mete Sertkan, and Allan Hanbury. thesedimensionsarenotyetfullyunderstood. Itll\\n\\n2020. Improving efficient neural ranking mod-\\n\\nbeexcitingtoseewhatcomesnext! els with cross-architecture knowledge distillation. arXiv:2010.02666. 5 Acknowledgments\\n\\nSebastian Hofsttter, Sheng-Chieh Lin, Jheng-Hong\\n\\nThisresearchwassupportedinpartbytheCanada Yang, Jimmy Lin, and Allan Hanbury. 2021. Ef-\\n\\nFirstResearchExcellenceFundandtheNaturalSci- ficiently teaching an effective dense retriever with\\n\\nbalanced topic aware sampling. In Proceedings of\\n\\nencesandEngineeringResearchCouncil(NSERC)\\n\\nthe 44th Annual International ACM SIGIR Confer-\\n\\nofCanada. Computationalresourceswereprovided\\n\\nence on Research and Development in Information\\n\\nbyComputeOntarioandComputeCanada. Retrieval(SIGIR2021). VladimirKarpukhin,BarlasOguz,SewonMin,Patrick\\n\\nLewis,LedellWu,SergeyEdunov,DanqiChen,and\\n\\nReferences\\n\\nWen-tau Yih. 2020. Dense passage retrieval for\\n\\nVo Ngoc Anh, Owen de Kretser, and Alistair Moffat. open-domainquestionanswering. InProceedingsof\\n\\n2001. Vector-spacerankingwitheffectiveearlyter- the 2020 Conference on Empirical Methods in Nat-\\n\\nmination. In Proceedings of the 24th Annual Inter- ural Language Processing (EMNLP), pages 6769\\n\\nnational ACM SIGIR Conference on Research and 6781. DevelopmentinInformationRetrieval(SIGIR2001),\\n\\nOmarKhattabandMateiZaharia.2020. ColBERT:Ef-\\n\\npages3542,NewOrleans,Louisiana. ficient and effective passage search via contextual-\\n\\nAvinash Atreya and Charles Elkan. 2010. Latent se- ized late interaction over BERT. In Proceedings of\\n\\nmantic indexing (LSI) fails for TREC collections. the 43rd International ACM SIGIR Conference on\\n\\nSIGKDDExplorations,12(2):510. ResearchandDevelopmentinInformationRetrieval\\n\\n(SIGIR2020),pages3948. Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng,\\n\\nJianfeng Gao, Xiaodong Liu, Rangan Majumder, Jimmy Lin, Rodrigo Nogueira, and Andrew Yates. Andrew McNamara, Bhaskar Mitra, Tri Nguyen, 2020. Pretrained transformers for text ranking:\\n\\nMirRosenberg,XiaSong,AlinaStoica,SaurabhTi- BERTandbeyond. arXiv:2010.06467.\\n\\nwary, and Tong Wang. 2018. MS MARCO: A Hu-\\n\\nman Generated MAchine Reading COmprehension Sheng-Chieh Lin, Jheng-Hong Yang, and Jimmy Lin. Dataset. arXiv:1611.09268v3. 2021. In-batchnegativesforknowledgedistillation\\n\\nwithtightly-coupledteachersfordenseretrieval. In\\n\\nZhuyun Dai and Jamie Callan. 2019. Context-aware Proceedingsofthe6thWorkshoponRepresentation\\n\\nsentence/passage term importance estimation for LearningforNLP. firststageretrieval. arXiv:1910.10687. Xueguang Ma, Kai Sun, Ronak Pradeep, and Jimmy\\n\\nScottDeerwester,SusanT.Dumais,GeorgeW.Furnas, Lin.2021. Areplicationstudyofdensepassagere-\\n\\nThomasK.Landauer,andRichardHarshman.1990. triever. arXiv:2104.05740.Antonio Mallia, Omar Khattab, Torsten Suel, and\\n\\nNicolaTonellotto. 2021. Learningpassage impacts\\n\\nforinvertedindexes. InProceedingsofthe44thAn-\\n\\nnual International ACM SIGIR Conference on Re-\\n\\nsearch and Development in Information Retrieval\\n\\n(SIGIR2021). Rodrigo Nogueira and Jimmy Lin. 2019. From\\n\\ndoc2querytodocTTTTTquery. Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang\\n\\nRen, Wayne Xin Zhao, Daxiang Dong, Hua Wu,\\n\\nand Haifeng Wang. 2021. RocketQA: An opti-\\n\\nmized training approach to dense passage retrieval\\n\\nfor open-domain question answering. In Proceed-\\n\\nings of the 2021 Conference of the North Ameri-\\n\\ncan Chapter of the Association for Computational\\n\\nLinguistics: Human Language Technologies, pages\\n\\n58355847. XingWeiandW.BruceCroft.2006. LDA-baseddoc-\\n\\nument models for ad-hoc retrieval. In Proceedings\\n\\nof the 29th Annual International ACM SIGIR Con-\\n\\nference on Research and Development in Informa-\\n\\ntionRetrieval(SIGIR2006),pages178185,Seattle,\\n\\nWashington. W. John Wilbur. 2001. Global term weights for docu-\\n\\nmentretrievallearnedfromTRECdata. Journalof\\n\\nInformationScience,27(5):303310. Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang,\\n\\nJialin Liu, Paul N. Bennett, Junaid Ahmed, and\\n\\nArnoldOverwijk.2021. Approximatenearestneigh-\\n\\nbor negative contrastive learning for dense text re-\\n\\ntrieval. InProceedingsofthe9thInternationalCon-\\n\\nferenceonLearningRepresentations(ICLR2021). Ikuya Yamada, Akari Asai, and Hannaneh Ha-\\n\\njishirzi. 2021. Efficient passage retrieval with\\n\\nhashing for open-domain question answering. arXiv:2106.00882. PeilinYang,HuiFang,andJimmyLin.2017. Anserini:\\n\\nenablingtheuseofLuceneforinformationretrieval\\n\\nresearch. In Proceedings of the 40th Annual Inter-\\n\\nnational ACM SIGIR Conference on Research and\\n\\nDevelopmentinInformationRetrieval(SIGIR2017),\\n\\npages12531256,Tokyo,Japan. PeilinYang,HuiFang,andJimmyLin.2018. Anserini:\\n\\nreproduciblerankingbaselinesusingLucene. Jour-\\n\\nnal of Data and Information Quality, 10(4):Article\\n\\n16.Doc2Query--: When Less is More\\n\\nMitko Gospodinov1, Sean MacAvaney2, and Craig Macdonald2\\n\\nUniversity of Glasgow\\n\\n12024810G@student.gla.ac.uk\\n\\n2{first}. {last}@glasgow.ac.uk\\n\\n3202\\n\\nAbstract. Doc2Query  the process of expanding the content of a\\n\\ndocument before indexing using a sequence-to-sequence model  has\\n\\nemergedasaprominenttechniqueforimprovingthefirst-stageretrieval\\n\\nbeF\\n\\neffectivenessofsearchengines.However,sequence-to-sequencemodelsare\\n\\nknown to be prone to hallucinating content that is not present in the\\n\\nsource text. We argue that Doc2Query is indeed prone to hallucination,\\n\\nwhichultimatelyharmsretrievaleffectivenessandinflatestheindexsize. 72\\n\\nInthiswork,weexploretechniquesforfilteringouttheseharmfulqueries\\n\\npriortoindexing.Wefindthatusingarelevancemodeltoremovepoor-\\n\\n]RI.sc[\\n\\nquality queries can improve the retrieval effectiveness of Doc2Query by\\n\\nupto16%,whilesimultaneouslyreducingmeanqueryexecutiontimeby\\n\\n23% and cutting the index size by 33%. We release the code, data, and\\n\\nalivedemonstrationtofacilitatereproductionandfurtherexploration.1\\n\\n1 Introduction 3v66230.1032:viXra\\n\\nNeural network models, particularly those based on contextualised language\\n\\nmodels, have been shown to improve search effectiveness [3]. While some ap-\\n\\nproaches focus on re-ranking document sets from a first-stage retrieval function\\n\\nto improve precision [27], others aim to improve the first stage itself [4]. In this\\n\\nwork, we focus on one of these first-stage approaches: Doc2Query [29]. This ap-\\n\\nproachtrainsasequence-to-sequencemodel(e.g.,T5[33])topredictqueriesthat\\n\\nmay be relevant to a particular text. Then, when indexing, this model is used\\n\\nto expand the document by generating a collection of queries and appending\\n\\nthem to the document. Though computationally expensive at index time [34],\\n\\nthis approach has been shown to be remarkably effective even when retrieving\\n\\nusing simple lexical models like BM25 [28]. Numerous works have shown that\\n\\nthe approach can produce a high-quality pool of results that are effective for\\n\\nsubsequent stages in the ranking pipeline [19,20,23,40]. However, sequence-to-sequence models are well-known to be prone to gener-\\n\\nate content that does not reflect the input text  a defect known in literature\\n\\nas hallucination [25]. We find that existing Doc2Query models are no excep-\\n\\ntion. Figure 1 provides example generated queries from the state-of-the-art T5\\n\\nDoc2Query model [28]. In this example, we see that many of the generated\\n\\nqueries cannot actually be answered by the source passage (score  1). 1 https://github.com/terrierteam/pyterrier_doc2query2 Gospodinov et al. Original Passage: Barley (Hordeum vulgare L.), aGeneratedQueries:(1)wheredoesbarleyoriginate\\n\\nmemberofthegrassfamily,isamajorcerealgrain.Itfrom(2)whatisthenameofthecerealgrainused\\n\\nwasoneofthefirstcultivatedgrainsandisnowgrownintibetancooking? (3)whatisbarleyusedfor(1)\\n\\nwidely.BarleygrainisastapleinTibetancuisineandwhatisbarleyinfood(0)whatisbarewheat(3)\\n\\nwaseatenwidelybypeasantsinMedievalEurope.Bar-whatfamilyoforganismsisbarleyin(1)whyisbar-\\n\\nleyhasalsobeenusedasanimalfodder,asasourceley important in tibetan diet  (3) what is barley\\n\\noffermentablematerialforbeerandcertaindistilled(2)whereisbarleygrown(1)wherewasbarleyfirst\\n\\nbeverages,andasacomponentofvarioushealthfoods.grownandeaten(1)wherewasbarleyfirstused...\\n\\nFig.1. Example passage from MS MARCO and generated queries using the T5\\n\\nDoc2Query model. The relevance of each query to the passage is scored by the au-\\n\\nthors on a scale of 03 using the TREC Deep Learning passage relevance criteria. Based on this observation, we hypothesise that retrieval performance of\\n\\nDoc2Querywouldimproveifhallucinatedquerieswereremoved.Inthispaper,we\\n\\nconduct experiments where we apply a new filtering phase that aims to remove\\n\\npoor queries prior to indexing. Given that this approach removes queries, we\\n\\ncalltheapproachDoc2Query--(Doc2Query-minus-minus).Ratherthantraining\\n\\na new model for this task, we identify that relevance models are already fit for\\n\\nthis purpose: they estimate how relevant a passage is to a query. We therefore\\n\\nexplore filtering strategies that make use of existing neural relevance models. Through experimentation on the MS MARCO dataset, we find that our fil-\\n\\ntering approach can improve the retrieval effectiveness of indexes built using\\n\\nDoc2Query-- by up to 16%; less can indeed be more. Meanwhile, filtering nat-\\n\\nurally reduces the index size, lowering storage and query-time computational\\n\\ncosts.Finally,weconductanexplorationoftheindex-timeoverheadsintroduced\\n\\nbythefilteringprocessandconcludethatthegainsfromfilteringmorethanmake\\n\\nupfortheadditionaltimespentgeneratingmorequeries.Theapproachalsohas\\n\\na positive impact on the environmental costs of applying Doc2Query; the same\\n\\nretrieval effectiveness can be achieved with only about a third of the compu-\\n\\ntational cost when indexing. To facilitate last-metre, last-mile, and complete\\n\\nreproduction efforts [36], we release the code, indices, and filtering scores.1 In\\n\\nsummary, we contribute a technique to improve the effectiveness and efficiency\\n\\nof Doc2Query by filtering out queries that do not reflect the original passage. 2 Related Work\\n\\nThe classical lexical mismatch problem is a key one in information retrieval -\\n\\ndocuments that do not contain the query terms may not be retrieved. In the\\n\\nliterature,variousapproacheshaveaddressedthis:queryreformulationinclud-\\n\\ning stemming, query expansion models (e.g. Rocchio, Bo1 [1], RM3 [12])  and\\n\\ndocument expansion [9,30,35]. Classically, query expansion models have been\\n\\npopular, as they avoid the costs associated with making additional processing\\n\\nfor each document needed for document expansion. However, query expansion\\n\\nmay result in reduced performance [11], as queries are typically short and the\\n\\nnecessary evidence to understand the context of the user is limited.Doc2Query--: When Less is More 3\\n\\nThe application of latent representations of queries and documents, such\\n\\nas using latent semantic indexing [8] allow retrieval to not be driven directly\\n\\nby lexical signals. More recently, transformer-based language models (such as\\n\\nBERT [6]) have resulted in representations of text where the contextualised\\n\\nmeaning of words are accounted for. In particular, in dense retrieval, queries\\n\\nand documents are represented in embeddings spaces [14,37], often facilitated\\n\\nby Approximate Nearest Neighbour (ANN) data structures [13]. However, even\\n\\nwhen using ANN, retrieval can still be inefficient or insufficiently effective [15]. Othershaveexploredapproachesforaugmentinglexicalrepresentationswith\\n\\nadditionaltermsthatmayberelevant.Inthiswork,weexploreDoc2Query[29],\\n\\nwhich uses a sequence-to-sequence model that maps a document to queries that\\n\\nit might be able to answer. By appending these generated queries to a docu-\\n\\nments content before indexing, the document is more likely to be retrieved for\\n\\nuser queries when using a model like BM25. An alternative style of document\\n\\nexpansion, proposed by MacAvaney et al. [19] and since used by several other\\n\\nmodels (e.g., [10,39,40]), uses the built-in Masked Language Modelling (MLM)\\n\\nmechanism.MLMexpansiongeneratesindividualtokenstoappendtothedocu-\\n\\nmentasabagofwords(ratherthanasasequence).AlthoughMLMexpansionis\\n\\nalso prone to hallucination,2 the bag-of-words nature of MLM expansion means\\n\\nthat individual expansion tokens may not have sufficient context to apply fil-\\n\\ntering effectively. We therefore focus only on sequence-style expansion and leave\\n\\nthe exploration of MLM expansion for future work. 3 Doc2Query--\\n\\nDoc2Query-- consists of two phases: a generation phrase and a filtering phase. In the generation phase, a Doc2Query model generates a set of n queries that\\n\\neach document might be able to answer. However, as shown in Figure 1, not\\n\\nall of the queries are necessarily relevant to the document. To mitigate this\\n\\nproblem, Doc2Query-- then proceeds to a filtering phase, which is responsible\\n\\nfor eliminating the generated queries that are least relevant to the source doc-\\n\\nument. Because hallucinated queries contain details not present in the original\\n\\ntext (by definition), we argue that hallucinated queries are less useful for re-\\n\\ntrieval than non-hallucinated ones. Filtering is accomplished by retaining only\\n\\nthe most relevant p proportion of generated queries over the entire corpus. The\\n\\nretained queries are then concatenated to their corresponding documents prior\\n\\nto indexing, as per the existing Doc2Query approach. More formally, consider an expansion function e that maps a document to n\\n\\nqueries: e : D (cid:55) Qn. In Doc2Query, each document in corpus D are concate-\\n\\nnatedwiththeirexpansionqueries,forminganewcorpusD(cid:48) ={Concat(d,e(d))|\\n\\ndD},whichisthenindexedbyaretrievalsystem.Doc2Query--addsafiltering\\n\\nmechanism that uses a relevance model that maps a query and document to a\\n\\nreal-valued relevance score s:QD(cid:55)R (with larger values indicating higher\\n\\n2 Forinstance,wefindthatSPLADE[10]generatesthefollowingseemingly-unrelated\\n\\nterms for the passage in Figure 1 in the top 20 expansion terms: reed, herb, and troy.4 Gospodinov et al. relevance). The relevance scoring function is used to filter down the queries to\\n\\nthose that meet a certain score threshold t as follows:\\n\\nD(cid:48) =(cid:110) Concat(cid:0) d,(cid:8) q |q e(d)s(q,d)t(cid:9)(cid:1) |dD(cid:111) (1)\\n\\nThe relevance threshold t is naturally dependent upon the relevance scoring\\n\\nfunction. It can be set empirically, chosen based on operational criteria (e.g.,\\n\\ntargetindexsize),or(forawell-calibratedrelevancescoringfunction)determined\\n\\na priori. In this work, we combine the first two strategies: we pick t based on\\n\\nthe distribution of relevance scores across all expansion queries. For instance,\\n\\nat p = 0.3 we only keep queries with relevance scores in the top 30%, which is\\n\\nt=3.215fortheELECTRA[31]scoringmodelontheMSMARCOdataset[26]. 4 Experimental Setup\\n\\nWe conduct experiments to answer the following research questions:\\n\\nRQ1 Does Doc2Query-- improve the effectiveness of document expansion? RQ2 Whatarethetrade-offsintermsofeffectiveness,efficiency,andstoragewhen\\n\\nusing Doc2Query--? Datasets and Measures. We conduct tests using the MS MARCO [26] v1\\n\\npassage corpus. We use five test collections:3 (1) the MS MARCO Dev (small)\\n\\ncollection, consisting of 6,980 queries (1.1 qrels/query); (2) the Dev2 collection,\\n\\nconsistingof4,281(1.1qrels/query);(3)theMSMARCOEvalset,consistingof\\n\\n6,837queries(held-outleaderboardset);(4/5)theTRECDL19/20collections,\\n\\nconsisting of 43/54 queries (215/211 qrels/query). We evaluate using the official\\n\\ntask evaluation measures: Reciprocal Rank at 10 (RR@10) for Dev/Dev2/Eval,\\n\\nnDCG@10 for DL19/20. We tune systems4 on Dev, leaving the remaining col-\\n\\nlections as held-out test sets. Models.WeusetheT5Doc2QuerymodelfromNogueiraandLin[28],mak-\\n\\ning use of the inferred queries released by the authors (80 per passage). To the\\n\\nbest of our knowledge, this is the highest-performing Doc2Query model avail-\\n\\nable. We consider three neural relevance models for filtering: ELECTRA5 [31],\\n\\nMonoT56[32],andTCT-ColBERT7[16],coveringtwostrongcross-encodermod-\\n\\nels and one strong bi-encoder model. We also explored filters that use the prob-\\n\\nabilities from the generation process itself but found them to be ineffective and\\n\\ntherefore omit these results due to space constraints. ToolsandEnvironment.WeusethePyTerriertoolkit[22]withaPISA[24,17]\\n\\nindex to conduct our experiments. We deploy PISAs Block-Max WAND [7] im-\\n\\nplementation for BM25 retrieval. Inference was conducted on an NVIDIA 3090\\n\\nGPU. Evaluation was conducted using the ir-measures package [18]. 3 ir-datasets [21] IDs: msmarco-passage/dev/small, msmarco-passage/dev/2,\\n\\nmsmarco-passage/eval/small, msmarco-passage/trec-dl-2019/judged,\\n\\nmsmarco-passage/trec-dl-2020/judged 4 BM25s k1, b, and whether to\\n\\nremove stopwords were tuned for all systems; the filtering percentage (p)\\n\\nwas also tuned for filtered systems. 5 crystina-z/monoELECTRA_LCE_nneg31\\n\\n6 castorini/monot5-base-msmarco 7 castorini/tct_colbert-v2-hnp-msmarcoDoc2Query--: When Less is More 5\\n\\nTable 1. Effectiveness and efficiency measurements for Doc2Query-- and baselines. Significant differences between Doc2Query and their corresponding filtered versions\\n\\nfor Dev,Dev2, DL19 and DL20 areindicated with * (paired t-test,p<0.05). Values\\n\\nmarkedwitharetakenfromthecorrespondingsubmissionstothepublicleaderboard. RR@10 nDCG@10 ms/q GB\\n\\nSystem Dev Dev2 Eval DL19 DL20 MRT Index\\n\\nBM25 0.185 0.182 0.186 0.499 0.479 5 0.71\\n\\nDoc2Query (n=40) 0.277 0.265 0.272 0.626 0.607 30 1.17\\n\\nw/ ELECTRA Filter (30%) *0.316 *0.310 - 0.667 0.611 23 0.89\\n\\nw/ MonoT5 Filter (40%) *0.308 *0.298 0.306 0.650 0.611 29 0.93\\n\\nw/ TCT Filter (50%) *0.287 *0.280 - 0.640 0.599 30 0.94\\n\\nDoc2Query (n=80) 0.279 0.267 - 0.627 0.605 30 1.41\\n\\nw/ ELECTRA Filter (30%) *0.323 *0.316 0.325 0.670 0.614 23 0.95\\n\\nw/ MonoT5 Filter (40%) *0.311 *0.298 - 0.665 0.609 28 1.04\\n\\nw/ TCT Filter (50%) *0.293 *0.283 - 0.642 0.588 28 1.05\\n\\n5 Results\\n\\nWe first explore RQ1: whether relevance filtering can improve the retrieval of\\n\\nDoc2Query models. Table 1 compares the effectiveness of Doc2Query with var-\\n\\nious filters. We observe that all the filters significantly improve the retrieval\\n\\neffectiveness on the Dev and Dev2 datasets at both n=40 and n=80. We also\\n\\nobserve a large boost in performance on the Eval dataset.8 Though the differ-\\n\\nences inDL19 andDL20 appearto beconsiderable (e.g.,0.627 to0.670), these\\n\\ndifferences are not statistically significant. Diggingalittledeeper,Figure2showstheretrievaleffectivenessofDoc2Query\\n\\nwithvariousnumbersofgeneratedqueries(indottedblack)andthecorrespond-\\n\\ning performance when filtering using the top-performing ELECTRA scorer (in\\n\\nsolid blue). We observe that performing relevance filtering at each value of n\\n\\nimproves the retrieval effectiveness. For instance, keeping only 30% of expan-\\n\\nsion queries at n = 80, performance is increased from 0.279 to 0.323  a 16%\\n\\nimprovement. In aggregate, results from Table 1 and Figure 2 answer RQ1: Doc2Query--\\n\\nfilteringcansignificantlyimprovetheretrievaleffectivenessofDoc2Queryacross\\n\\nvarious scoring models, numbers of generated queries (n) and thresholds (p). Next,weexplorethetrade-offsintermsofeffectiveness,efficiency,andstorage\\n\\nwhen using Doc2Query--. Table 1 includes the mean response time and index\\n\\nsizes for each of the settings. As expected, filtering reduces the index size since\\n\\nfewertermsarestored.Forthebest-performingsetting(n=80withELECTRA\\n\\n8 Significancecannotbedeterminedduetotheheld-outnatureofthedataset.Further,\\n\\ndue to restrictions on the number of submissions to the leaderboard, we only are able\\n\\ntosubmittworuns.ThefirstaimstobeafaircomparisonwiththeexistingDoc2Query\\n\\nEval result, using the same number of generated queries and same base T5 model for\\n\\nscoring. The second is our overall best-performing setting, using the ELECTRA filter\\n\\nat n=80 generated queries.6 Gospodinov et al. 0.325 30% 40% 50%\\n\\n60%\\n\\n70% 80%Filte\\n\\n0.300 9r 0in %g Phase 01@RR\\n\\n0.275 n=40 n=80\\n\\nn=20\\n\\nn=10 Generation Phase\\n\\n0.250\\n\\nn=5\\n\\n0.225\\n\\n0 1 2 3 4 5\\n\\nTotal Tokens 1e9\\n\\nFig.2. Effectiveness (RR@10) on the Dev set, compared with the total number of\\n\\nindexed tokens. The generation phase is shown in dotted black (at various values of\\n\\nn), and the ELECTRA filtering phase is shown in solid blue (at various values of p). filter),thisamountstoa33%reductioninindexsize(1.41GBdownto0.95GB). Naturally, such a reduction has an impact on query processing time as well; it\\n\\nyields a 23% reduction in mean response time (30ms down to 23ms). Doc2Query-- filtering adds substantial cost an indexing time, mostly due to\\n\\nscoring each of the generated queries. Table 2 reports the cost (in hours of GPU\\n\\ntime) of the generation and filtering phases. We observe that ELECTRA filter-\\n\\ningcanyielduptoa78%increaseinGPUtime(n=10).However,wefindthat\\n\\nthe improved effectiveness makes up for this cost. To demonstrate this, we al-\\n\\nlocate the time spent filtering to generating additional queries for each passage. For instance, the 15 hours spent scoring n = 5 queries could instead be spent\\n\\ngenerating6morequeriesperpassage(foratotalofn=11).Wefindthatwhen\\n\\ncomparingagainstanunfilterednthatcloselyapproximatesthetotaltimewhen\\n\\nTable 2. Retrieval effectiveness comparison for comparable indexing computational\\n\\nbudgets(inhoursofGPUtime).Valuesofnwithoutafilterarechosentobestapprox-\\n\\nimate the total compute hours or the Dev effectiveness of the corresponding filtered\\n\\nversion. Significant differences between in RR@10 performance are indicated with *\\n\\n(paired t-test, p<0.05). GPU Hours RR@10\\n\\nn Filter Gen+Filt=Tot Dev Dev2 Comment\\n\\n5 ELECTRA 20 + 15 = 34 0.273 0.270\\n\\n11 None 34 + 0 = 34 *0.261 *0.256 4% Dev RR for sim. GPU hrs\\n\\n31 None 99 + 0 = 99 0.273 0.265 2.9 GPU hrs to match Dev RR\\n\\n10 ELECTRA 32 + 25 = 57 0.292 0.292\\n\\n18 None 59 + 0 = 59 *0.270 *0.260 8% Dev RR for sim. GPU hrs\\n\\n20 ELECTRA 66 + 47 = 113 0.307 0.303\\n\\n36 None 113 + 0 = 113 *0.275 *0.265 10% Dev RR for sim. GPU hrs\\n\\n40 ELECTRA 128 + 86 = 214 0.316 0.310\\n\\n68 None 216 + 0 = 216 *0.279 *0.267 12% Dev RR for sim. GPU hrsDoc2Query--: When Less is More 7\\n\\nfiltering, the filtered results consistently yield significantly higher retrieval effec-\\n\\ntiveness. As the computational budget increases, so does the margin between\\n\\nDoc2Query and Doc2Query--, from 4% at 34 hours up to 12% at 216 hours. From the opposite perspective, Doc2Query consumes 2.9 or more GPU\\n\\ntime than Doc2Query-- to achieve similar effectiveness (n = 13 with no filter\\n\\nvs. n = 5 with ELECTRA filter). Since the effectiveness of Doc2Query flattens\\n\\nout between n = 40 and n = 80 (as seen in Figure 2), it likely requires a\\n\\nmassiveamountofadditionalcomputetoreachtheeffectivenessofDoc2Query--\\n\\nat n10, if that effectiveness is achievable at all. These comparisons show that\\n\\nif a deployment is targeting a certain level of effectiveness (rather than a target\\n\\ncompute budget), Doc2Query-- is also preferable to Doc2Query. TheseresultscollectivelyanswerRQ2:Doc2Query--provideshighereffective-\\n\\nnessatlowerquery-timecosts,evenwhencontrollingfortheadditionalcompute\\n\\nrequired at index time. 6 Conclusions\\n\\nThisworkdemonstratedthatthereareuntappedadvantagesingeneratingnatural-\\n\\nlanguagefordocumentexpansion.Specifically,wepresentedDoc2Query--,which\\n\\nisanewapproachforimprovingtheeffectivenessandefficiencyoftheDoc2Query\\n\\nmodel by filtering out the least relevant queries. We observed that a 16% im-\\n\\nprovement in retrieval effectiveness can be achieved, while reducing the index\\n\\nsize by 33% and mean query execution time by 23%. The technique of filtering text generated from language models using rel-\\n\\nevance scoring is ripe for future work. For instance, relevance filtering could\\n\\npotentially apply to approaches that generate alternative forms of queries [38],\\n\\ntraining data [2], or natural language responses to queries [5]  all of which\\n\\narepotentiallyaffectedbyhallucinatedcontent.Furthermore,futureworkcould\\n\\nexplore approaches for relevance filtering over masked language modelling ex-\\n\\npansion [19], rather than sequence-to-sequence expansion. Acknowledgements\\n\\nSeanMacAvaneyandCraigMacdonaldacknowledgeEPSRCgrantEP/R018634/1:\\n\\nClosed-LoopDataScienceforComplex,Computationally-&Data-IntensiveAn-\\n\\nalytics. References\\n\\n1. Amati, G., Van Rijsbergen, C.J. : Probabilistic models of information retrieval\\n\\nbasedonmeasuringthedivergencefromrandomness.ACMTrans.Inf.Syst.20(4)\\n\\n(2002)\\n\\n2. Bonifacio,L.,Abonizio,H.,Fadaee,M.,Nogueira,R. :InPars:Unsuperviseddataset\\n\\ngeneration for information retrieval. In: Proceedings of SIGIR (2022)8 Gospodinov et al. 3. Dai, Z., Callan, J.: Deeper text understanding for IR with contextual neural lan-\\n\\nguage modeling. In: Proceedings of SIGIR (2019)\\n\\n4. Dai,Z.,Callan,J. :Context-awaredocumenttermweightingforad-hocsearch.In:\\n\\nProceedings of The Web Conference (2020)\\n\\n5. Das, R., Dhuliawala, S., Zaheer, M., McCallum, A.: Multi-step retriever-reader\\n\\ninteractionforscalableopen-domainquestionanswering.In:ProceedingsofICLR\\n\\n(2019)\\n\\n6. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of deep\\n\\nbidirectionaltransformersforlanguageunderstanding.In:ProceedingsofNAACL-\\n\\nHLT (2019)\\n\\n7. Ding, S., Suel, T.: Faster top-k document retrieval using block-max indexes. In:\\n\\nProceedings of SIGIR (2011)\\n\\n8. Dumais,S.T.,Furnas,G.W.,Landauer,T.K.,Deerwester,S.,Harshman,R. :Using\\n\\nlatentsemanticanalysistoimproveaccesstotextualinformation.In:Proceedings\\n\\nof SIGCHI CHI (1988)\\n\\n9. Efron, M., Organisciak, P., Fenlon, K.: Improving retrieval of short texts through\\n\\ndocument expansion. In: Proceedings of SIGIR (2012)\\n\\n10. Formal,T.,Piwowarski,B.,Clinchant,S. :SPLADE:Sparselexicalandexpansion\\n\\nmodel for first stage ranking. In: Proceedings of SIGIR (2021)\\n\\n11. He,B.,Ounis,I. :Studyingqueryexpansioneffectiveness.In:ProceedingsofECIR\\n\\n(2009)\\n\\n12. Jaleel,N.A.,Allan,J.,Croft,W.B.,Diaz,F.,Larkey,L.S.,Li,X.,Smucker,M.D.,\\n\\nWade, C.: Umass at TREC 2004: Novelty and HARD. In: TREC (2004)\\n\\n13. Johnson,J.,Douze,M.,Jegou,H. :Billion-scalesimilaritysearchwithGPUs.IEEE\\n\\nTransactions on Big Data 7(03) (2021)\\n\\n14. Khattab, O., Zaharia, M.: ColBERT: Efficient and effective passage search via\\n\\ncontextualized late interaction over BERT. In: Proceedings of SIGIR (2020)\\n\\n15. Lin,J.,Ma,X.,Mackenzie,J.,Mallia,A. :Ontheseparationoflogicalandphysical\\n\\nrankingmodelsfortextretrievalapplications.In:ProceedingsofDESIRES(2021)\\n\\n16. Lin, S.C., Yang, J.H., Lin, J.: In-batch negatives for knowledge distillation with\\n\\ntightly-coupled teachers for dense retrieval. In: Proceedings of RepL4NLP (2021)\\n\\n17. MacAvaney, S., Macdonald, C.: A Python interface to PISA! In: Proceedings of\\n\\nSIGIR (2022)\\n\\n18. MacAvaney,S.,Macdonald,C.,Ounis,I.:Streamliningevaluationwithir-measures. In: Proceedings of ECIR (2022)\\n\\n19. MacAvaney, S., Nardini, F.M., Perego, R., Tonellotto, N., Goharian, N., Frieder,\\n\\nO.:Expansionviapredictionofimportancewithcontextualization.In:Proceedings\\n\\nof SIGIR (2020)\\n\\n20. MacAvaney, S., Tonellotto, N., Macdonald, C.: Adaptive re-ranking with a corpus\\n\\ngraph. In: Proceedings of CIKM (2022)\\n\\n21. MacAvaney, S., Yates, A., Feldman, S., Downey, D., Cohan, A., Goharian, N.:\\n\\nSimplified data wrangling with ir_datasets. In: Proceedings of SIGIR (2021)\\n\\n22. Macdonald, C., Tonellotto, N.: Declarative experimentation in information re-\\n\\ntrieval using PyTerrier. In: Proceedings of ICTIR (2020)\\n\\n23. Mallia, A., Khattab, O., Suel, T., Tonellotto, N.: Learning passage impacts for\\n\\ninverted indexes. In: Proceedings of SIGIR (2021)\\n\\n24. Mallia, A., Siedlaczek, M., Mackenzie, J., Suel, T.: PISA: performant indexes and\\n\\nsearch for academia. In: Proceedings of OSIRRC@SIGIR (2019)\\n\\n25. Maynez,J.,Narayan,S.,Bohnet,B.,McDonald,R. :Onfaithfulnessandfactuality\\n\\nin abstractive summarization. In: Proceedings of ACL (2020)Doc2Query--: When Less is More 9\\n\\n26. Nguyen, T., Rosenberg, M., Song, X., Gao, J., Tiwary, S., Majumder, R., Deng,\\n\\nL.:MSMARCO:Ahumangeneratedmachinereadingcomprehensiondataset.In:\\n\\nProceedings of CoCo@NIPS (2016)\\n\\n27. Nogueira, R., Cho, K.: Passage re-ranking with BERT. ArXiv abs/1901.04085\\n\\n(2019)\\n\\n28. Nogueira, R., Lin, J.: From doc2query to doctttttquery (2019)\\n\\n29. Nogueira,R.,Yang,W.,Lin,J.J.,Cho,K. :Documentexpansionbyquerypredic-\\n\\ntion. ArXiv abs/1904.08375 (2019)\\n\\n30. Pickens, J., Cooper, M., Golovchinsky, G.: Reverted indexing for feedback and\\n\\nexpansion. In: Proceedings of CIKM (2010)\\n\\n31. Pradeep,R.,Liu,Y.,Zhang,X.,Li,Y.,Yates,A.,Lin,J. :Squeezingwaterfroma\\n\\nstone:Abagoftricksforfurtherimprovingcross-encodereffectivenessforrerank-\\n\\ning. In: Proceedings of ECIR (2022)\\n\\n32. Pradeep,R.,Nogueira,R.,Lin,J. :Theexpando-mono-duodesignpatternfortext\\n\\nranking with pretrained sequence-to-sequence models. ArXiv abs/2101.05667\\n\\n(2021)\\n\\n33. Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y.,\\n\\nLi, W., Liu, P.J., et al. : Exploring the limits of transfer learning with a unified\\n\\ntext-to-text transformer. J. Mach. Learn. Res. 21(140) (2020)\\n\\n34. Scells, H., Zhuang, S., Zuccon, G.: Reduce, reuse, recycle: Green information re-\\n\\ntrieval research. In: Proceedings of SIGIR (2022)\\n\\n35. Tao, T., Wang, X., Mei, Q., Zhai, C.: Language model information retrieval with\\n\\ndocument expansion. In: Proceedings of HLT-NAACL (2006)\\n\\n36. Wang, X., MacAvaney, S., Macdonald, C., Ounis, I.: An inspection of the repro-\\n\\nducibility and replicability of TCT-ColBERT. In: Proceedings of SIGIR (2022)\\n\\n37. Xiong, L., Xiong, C., Li, Y., Tang, K.F., Liu, J., Bennett, P.N., Ahmed, J., Over-\\n\\nwijk,A. :Approximatenearestneighbornegativecontrastivelearningfordensetext\\n\\nretrieval. In: Proceedings of ICLR (2021)\\n\\n38. Yu, S.Y., Liu, J., Yang, J., Xiong, C., Bennett, P.N., Gao, J., Liu, Z.: Few-shot\\n\\ngenerative conversational query rewriting. In: Proceedings of SIGIR (2020)\\n\\n39. Zhao,T.,Lu,X.,Lee,K. :SPARTA:Efficientopen-domainquestionansweringvia\\n\\nsparse transformer matching retrieval. arXiv abs/2009.13013 (2020)\\n\\n40. Zhuang, S., Zuccon, G.: TILDE: Term independent likelihood model for passage\\n\\nre-ranking. In: Proceedings of SIGIR (2021)Query2doc: Query Expansion with Large Language Models\\n\\nLiangWang and NanYang and FuruWei\\n\\nMicrosoftResearch\\n\\n{wangliang,nanya,fuwei}@microsoft.com\\n\\nAbstract 2009)haveonlyshownlimitedsuccessonpopular\\n\\ndatasets (Camposetal.,2016),andmoststate-of-\\n\\nThis paper introduces a simple yet effec-\\n\\nthe-artdenseretrieversdonotadoptthistechnique. tive query expansion approach, denoted as\\n\\nInthemeantime,documentexpansionmethodslike\\n\\nquery2doc, to improve both sparse and dense\\n\\n3202\\n\\nretrieval systems. The proposed method doc2query (Nogueiraetal.,2019)haveprovento\\n\\nfirstgeneratespseudo-documentsbyfew-shot beeffectiveforsparseretrieval. promptinglargelanguagemodels(LLMs),and Inthispaper,wedemonstratetheeffectiveness\\n\\nthenexpandsthequerywithgeneratedpseudo- of LLMs (Brown et al., 2020) as query expan- raM\\n\\ndocuments. LLMs are trained on web-scale\\n\\nsionmodelsbygeneratingpseudo-documentscon-\\n\\ntextcorporaandareadeptatknowledgemem-\\n\\nditioned on few-shot prompts. Given that search\\n\\norization. Thepseudo-documentsfromLLMs\\n\\n41\\n\\nqueriesareoftenshort,ambiguous,orlackneces-\\n\\noften contain highly relevant information that\\n\\ncan aid in query disambiguation and guide sarybackgroundinformation, LLMscanprovide\\n\\nthe retrievers. Experimental results demon- relevantinformationtoguideretrievalsystems,as ]RI.sc[\\n\\nstrate that query2doc boosts the performance theymemorizeanenormousamountofknowledge\\n\\nofBM25by3%to15%onad-hocIRdatasets,\\n\\nandlanguagepatternsbypre-trainingontrillions\\n\\nsuch as MS-MARCO and TREC DL, with-\\n\\noftokens. out any model fine-tuning. Furthermore, our\\n\\nOur proposed method, called query2doc, gen-\\n\\nmethod also benefits state-of-the-art dense re-\\n\\n1v87670.3032:viXra\\n\\ntrieversintermsofbothin-domainandout-of- erates pseudo-documents by few-shot prompting\\n\\ndomainresults. LLMs and concatenates them with the original\\n\\nquerytoformanewquery. Thismethodissimple\\n\\n1 Introduction\\n\\ntoimplementanddoesnotrequireanychangesin\\n\\nInformation retrieval (IR) aims to locate relevant trainingpipelinesormodelarchitectures,makingit\\n\\ndocuments from a large corpus given a user is- orthogonaltotheprogressinthefieldofLLMsand\\n\\nsued query. It is a core component in modern information retrieval. Future methods can easily\\n\\nsearch engines and researchers have invested for builduponourqueryexpansionframework. decades in this field. There are two mainstream For in-domain evaluation, we adopt the MS-\\n\\nparadigms for IR: lexical-based sparse retrieval, MARCOpassageranking (Camposetal.,2016),\\n\\nsuch as BM25, and embedding-based dense re- TREC DL 2019 and 2020 datasets. Pseudo-\\n\\ntrieval (Xiong et al., 2021; Qu et al., 2021). Al- documents are generated by prompting an im-\\n\\nthoughdenseretrieversperformbetterwhenlarge proved version of GPT-3 text-davinci-003 from\\n\\namountsoflabeleddataareavailable (Karpukhin OpenAI (Brown et al., 2020). Results show that\\n\\netal.,2020),BM25remainscompetitiveonout-of- query2docsubstantiallyimprovestheoff-the-shelf\\n\\ndomaindatasets (Thakuretal.,2021). BM25 algorithm without fine-tuning any model,\\n\\nQuery expansion (Rocchio, 1971; Lavrenko particularly for hard queries from the TREC DL\\n\\nand Croft, 2001) is a long-standing technique track. Strong dense retrievers, including DPR\\n\\nthatrewritesthequerybasedonpseudo-relevance (Karpukhin et al., 2020), SimLM (Wang et al.,\\n\\nfeedback or external knowledge sources such as 2022a), and E5 (Wang et al., 2022b) also bene-\\n\\nWordNet. For sparse retrieval, it can help bridge fitfromquery2doc,althoughthegainstendtobe\\n\\nthe lexical gap between the query and the docu- diminishing when distilling from a strong cross-\\n\\nments. However, query expansion methods like encoderbasedre-ranker. Experimentsinzero-shot\\n\\nRM3 (Lavrenko and Croft, 2001; Lv and Zhai, OOD settings demonstrate that our method out-performs strong baselines on most datasets. Fur-\\n\\ntheranalysisalsorevealstheimportanceofmodel q+ = concat({q}n, d(cid:48)) (1)\\n\\nscales: query2docworksbestwhencombinedwith\\n\\nHere, concat denotes the string concatenation\\n\\nthemostcapableLLMswhilesmalllanguagemod- function. q+ is used as the new query for\\n\\nelsonlyprovidemarginalimprovementsoverbase-\\n\\nBM25 retrieval. We find that n = 5 is a gener-\\n\\nlines. allygoodvalueanddonottuneitonadatasetbasis. To aid reproduction, we release all\\n\\nthe generations from text-davinci-003 Dense Retrieval The new query q+ is a sim-\\n\\nat https://huggingface.co/datasets/\\n\\nple concatenation of the original query q and the\\n\\nintfloat/query2doc_msmarco. pseudo-documentd(cid:48) separatedby[SEP]:\\n\\n2 Method q+ = concat(q, [SEP], d(cid:48)) (2)\\n\\nFortrainingdenseretrievers,severalfactorscan\\n\\ninfluencethefinalperformance,suchashardnega-\\n\\nLLM Prompts tivemining (Xiongetal.,2021),intermediatepre-\\n\\ntraining (GaoandCallan,2021),andknowledge\\n\\nWrite a passage that answers the given query:\\n\\ndistillation from a cross-encoder based re-ranker\\n\\nQuery:what state is this zip code 85282 (Quetal.,2021). Inthispaper,weinvestigatetwo\\n\\nPassage:Welcome to TEMPE, AZ 85282.\\n\\nsettingstogainamorecomprehensiveunderstand-\\n\\n85282 is a rural zip code in Tempe, Arizona. The population is primarily white ingofourmethod. ThefirstsettingistrainingDPR\\n\\n(Karpukhin et al., 2020) models initialized from\\n\\nQuery:when was pokemongreen released\\n\\nBERT withBM25hardnegativesonly. Theop-\\n\\nPassage: base\\n\\ntimizationobjectiveisastandardcontrastiveloss:\\n\\nLLM Output ehqh d\\n\\nL = log (3)\\n\\nP Feo bke rum ao ryn 2G 7r te he n 9w 9a 6s r Ie l wea as se td ein iJ ra sp a inn to hn cont ehqh d +(cid:80) diNehqh di\\n\\n, 1 . t h f t e\\n\\nPokemonseries of games and served as the whereh andh representtheembeddingsforthe\\n\\nq d\\n\\nbasis for PokemonRed and Blue, which were query and document, respectively. N denotes the\\n\\nreleased in the US in 1998. The original\\n\\nsetofhardnegatives. PokemonGreen remains a beloved classic\\n\\namong fans of the series. Thesecondsettingistobuilduponstate-of-the-\\n\\nartdenseretrieversanduseKLdivergencetodistill\\n\\nfromacross-encoderteachermodel. Figure1:Illustrationofquery2docfew-shotprompting. Weomitsomein-contextexamplesforspacereasons. min D (p ,p )+L (4)\\n\\nKL ce stu cont\\n\\np and p are the probabilities from the cross-\\n\\nce stu\\n\\nGivenaqueryq,weemployfew-shotprompting encoderandourstudentmodel,respectively. is\\n\\nto generate a pseudo-document d(cid:48) as depicted in a coefficient to balance the distillation loss and\\n\\nFigure 1. Thepromptcomprisesabriefinstruction contrastiveloss. Write a passage that answers the given query:\\n\\nand k labeled pairs randomly sampled from a Comparison with Pseudo-relevance Feedback\\n\\ntrainingset. Weusek = 4throughoutthis paper. Our proposed method can be viewed as a variant\\n\\nSubsequently, we rewrite q to a new query q+ of pseudo-relevance feedback (PRF) (Lavrenko\\n\\nby concatenating with the pseudo-document d(cid:48). and Croft, 2001; Lv and Zhai, 2009). In conven-\\n\\nThere are slight differences in the concatenation tionalPRF,thefeedbacksignalsforqueryexpan-\\n\\noperation for sparse and dense retrievers, which sion come from the top-k documents obtained in\\n\\nweelaborateoninthefollowingsection. theinitialretrievalstep,whileourmethodprompts\\n\\nLLMstogeneratepseudo-documents. Ourmethod\\n\\nSparse Retrieval Since the query q is typically doesnotrelyonthequalityoftheinitialretrievalre-\\n\\nmuchshorterthanpseudo-documents,weboostthe sults,whichareoftennoisyorirrelevant. Rather,it\\n\\nquerytermweightsbyrepeatingthequeryntimes exploitscutting-edgeLLMstogeneratedocuments\\n\\nbeforeconcatenatingwiththepseudo-documentd(cid:48): thataremorelikelytocontainrelevantterms.MSMARCOdev TRECDL19 TRECDL20\\n\\nMethod Fine-tuning\\n\\nMRR@10 R@50 R@1k nDCG@10 nDCG@10\\n\\nSparseretrieval\\n\\nBM25 (cid:55) 18.4 58.5 85.7 51.2 47.7\\n\\n+query2doc (cid:55) 21.4+3.0 65.3+6.8 91.8+6.1 66.2+15.0 62.9+15.2\\n\\nBM25+RM3 (cid:55) 15.8 56.7 86.4 52.2 47.4\\n\\ndocT5query (NogueiraandLin) (cid:51) 27.7 75.6 94.7 64.2 -\\n\\nDenseretrievalw/odistillation\\n\\nANCE (Xiongetal.,2021) (cid:51) 33.0 - 95.9 64.5 64.6\\n\\nHyDE (Gaoetal.,2022) (cid:55) - - - 61.3 57.9\\n\\nDPR (ourimpl.) (cid:51) 33.7 80.5 95.9 64.7 64.1\\n\\nbert-base\\n\\n+query2doc (cid:51) 35.1+1.4 82.6+2.1 97.2+1.3 68.7+4.0 67.1+3.0\\n\\nDenseretrievalw/distillation\\n\\nRocketQAv2 (Renetal.,2021) (cid:51) 38.8 86.2 98.1 - -\\n\\nAR2 (Zhangetal.,2021) (cid:51) 39.5 87.8 98.6 - -\\n\\nSimLM (Wangetal.,2022a) (cid:51) 41.1 87.8 98.7 71.4 69.7\\n\\n+query2doc (cid:51) 41.5+0.4 88.0+0.2 98.8+0.1 72.9+1.5 71.6+1.9\\n\\nE5 +KD (Wangetal.,2022b) (cid:51) 40.7 87.6 98.6 74.3 70.7\\n\\nbase\\n\\n+query2doc (cid:51) 41.5+0.8 88.1+0.5 98.7+0.1 74.9+0.6 72.5+1.8\\n\\nTable1: MainresultsontheMS-MARCOpassagerankingandTRECdatasets. TheFine-tuningcolumnindi-\\n\\ncateswhetherthemethodrequiresfine-tuningmodelonlabeleddataornot. : ourreproduction. 3 Experiments arelong-tailedentity-centricqueries,whichbenefit\\n\\nmorefromtheexactlexicalmatch. Thetraditional\\n\\n3.1 Setup\\n\\nquery expansion method RM3 only marginally\\n\\nEvaluation Datasets For in-domain evaluation, improves the R@1k metric. Although the docu-\\n\\nweutilizetheMS-MARCOpassageranking (Cam- mentexpansionmethoddocT5queryachievesbet-\\n\\nposetal.,2016),TRECDL2019 (Craswelletal., ternumbersontheMS-MARCOdevset,itrequires\\n\\n2020a)and2020 (Craswelletal.,2020b)datasets. training a T5-based query generator with all the\\n\\nForzero-shotout-of-domainevaluation,weselect availablelabeleddata,whileBM25+query2doc\\n\\nfive low-resource datasets from the BEIR bench- doesnotrequireanymodelfine-tuning. mark (Thakur et al., 2021). The evaluation met- Fordenseretrieval,themodelvariantsthatcom-\\n\\nricsincludeMRR@10,R@k(k  {50,1k}),and bine with query2doc also outperform the corre-\\n\\nnDCG@10. sponding baselines on all metrics. However, the\\n\\nHyperparameters Forsparseretrievalincluding gainbroughtbyquery2doctendstodiminishwhen\\n\\nBM25andRM3,weadoptthedefaultimplementa- usingintermediatepre-trainingorknowledgedistil-\\n\\ntionfromPyserini (Linetal.,2021). Whentraining lationfromcross-encoderre-rankers,asshownby\\n\\ndense retrievers, we use mostly the same hyper- theSimLM+query2docandE5+query2doc\\n\\nparametersas SimLM(Wanget al.,2022a), with results. the exception of increasing the maximum query Forzero-shotout-of-domainretrieval,theresults\\n\\nlengthto144toincludepseudo-documents. When are mixed as shown in Table 2. Entity-centric\\n\\nprompting LLMs, we include 4 in-context exam- datasetslikeDBpediaseethelargestimprovements. plesandusethedefaulttemperatureof1tosample OntheNFCorpusandScifactdatasets,weobserve\\n\\natmost128tokens. Forfurtherdetails,pleaserefer aminordecreaseinrankingquality. Thisislikely\\n\\ntoAppendix A. duetothedistributionmismatchbetweentraining\\n\\nandevaluation. 3.2 MainResults\\n\\n4 Analysis\\n\\nInTable 1,welisttheresultsontheMS-MARCO\\n\\npassagerankingandTRECDLdatasets. Forsparse Scaling up LLMs is Critical For our proposed\\n\\nretrieval, BM25 + query2doc beats the BM25 method, a question that naturally arises is: how\\n\\nbaseline with over 15% improvements on TREC does the model scale affect the quality of query\\n\\nDL2019and2020datasets. Ourmanualinspection expansion? Table 3 shows that the performance\\n\\nrevealsthatmostqueriesfromtheTRECDLtrack steadily improves as we go from the 1.3B modelDBpedia NFCorpus Scifact Trec-Covid Touche2020\\n\\nBM25 31.3 32.5 66.5 65.6 36.7\\n\\n+query2doc 37.0+5.7 34.9+2.4 68.6+2.1 72.2+6.6 39.8+3.1\\n\\nSimLM (Wangetal.,2022a) 34.9 32.7 62.4 55.0 18.9\\n\\n+query2doc 38.3+3.4 32.1-0.6 59.5-2.9 59.9+4.9 25.6+6.7\\n\\nE5 +KD (Wangetal.,2022b) 40.7 35.0 70.4 74.1 30.9\\n\\nbase\\n\\n+query2doc 42.4+1.7 35.2+0.2 67.5-2.9 75.1+1.0 31.7+0.8\\n\\nTable 2: Zero-shot out-of-domain results on 5 low-resource datasets from the BEIR benchmark (Thakur et al.,\\n\\n2021). ThereportednumbersarenDCG@10. Forafaircomparison,thein-contextexamplesforpromptingLLMs\\n\\ncomefromtheMS-MARCOtrainingset. #params TREC19 TREC20 contributionisorthogonaltothecontinualscaling\\n\\nBM25 - 51.2 47.7 upofsupervisionsignals. w/babbage 1.3B 52.0 50.2\\n\\nw/curie 6.7B 55.1 50.1\\n\\nw/davinci-001 175B 63.5 58.2 TREC19 TREC20\\n\\nw/davinci-003 175B 66.2 62.9 BM25+query2doc 66.2 62.9\\n\\nw/queryonly 51.2 47.7\\n\\nTable3: Queryexpansionwithdifferentmodelsizes. w/pseudo-doconly 48.7 44.5\\n\\nto175Bmodels. Empirically,thetextsgenerated Table4: Usingtheconcatenationoftheoriginalquery\\n\\nandthegeneratedpseudo-documentsperformsubstan-\\n\\nbysmallerlanguagemodelstendtobeshorterand\\n\\ntiallybetter. containmorefactualerrors. Also,thedavinci-003\\n\\nmodeloutperformsitsearlierversiondavinci-001\\n\\nHow to Use Pseudo-documents In this paper,\\n\\nby using better training data and improved\\n\\nwe concatenate the original query and pseudo-\\n\\ninstructiontuning. documentsasthenewquery. Alternatively,onecan\\n\\nsolely use the pseudo-documents, as done in the\\n\\napproachofHyDE (Gaoetal.,2022). Theresults\\n\\npresentedinTable 4demonstratethattheoriginal\\n\\n36 35.1 queryandpseudo-documentsarecomplementary,\\n\\n34.1\\n\\n34 andtheircombinationleadstosubstantiallybetter\\n\\n32.1 33.7\\n\\n32 32.8 performanceinsparseretrieval. tes\\n\\n31.4 30 ved\\n\\n28.5\\n\\n28 CaseAnalysis InTable 5,weshowtwoqueries no\\n\\n27.3 alongwiththeirrespectivepseudo-documentsand RRM\\n\\n26\\n\\ngroundtruth. The pseudo-documents, which are\\n\\n24\\n\\n22.7\\n\\nDPR w/o query2doc generatedbyLLMs,offerdetailedandmostlyac-\\n\\n22\\n\\nDPR w/ query2doc curate information, thereby reducing the lexical\\n\\n21.4\\n\\n20\\n\\n1 10 30 50 100 mismatch between the query and documents. In\\n\\n% labeled data for fine-tuning\\n\\nsomecases,thepseudo-documentsaresufficientto\\n\\nFigure 2: MRR on MS-MARCO dev set w.r.t the per-\\n\\nmeet the users information needs, rendering the\\n\\ncentageoflabeleddatausedforfine-tuning. retrieval step unnecessary. However, it is worth\\n\\nnotingthattheLLMgenerationsmaycontainfac-\\n\\nPerformance Gains are Consistent across Data tualerrors. Forinstance,inthesecondquery,the\\n\\nScales Figure 2 presents a comparison between themesong\"ItsaJungleOutThere\"wasusedas\\n\\ntwo variants of DPR models, which differ in the ofseasontwoin2003,not2002 1. Althoughsuch\\n\\namount of labeled data used. The results show errorsmayappearsubtleanddifficulttoverify,they\\n\\nthat the DPR + query2doc variant consistently poseasignificantchallengetobuildingtrustworthy\\n\\noutperforms the DPR baseline by approximately systemsusingLLMs. 1%, regardless of the amount of data used for\\n\\n1Refer to https://en.wikipedia.org/wiki/Its_a_\\n\\nfine-tuning. This observation highlights that our Jungle_Out_There_(song)query whokillednicholasiiofrussia\\n\\nLLMgeneration NicholasIIofRussia,thelastTsarofRussia,wasexecutedbyBolshevikrevolutionarieson\\n\\nJuly17th,1918,alongwithhiswifeAlexandraandtheirfivechildren. Theexecutionwas\\n\\norderedbyVladimirLenin,theleaderoftheBolshevikParty.Theactualexecutionwascarried\\n\\noutbyafiringsquadofBolsheviktroops,andthebodieswerelaterburiedinamassgrave...\\n\\nGroundtruth (1868-1918). Nicholas II was the last emperor, or tsar, of Russia, serving from 1894 to\\n\\n1917.Nicholas,hiswife,andtheirfivechildrenwerekilledbytheBolsheviks,membersofa\\n\\nrevolutionarygroup(ledbyLenin)whoseizedcontrolofthegovernmentinRussiaduring\\n\\ntheOctoberRevolution(seeRussianRevolution)of1917. query whosingsmonkthemesong\\n\\nLLMgeneration ThethemesongforthetelevisionshowMonkisentitled\"ItsaJungleOutThere\"andis\\n\\nsungbyAmericansinger-songwriterRandyNewman.Thesongwaswrittenspecificallyfor\\n\\ntheshow,andithasbeenusedasthethemesongsincetheseriespremieredin2002. Ithas\\n\\nbeenpraisedbycriticsandfansalikeandisoftenregardedasoneofthebestthemesongsin\\n\\ntelevisionhistory. Groundtruth existsandisanalternateof. TheMonkthemesongisItsaJungleOutTherebyRandy\\n\\nNewman.TheMonkthemesongisItsaJungleOutTherebyRandyNewman. Table5: ExamplesfromtheTRECDL2020dataset. Boldtextsaretheoverlappingwordsbetweengroundtruth\\n\\nandpseudo-documentsgeneratedfromLLMs. Theitalicizedredsentencedemonstratesafactualerrorinlanguage\\n\\nmodelgenerations. 5 RelatedWork across various tasks. LLMs can follow instruc-\\n\\ntionsinazero-shotmannerorconductin-context\\n\\nQuery Expansion and Document Expansion\\n\\nlearningthroughfew-shotprompting. Labelinga\\n\\nare two classical techniques to improve retrieval\\n\\nfewhigh-qualityexamplesonlyrequiresminimal\\n\\nquality, particularly for sparse retrieval systems. human effort. In this paper, we employ few-shot\\n\\nBothtechniquesaimtominimizethelexicalgapbe-\\n\\nprompting to generate pseudo-documents from a\\n\\ntweenthequeryandthedocuments. Queryexpan-\\n\\ngivenquery. AcloselyrelatedrecentworkHyDE\\n\\nsion typically involves rewriting the query based\\n\\n(Gao et al., 2022) instead focuses on the zero-\\n\\nonrelevancefeedback (LavrenkoandCroft,2001;\\n\\nshot setting and uses embeddings of the pseudo-\\n\\nRocchio,1971)orlexicalresourcessuchasWord-\\n\\ndocumentsforsimilaritysearch. HyDEimplicitly\\n\\nNet (Miller, 1992). In cases where labeled rele-\\n\\nassumesthatthegroundtruthdocumentandpseudo-\\n\\nvancefeedbackisnotavailable,thetop-kretrieved\\n\\ndocumentsexpressthesamesemanticsindifferent\\n\\ndocumentscanserveaspseudo-relevancefeedback\\n\\nwords,whichmaynotholdforsomequeries. Inthe\\n\\nsignals (LvandZhai,2009). fieldofquestionanswering,RECITE (Sunetal.,\\n\\nIn contrast, document expansion enriches the\\n\\n2022) and GENREAD (Yu et al., 2022) demon-\\n\\ndocumentrepresentationbyappendingadditional\\n\\nstratethatLLMsarepowerfulcontextgenerators\\n\\nrelevantterms. Doc2query (Nogueiraetal.,2019)\\n\\nandcanencodeabundantfactualknowledge. How-\\n\\ntrains a seq2seq model to predict pseudo-queries\\n\\never,asouranalysisshows,LLMscansometimes\\n\\nbased on documents and then adds generated\\n\\ngeneratefalseclaims,hinderingtheirpracticalap-\\n\\npseudo-queries to the document index. Learned\\n\\nplicationincriticalareas. sparseretrievalmodelssuchasSPLADE (Formal\\n\\net al., 2021) and uniCOIL (Lin and Ma, 2021)\\n\\n6 Conclusion\\n\\nalsolearndocumenttermweightinginanend-to-\\n\\nendfashion. However,moststate-of-the-artdense This paper presents a simple method query2doc\\n\\nretrievers (Ren et al., 2021; Wang et al., 2022a) to leverage LLMs for query expansion. It first\\n\\ndo not adopt any expansion techniques. Our pa- prompts LLMs with few-shot examples to gener-\\n\\nperdemonstratesthatstrongdenseretrieversalso atepseudo-documentsandthenintegrateswithex-\\n\\nbenefitfromqueryexpansionusingLLMs. isting sparse or dense retrievers by augmenting\\n\\nLargeLanguageModels(LLMs) suchasGPT-3 querieswithgeneratedpseudo-documents. Theun-\\n\\n(Brown et al., 2020), PaLM (Chowdhery et al., derlyingmotivationistodistilltheLLMsthrough\\n\\n2022), and LLaMA (Touvron et al., 2023) are prompting. Despiteitssimplicity,empiricalevalua-\\n\\ntrainedontrillionsoftokenswithbillionsofparam- tionsdemonstrateconsistentimprovementsacross\\n\\neters,exhibitingunparalleledgeneralizationability variousretrievalmodelsanddatasets.Limitations Majumder, Li Deng, and Bhaskar Mitra. 2016. Ms\\n\\nmarco: A human generated machine reading com-\\n\\nprehensiondataset. ArXiv,abs/1611.09268. LLMcall Indexsearch\\n\\nBM25 - 16ms Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,\\n\\n+query2doc >2000ms 177ms Maarten Bosma, Gaurav Mishra, Adam Roberts,\\n\\nPaul Barham, Hyung Won Chung, Charles Sutton,\\n\\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\\n\\nTable6:Latencyanalysisforretrievalsystemswithour\\n\\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\\n\\nproposedquery2doc.Weretrievethetop100resultsfor\\n\\nRao,ParkerBarnes,YiTay,NoamM.Shazeer,Vin-\\n\\nMS-MARCOdevquerieswithasinglethreadandthen\\n\\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben-\\n\\naverageoverallthequeries. ThelatencyforLLMAPI\\n\\ntonC.Hutchinson,ReinerPope,JamesBradbury,Ja-\\n\\ncallsdependsonserverloadandisdifficulttoprecisely\\n\\ncobAustin,MichaelIsard,GuyGur-Ari,Pengcheng\\n\\nmeasure. Yin, Toju Duke, Anselm Levskaya, Sanjay Ghe-\\n\\nmawat, Sunipa Dev, Henryk Michalewski, Xavier\\n\\nGarca, Vedant Misra, Kevin Robinson, Liam Fe-\\n\\nAn apparent limitation is the efficiency of re-\\n\\ndus, Denny Zhou, Daphne Ippolito, David Luan,\\n\\ntrieval. Ourmethodrequiresrunninginferencewith\\n\\nHyeontaekLim,BarretZoph,AlexanderSpiridonov,\\n\\nLLMswhichcanbeconsiderablyslowerduetothe RyanSepassi,DavidDohan,ShivaniAgrawal,Mark\\n\\ntoken-by-tokenautoregressivedecoding. Moreover, Omernick,AndrewM.Dai,ThanumalayanSankara-\\n\\nwithquery2doc,searchingtheinvertedindexalso narayana Pillai, Marie Pellat, Aitor Lewkowycz,\\n\\nErica Moreira, Rewon Child, Oleksandr Polozov,\\n\\nbecomesslowerasthenumberofquerytermsin-\\n\\nKatherineLee,ZongweiZhou,XuezhiWang,Bren-\\n\\ncreases afterexpansion. This issupported by the nanSaeta,MarkDaz,OrhanFirat,MicheleCatasta,\\n\\nbenchmarkingresultsinTable 6. Real-worldde- Jason Wei, Kathleen S. Meier-Hellstern, Douglas\\n\\nploymentofourmethodshouldtakethesefactors Eck,JeffDean,SlavPetrov,andNoahFiedel.2022. Palm: Scaling language modeling with pathways. intoconsideration. ArXiv,abs/2204.02311. Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel\\n\\nReferences\\n\\nCampos, and Ellen M Voorhees. 2020a. Overview\\n\\nofthetrec2019deeplearningtrack. ArXivpreprint,\\n\\nAlexander Bondarenko, Maik Frbe, Johannes Kiesel,\\n\\nabs/2003.07820. Shahbaz Syed, Timon Gurcke, Meriem Beloucif,\\n\\nAlexanderPanchenko,ChrisBiemann,BennoStein,\\n\\nNick Craswell, Bhaskar Mitra, Emine Yilmaz,\\n\\nHenning Wachsmuth, et al. 2022. Overview of\\n\\nDaniel Fernando Campos, and Ellen M. Voorhees. touch 2022: argument retrieval. In Interna-\\n\\n2020b. Overview of the trec 2020 deep learning\\n\\ntional Conference of the Cross-Language Evalua-\\n\\ntrack. ArXiv,abs/2003.07820. tion Forum for European Languages, pages 311\\n\\n336.Springer. ThibaultFormal,BenjaminPiwowarski,andStphane\\n\\nClinchant.2021. Splade: Sparselexicalandexpan-\\n\\nVera Boteva, Demian Gholipour, Artem Sokolov, and\\n\\nsion model for first stage ranking. Proceedings of\\n\\nStefan Riezler. 2016. A full-text learning to rank\\n\\nthe 44th International ACM SIGIR Conference on\\n\\ndataset for medical information retrieval. In Euro-\\n\\nResearchandDevelopmentinInformationRetrieval. pean Conference on Information Retrieval, pages\\n\\n716722.Springer. Luyu Gao and Jamie Callan. 2021. Condenser: a pre-\\n\\nTomB.Brown,BenjaminMann,NickRyder,Melanie trainingarchitecturefordenseretrieval. InProceed-\\n\\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind ings of the 2021 Conference on Empirical Methods\\n\\nNeelakantan,PranavShyam,GirishSastry,Amanda in Natural Language Processing, pages 981993,\\n\\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, OnlineandPuntaCana,DominicanRepublic.Asso-\\n\\nGretchen Krueger, Tom Henighan, Rewon Child, ciationforComputationalLinguistics. Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\\n\\nClemens Winter, Christopher Hesse, Mark Chen, Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie\\n\\nEric Sigler, Mateusz Litwin, Scott Gray, Benjamin Callan.2022. Precisezero-shotdenseretrievalwith-\\n\\nChess, Jack Clark, Christopher Berner, Sam Mc- outrelevancelabels. ArXiv,abs/2212.10496. Candlish, Alec Radford, Ilya Sutskever, and Dario\\n\\nAmodei.2020. Languagemodelsarefew-shotlearn- Faegheh Hasibi, Fedor Nikolaev, Chenyan Xiong,\\n\\ners. InAdvancesinNeuralInformationProcessing Krisztian Balog, Svein Erik Bratsberg, Alexander\\n\\nSystems33: AnnualConferenceonNeuralInforma- Kotov, and Jamie Callan. 2017. Dbpedia-entity v2:\\n\\ntion Processing Systems 2020, NeurIPS 2020, De- A test collection for entity search. In Proceedings\\n\\ncember6-12,2020,virtual. ofthe40thInternationalACMSIGIRConferenceon\\n\\nResearchandDevelopmentinInformationRetrieval,\\n\\nDanielFernandoCampos,TriNguyen,MirRosenberg, Shinjuku, Tokyo, Japan, August 7-11, 2017, pages\\n\\nXia Song, Jianfeng Gao, Saurabh Tiwary, Rangan 12651268.ACM.VladimirKarpukhin,BarlasOguz,SewonMin,Patrick ZhiqingSun,XuezhiWang,YiTay,YimingYang,and\\n\\nLewis,LedellWu,SergeyEdunov,DanqiChen,and DennyZhou.2022. Recitation-augmentedlanguage\\n\\nWen-tau Yih. 2020. Dense passage retrieval for models. ArXiv,abs/2210.01296. open-domainquestionanswering. InProceedingsof\\n\\nthe 2020 Conference on Empirical Methods in Nat- Nandan Thakur, Nils Reimers, Andreas Rckl, Ab-\\n\\nural Language Processing (EMNLP), pages 6769 hishek Srivastava, and Iryna Gurevych. 2021. Beir:\\n\\n6781, Online. Association for Computational Lin- A heterogeneous benchmark for zero-shot evalua-\\n\\nguistics. tion of information retrieval models. In Thirty-fifth\\n\\nConference on Neural Information Processing Sys-\\n\\nVictorLavrenkoandW.BruceCroft.2001. Relevance- temsDatasetsandBenchmarksTrack(Round2). basedlanguagemodels. ACMSIGIRForum,51:260\\n\\n267. HugoTouvron,ThibautLavril,GautierIzacard,Xavier\\n\\nMartinet, Marie-Anne Lachaux, Timothe Lacroix,\\n\\nJimmy J. Lin and Xueguang Ma. 2021. A few brief\\n\\nBaptiste Rozire, Naman Goyal, Eric Hambro,\\n\\nnotes on deepimpact, coil, and a conceptual frame-\\n\\nFaisal Azhar, Aurelien Rodriguez, Armand Joulin,\\n\\nwork for information retrieval techniques. ArXiv,\\n\\nEdouard Grave, and Guillaume Lample. 2023.\\n\\nabs/2106.14807. Llama:Openandefficientfoundationlanguagemod-\\n\\nels. ArXiv,abs/2302.13971. JimmyJ.Lin,XueguangMa,Sheng-ChiehLin,Jheng-\\n\\nHongYang,RonakPradeep,RodrigoNogueira,and\\n\\nEllen Voorhees, Tasmeer Alam, Steven Bedrick, Dina\\n\\nDavidR.Cheriton.2021. Pyserini:Apythontoolkit\\n\\nDemner-Fushman,WilliamRHersh,KyleLo,Kirk\\n\\nforreproducibleinformationretrievalresearchwith\\n\\nRoberts, Ian Soboroff, and Lucy Lu Wang. 2021.\\n\\nsparseanddenserepresentations. Proceedingsofthe\\n\\nTrec-covid: constructingapandemicinformationre-\\n\\n44th International ACM SIGIR Conference on Re-\\n\\ntrieval test collection. In ACM SIGIR Forum, vol-\\n\\nsearchandDevelopmentinInformationRetrieval. ume54,pages112.ACMNewYork,NY,USA. YuanhuaLvandChengXiangZhai.2009. Acompara-\\n\\ntivestudyofmethodsforestimatingquerylanguage David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu\\n\\nmodels with pseudo feedback. Proceedings of the Wang, Madeleine van Zuylen, Arman Cohan, and\\n\\n18th ACM conference on Information and knowl- Hannaneh Hajishirzi. 2020. Fact or fiction: Verify-\\n\\nedgemanagement. ing scientific claims. In Proceedings of the 2020\\n\\nConference on Empirical Methods in Natural Lan-\\n\\nGeorgeA.Miller.1992. WordNet: Alexicaldatabase guageProcessing(EMNLP),pages75347550,On-\\n\\nforEnglish. InSpeechandNaturalLanguage: Pro- line.AssociationforComputationalLinguistics. ceedings of a Workshop Held at Harriman, New\\n\\nYork,February23-26,1992. LiangWang,NanYang,XiaolongHuang,BinxingJiao,\\n\\nLinjun Yang, Daxin Jiang, Rangan Majumder, and\\n\\nRodrigoNogueiraandJimmyLin. Fromdoc2queryto Furu Wei. 2022a. Simlm: Pre-training with rep-\\n\\ndoctttttquery. resentation bottleneck for dense passage retrieval. ArXiv,abs/2207.02578. Rodrigo Nogueira, Wei Yang, Jimmy J. Lin, and\\n\\nKyunghyun Cho. 2019. Document expansion by\\n\\nLiang Wang, Nan Yang, Xiaolong Huang, Binx-\\n\\nqueryprediction. ArXiv,abs/1904.08375. ing Jiao, Linjun Yang, Daxin Jiang, Rangan Ma-\\n\\njumder, andFuruWei.2022b. Textembeddingsby\\n\\nYingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang\\n\\nweakly-supervised contrastive pre-training. ArXiv,\\n\\nRen, Wayne Xin Zhao, Daxiang Dong, Hua Wu,\\n\\nabs/2212.03533. and Haifeng Wang. 2021. RocketQA: An opti-\\n\\nmized training approach to dense passage retrieval\\n\\nLee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang,\\n\\nfor open-domain question answering. In Proceed-\\n\\nJialin Liu, Paul N. Bennett, Junaid Ahmed, and\\n\\nings of the 2021 Conference of the North Ameri-\\n\\nArnoldOverwijk.2021. Approximatenearestneigh-\\n\\ncan Chapter of the Association for Computational\\n\\nbor negative contrastive learning for dense text re-\\n\\nLinguistics: Human Language Technologies, pages\\n\\ntrieval. In9thInternationalConferenceonLearning\\n\\n58355847, Online. Association for Computational\\n\\nRepresentations,ICLR2021,VirtualEvent,Austria,\\n\\nLinguistics. May3-7,2021.OpenReview.net. Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao,\\n\\nQiaoQiaoShe,HuaWu,HaifengWang,andJi-Rong W.Yu,DanIter,ShuohangWang,YichongXu,Mingx-\\n\\nWen. 2021. RocketQAv2: A joint training method uan Ju, Soumya Sanyal, Chenguang Zhu, Michael\\n\\nfor dense passage retrieval and passage re-ranking. Zeng, and Meng Jiang. 2022. Generate rather than\\n\\nIn Proceedings of the 2021 Conference on Empiri- retrieve: Large language models are strong context\\n\\ncalMethodsinNaturalLanguageProcessing,pages generators. ArXiv,abs/2209.10063. 28252835,OnlineandPuntaCana,DominicanRe-\\n\\npublic.AssociationforComputationalLinguistics. Hang Zhang, Yeyun Gong, Yelong Shen, Jiancheng\\n\\nLv, Nan Duan, and Weizhu Chen. 2021. Adversar-\\n\\nJ.J.Rocchio.1971. Relevancefeedbackininformation ial retriever-ranker for dense text retrieval. ArXiv\\n\\nretrieval. preprint,abs/2110.03611.query whosingsheygoodlooking\\n\\nLLMgeneration HeyGoodLookinwasoriginallywrittenandrecordedbythecountrymusicsingerHank\\n\\nWilliams in 1951. The song has since been covered by several other artists and bands,\\n\\nincludingJimmyBuffett,ConwayTwitty,andWillieNelson. Groundtruth Hey,GoodLookin. (1951)Hey,GoodLookinisa1951songwrittenandrecordedbyHank\\n\\nWilliams, andhisversionwasinductedintotheGrammyHallofFamein2001. Sinceits\\n\\noriginal1951recordingithasbeencoveredbyavarietyofartists. query trumbullmarriottfaxnumber\\n\\nLLMgeneration ThefaxnumberfortheTrumbullMarriottSheltonis203-378-4444. Groundtruth Businessname: TrumbullMarriottMerrittParkway;Address: 180HawleyLaneTrumbull,\\n\\nConnecticut 06611; Phone number: 203-378-4958; Fax number: 203-378-1400; Business\\n\\nhours:24;Creditcardsaccepted:Yes;Numberofemployees:10-19;Map:\\n\\nquery whatishraandhsa\\n\\nLLMgeneration HRAstandsforHealthReimbursementArrangement. Itisatypeofbenefitplanwherean\\n\\nemployerreimbursesemployeesforqualifyingmedicalexpenses.Italsoallowsemployers\\n\\ntosetasidemoneytax-freetoreimburseemployeesformedicalexpensesthatarenotcovered\\n\\nundertheemployershealthinsuranceplan. HSAstandsforHealthSavingsAccount. Itis\\n\\nasavingsaccountthatisusedinconjunctionwithaqualifiedHighDeductibleHealthPlan\\n\\n(HDHP).AnHSAenablesanindividualtopayforcurrenthealthexpensesandsaveforfuture\\n\\nhealthexpensesonatax-freebasis.Contributionstotheaccountaretax\\n\\nGroundtruth ThekeydifferencebetweenHRAandHSAisthatHRAisanemployerfundedhealthbenefit\\n\\nplanthatreimbursesformedicalexpensesincludingpersonalhealthinsurancepolicypre-\\n\\nmiumsofemployeeswhereasHSAisalsoatax-advantagedhealthbenefitplanexclusively\\n\\navailabletotaxpayersintheUnitedStateswhoareenrolledinaHigh-DeductibleHealthPlan\\n\\n(HDHP). Table7: MoreexamplesofLLMgenerations. TheformatisthesameasinTable 5. A ImplementationDetails DPR w/distillation\\n\\nlearningrate 2105 3105\\n\\nFor dense retrieval experiments in Table 1, we PLM BERT base SimLM/E5 base-unsup\\n\\nlist the hyperparameters in Table 8. When #ofGPUs 4 4\\n\\nwarmupsteps 1000 1000\\n\\ntraining dense retrievers with distillation from\\n\\nbatchsize 64 64\\n\\ncross-encoder, we use the same teacher score\\n\\nepoch 3 6\\n\\nreleased by Wang et al.. The SimLM and\\n\\nn.a. 0.2\\n\\nE5 checkpoints for initialization are pub-\\n\\nnegativesdepth 1000 200\\n\\nlicly available at https://huggingface. querylength 144 144\\n\\nco/intfloat/simlm-base-msmarco and passagelength 144 144\\n\\nhttps://huggingface.co/intfloat/ #ofnegatives 15 23\\n\\ne5-base-unsupervised. To compute the\\n\\nTable8: Hyper-parametersfortrainingdenseretrievers\\n\\ntext embeddings, we utilize the [CLS] vector for\\n\\nonMS-MARCOpassagerankingdataset. SimLMandmeanpoolingforE5. Thismakessure\\n\\nthat the pooling mechanisms remain consistent\\n\\nbetweenintermediatepre-trainingandfine-tuning. For ablation experiments in Figure 2, we fine-\\n\\nWhenpromptingLLMs,weinclude4in-context tune for 40 epochs or 18k steps, whichever is\\n\\nexamples from the MS-MARCO training set. To reachedfirst. increase prompt diversity, we randomly select 4\\n\\nexamplesforeachAPIcall. Acompletepromptis\\n\\nshowninTable 9. Regardingout-of-domainevaluationsonDBpe-\\n\\ndia (Hasibietal.,2017),NFCorpus (Botevaetal.,\\n\\n2016),Scifact (Waddenetal.,2020),Trec-Covid\\n\\n(Voorhees et al., 2021), and Touche2020 (Bon-\\n\\ndarenko et al., 2022), SimLMs results are based\\n\\nonthereleasedcheckpointby Wangetal..Writeapassagethatanswersthegivenquery:\\n\\nQuery:whatstateisthiszipcode85282\\n\\nPassage:WelcometoTEMPE,AZ85282.85282isaruralzipcodeinTempe,Arizona.Thepopulation\\n\\nisprimarilywhite, andmostlysingle. At$200,200theaveragehomevaluehereisabithigherthan\\n\\naverageforthePhoenix-Mesa-Scottsdalemetroarea,sothisprobablyisnttheplacetolookforhousing\\n\\nbargains.5282ZipcodeislocatedintheMountaintimezoneat33degreeslatitude(FunFact:thisisthe\\n\\nsamelatitudeasDamascus,Syria!)and-112degreeslongitude. Query:whyisgibbsmodelofreflectiongood\\n\\nPassage:Inthisreflection,IamgoingtouseGibbs(1988)ReflectiveCycle.Thismodelisarecognised\\n\\nframeworkformyreflection. Gibbs(1988)consistsofsixstagestocompleteonecyclewhichisable\\n\\ntoimprovemynursingpracticecontinuouslyandlearningfromtheexperienceforbetterpracticeinthe\\n\\nfuture.nconclusionofmyreflectiveassignment,ImentionthemodelthatIchose,Gibbs(1988)Reflective\\n\\nCycleasmyframeworkofmyreflective.IstatethereasonswhyIamchoosingthemodelaswellassome\\n\\ndiscussionontheimportantofdoingreflectioninnursingpractice. prompts\\n\\nQuery:whatdoesathousandpardonsmeans\\n\\nPassage: Oh, thatsallright, thatsallright, giveusarest; nevermindaboutthedirection, hangthe\\n\\ndirection-Ibegpardon,Ibegathousandpardons,Iamnotwellto-day;paynoattentionwhenIsoliloquize,\\n\\nitisanoldhabit,anold,badhabit,andhardtogetridofwhenonesdigestionisalldisorderedwitheating\\n\\nfoodthatwasraisedforeverandeverbeforehewasborn;goodland! amancantkeephisfunctions\\n\\nregularonspringchickensthirteenhundredyearsold. Query:whatisamacrowarning\\n\\nPassage: Macro virus warning appears when no macros exist in the file in Word. When you open\\n\\na Microsoft Word 2002 document or template, you may receive the following macro virus warning,\\n\\neventhoughthedocumentortemplatedoesnotcontainmacros:C:\\\\<path>\\\\<filename>containsmacros. Macrosmaycontainviruses. Query:whenwaspokemongreenreleased\\n\\nPassage:\\n\\nPokemonGreenwasreleasedinJapanonFebruary27th,1996.ItwasthefirstinthePokemonseriesof\\n\\noutput gamesandservedasthebasisforPokemonRedandBlue,whichwerereleasedintheUSin1998.The\\n\\noriginalPokemonGreenremainsabelovedclassicamongfansoftheseries. Table9: ThefullpromptusedfortheexampleinFigure 1.', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'})]\n",
            "[Document(page_content='COIL: Revisit Exact Lexical Match in Information Retrieval\\n\\nwith Contextualized Inverted List\\n\\nLuyuGao,ZhuyunDai,JamieCallan\\n\\nLanguageTechnologiesInstitute\\n\\nCarnegieMellonUniversity\\n\\n{luyug, zhuyund, callan}@cs.cmu.edu\\n\\nAbstract the-artintextrankingwithhugeperformanceleap\\n\\n(NogueiraandCho,2019;DaiandCallan,2019b). Classicalinformationretrievalsystemssuchas\\n\\nThough the idea of soft matching all tokens is\\n\\nBM25 rely on exact lexical match and carry\\n\\ncarriedthroughthedevelopmentofneuralIRmod-\\n\\nout search efficiently with inverted list index. 1202\\n\\nRecent neural IR models shifts towards soft els, seeing the success brought by deep LMs, we\\n\\nsemantic matching all query document terms, takeastepbackandask: howmuchgaincanweget\\n\\nbut they lose the computation efficiency of ifweintroducecontextualizedrepresentationsback\\n\\nexact match systems. This paper presents\\n\\ntolexicalexactmatchsystems? Inotherwords,can rpA\\n\\nCOIL, a contextualized exact match retrieval\\n\\nwebuildasystemthatstillperformsexactquery-\\n\\narchitecturethatbringssemanticlexicalmatch-\\n\\ndocumenttokenmatchingbutcomputematching\\n\\ning. COIL scoring is based on overlapping\\n\\n51\\n\\nsignalswithcontextualizedtokenrepresentations\\n\\nquery document tokens contextualized repre-\\n\\nsentations. The new architecture stores con- insteadofheuristics? Thismayseemaconstraint\\n\\ntextualized token representations in inverted onthemodel,butexactlexicalmatchproducemore ]RI.sc[\\n\\nlists, bringing together the efficiency of exact explainableandcontrolledpatternsthansoftmatch-\\n\\nmatch and the representation power of deep ing. It also allows search to focus on only the\\n\\nlanguage models. Our experimental results\\n\\nsubset of documents that have overlapping terms\\n\\nshow COIL outperforms classical lexical re-\\n\\nwithquery,whichcanbedoneefficientlywithin-\\n\\ntrieversandstate-of-the-artdeepLMretrievers\\n\\n1v68170.4012:viXra\\n\\nvertedlistindex. Meanwhile,usingdensecontex-\\n\\nwithsimilarorsmallerlatency.1\\n\\ntualized token representations enables the model\\n\\n1 Introduction to handle semantic mismatch, which has been a\\n\\nlong-standingprobleminclassiclexicalsystems. Widelyused,bag-of-words(BOW)informationre-\\n\\nToanswerthequestion,weproposeanewlexi-\\n\\ntrieval (IR) systems such as BM25 rely on exact\\n\\ncalmatchingschemethatusesvectorsimilarities\\n\\nlexicalmatch2betweenqueryanddocumentterms. betweenquery-documentoverlappingtermcontex-\\n\\nRecentstudyinneuralIRtakesadifferentapproach\\n\\ntualized representations to replace heuristic scor-\\n\\nandcomputesoftmatchingbetweenallqueryand', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='ing used in classical systems. We present COn-\\n\\ndocumenttermstomodelcomplexmatching. textualizedInvertedList(COIL),anewexactlex-\\n\\nTheshifttosoftmatchinginneuralIRmodels\\n\\nicalmatchretrievalarchitecturearmedwithdeep\\n\\nattemptstoaddressvocabularymismatchproblems,\\n\\nLM representations. COIL processes documents\\n\\nthat query and the relevant documents use differ-\\n\\nwithdeepLMofflineandproducesrepresentations\\n\\nent terms, e.g. cat v.s. kitty, for the same con-\\n\\nforeachdocumenttoken. Therepresentationsare\\n\\ncept(Huangetal.,2013;Guoetal.,2016;Xiong\\n\\ngroupedbytheirsurfacetokensintoinvertedlists. etal.,2017). Laterintroductionofcontextualized\\n\\nAt search time, we build representation vectors\\n\\nrepresentations(Petersetal.,2018)fromdeeplan-\\n\\nfor query tokens and perform contextualized ex-\\n\\nguagemodels(LM)furtheraddresssemanticmis-\\n\\nact match: use each query token to look up its\\n\\nmatch, that the same term can refer to different\\n\\nown inverted list and compute vector similarity\\n\\nconcepts, e.g., bank of river vs. bank in finance. with document vectors stored in the inverted list\\n\\nFine-tuneddeepLMrerankersproducetokenrep-\\n\\nasmatchingscores. COILenablesefficientsearch\\n\\nresentationsbasedoncontextandachievestate-of-\\n\\nwithrich-in-semanticmatchingbetweenqueryand\\n\\n1Our code is available at https://github.com/\\n\\ndocument. luyug/COIL. 2Exactmatchuptomorphologicalchanges. Our contributions include 1) introduce a novelretrieval architecture, contextualized inverted Deep LM Based Ranker and Retriever Deep\\n\\nlists (COIL) that brings semantic matching into LM made a huge impact on neural IR. Fine-\\n\\nlexical IR systems, 2) show matching signals in- tuned Transformer (Vaswani et al., 2017) LM\\n\\nducedfromexactlexicalmatchcancapturecom- BERT(Devlinetal.,2019)achievedstate-of-the-\\n\\nplicatedmatchingpatterns,3)demonstrateCOIL artrerankingperformanceforpassagesanddocu-\\n\\nsignificantly outperform classical and deep LM ments (Nogueira and Cho, 2019; Dai and Callan,\\n\\naugmentedlexicalretrieversaswellasstate-of-the- 2019b). As illustrated in Figure 1a, the common\\n\\nartdenseretrieversontworetrievaltasks. approach is to feed the concatenated query docu-\\n\\nment text through BERT and use BERTs [CLS]\\n\\noutput token to produce a relevance score. The\\n\\n2 RelatedWork\\n\\ndeepLMrerankersaddressedbothvocabularyand\\n\\nsemanticmismatchbycomputingfullcrossatten-\\n\\nLexicalRetriever ClassicalIRsystemsrelyon\\n\\ntionbetweencontextualizedtokenrepresentations. exact lexical match retrievers such as Boolean', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='Lighter deep LM rankers are developed (MacA-\\n\\nRetrieval, BM25 (Robertson and Walker, 1994)\\n\\nvaneyetal.,2020;Gaoetal.,2020),buttheircross\\n\\nandstatisticallanguagemodels(LaffertyandZhai,\\n\\nattentionoperationsarestilltooexpensiveforfull-\\n\\n2001). This type of retrieval model can process\\n\\ncollectionretrieval. queriesveryquicklybyorganizingthedocuments\\n\\nLater research therefore resorted to augment-\\n\\ninto inverted index, where each distinct term has\\n\\ninglexicalretrievalwithdeepLMsbyexpanding\\n\\naninvertedlistthatstoresinformationaboutdocu-\\n\\nthe document surface form to narrow the vocab-\\n\\nmentsitappearsin. Nowadays,theyarestillwidely\\n\\nulary gap, e.g., DocT5Query (Nogueira and Lin,\\n\\nused in production systems. However, these re-\\n\\n2019),oralteringtermweightstoemphasizeimpor-\\n\\ntrievalmodelsfallshortofmatchingrelatedterms\\n\\ntantterms,e.g.,DeepCT(DaiandCallan,2019a). (vocabularymismatch)ormodelingcontextofthe\\n\\nSmartlycombiningdeepLMretrieverandreranker\\n\\nterms (semantic mismatch). Much early effort\\n\\ncanofferadditivegainforendperformance(Gao\\n\\nwasputintoimprovingexactlexicalmatchretriev-\\n\\netal.,2021a). Theseretrievershoweverstillsuffer\\n\\ners,suchasmatchingn-grams(MetzlerandCroft,\\n\\nfromvocabularyandsemanticmismatchastradi-\\n\\n2005)orexpandingquerieswithtermsfromrelated\\n\\ntionallexicalretrievers. documents(LavrenkoandCroft,2001). However,\\n\\nthesemethodsstilluseBOWframeworkandhave Anotherlineofresearchcontinuestheworkon\\n\\nlimitedcapabilityofmodelinghumanlanguages. singlevectorrepresentationandbuilddenseretriev-\\n\\ners, as illustrated in Figure 1b. They store docu-\\n\\nment vectors in a dense index and retrieve them\\n\\nNeural Ranker In order to deal with vocab-\\n\\nthrough Nearest Neighbours search. Using deep\\n\\nulary mismatch, neural retrievers that rely on\\n\\nLMs,denseretrievershaveachievedpromisingre-\\n\\nsoft matching between numerical text represen-\\n\\nsults on several retrieval tasks (Karpukhin et al.,\\n\\ntations are introduced. Early attempts compute\\n\\n2020). Laterresearchesshowthatdenseretrieval\\n\\nsimilarity between pre-trained word embedding\\n\\nsystems can be further improved by better train-\\n\\nsuch as word2vec (Mikolov et al., 2013) and\\n\\ning(Xiongetal.,2020;Gaoetal.,2021b). GLoVe(Penningtonetal.,2014)toproducematch-\\n\\ningscore(Gangulyetal.,2015;Diazetal.,2016). Singlevectorsystemshavealsobeenextended\\n\\nOnemorerecentapproachencodesqueryanddoc- to multi-vector representation systems. Poly-\\n\\numenteachintoavectorandcomputesvectorsim- encoder (Humeau et al., 2020) encodes queries', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='ilarity(Huangetal.,2013). Laterresearchesreal- into a set of vectors. Similarly, Me-BERT (Luan\\n\\nized the limited capacity of a single vector to en- etal.,2020)representsdocumentswithasetofvec-\\n\\ncodefine-grainedinformationandintroducedfull tors. AconcurrentworkColBERT(Figure1c)use\\n\\ninteraction models to perform soft matching be- multiplevectorstoencodebothqueriesanddocu-\\n\\ntween all term vectors (Guo et al., 2016; Xiong ments(KhattabandZaharia,2020). Inparticular,it\\n\\net al., 2017). In these approaches, scoring is representsadocumentswithallitstermsvectors\\n\\nbased onlearned neuralnetworks andthe hugely andaquerywithanexpandedsetoftermvectors. increased computation cost limited their use to It then computesall-to-all (Cartesian) soft match\\n\\nrerankingatopcandidatelistgeneratedbyalexical betweenthetokens. ColBERTperformsinteraction\\n\\nretriever. asdotproductfollowedpoolingoperations,whichscore\\n\\nscore\\n\\nCLS bank account SEP bank river bank\\n\\nCLS bank account SEP bank river bank CLS bank account CLS bank river bank\\n\\nCLS bank account SEP bank river bank CLS bank account CLS bank river bank\\n\\nCLS bank account SEP bank river bank CLS bank account CLS bank river bank\\n\\n(a)Cross-AttentionModel(e.g.,BERTreranker) (b)DenseRetrievers(e.g.,DPR)\\n\\nscore sum\\n\\ndot max\\n\\nmax max max max max\\n\\nCLS bank account EXP EXP CLS bank river bank CLS bank account CLS bank river bank\\n\\nCLS bank account EXP EXP CLS bank river bank CLS bank account CLS bank river bank\\n\\nCLS bank account EXP EXP CLS bank river bank CLS bank account CLS bank river bank\\n\\n(c)ColBERT:All-to-AllMatch (d)COIL:ContextualizedExactMatch\\n\\nFigure1: Anillustrationofreranking/retrievalmechanismswithdeepLM,includingourproposedmodel,COIL. BBMM2255 docid [1 2 3 4 .............C] matrix\\n\\nBank do tc f:i d 1: 1 do tc f:i d 1: 3 do tc f:i d 1: 6 .... ssccoorriinngg Bank CLS vectors ... product CLS\\n\\ndocid: 1 docid: 2 docid: 4 docid: 5\\n\\nRiver tf: 1 tf: 1 tf: 1 tf: 2 .... docid [1 3 6 7]\\n\\nmatrix\\n\\nAccount Bank vectors product\\n\\nBank\\n\\ndocid: 3 docid: 9\\n\\nAccount\\n\\ntf: 2 tf: 1 BM25 docid [1 2 4 5 5 9]\\n\\nscoring River vectors\\n\\nAccount\\n\\nTraditional Inverted Lists Query\\n\\ndocid [3 3 9]\\n\\nFigure 2: An illustration of traditional inverted lists. Account vectors matrix\\n\\nproduct\\n\\nThe inverted list maps a term to the list of documents\\n\\nwherethetermoccurs. Retrieverlooksupqueryterms\\n\\ninverted lists and scores those documents with stored Contextualized Inverted Lists Query', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='statisticssuchastermfrequency(tf). Figure 3: COILs index and retrieval architecture. COIL-tok relies on the exact token matching (lower). COIL-fullincludesinadditionCLSmatching(upper). allowsittoalsoleverageadenseindextodofull\\n\\ncorpusretrieval. However,sinceColBERTencodes\\n\\nadocumentwithalltokens,itaddsanotherorder 3.1 Preliminaries\\n\\nofmagnitudeofindexcomplexitytoallaforemen-\\n\\nClassic lexical retrieval system relies on overlap-\\n\\ntionedmethods: documenttokensinthecollection\\n\\npingquerydocumenttermsundermorphological\\n\\nneed to be stored in a single huge index and con-\\n\\ngeneralizationlikestemming,inotherwords,exact\\n\\nsideredatquerytime. Consequently,ColBERTis\\n\\nlexical match, to score query document pair. A\\n\\nengineeringandhardwaredemanding. scoring function is defined as a sum of matched\\n\\ntermscores. Thescoresareusuallybasedonstatis-\\n\\n3 Methodologies\\n\\ntics like term frequency (tf). Generally, we can\\n\\nwrite,\\n\\nInthissection,wefirstprovidesomepreliminaries\\n\\nonexactlexicalmatchsystems. Thenwediscuss (cid:88)\\n\\ns =  (h (q,t),h (d,t)) (1)\\n\\nt q d\\n\\nCOILscontextualizedexactmatchdesignandhow\\n\\ntqd\\n\\nitssearchindexisorganized. Wealsogiveacom-\\n\\nparisonbetweenCOILandotherpopularretrievers. whereforeachoverlappingtermtbetweenqueryq\\n\\nanddocumentd,functionsh andh extractterm\\n\\nq dinformation and a term scoring function  com- where Wntn lm is a matrix that maps the LMs\\n\\nt tok\\n\\nbines them. A popular example is BM25, which n dimension output into a vector of lower di-\\n\\nlm\\n\\ncomputes, mension n . We down project the vectors as we\\n\\nt\\n\\n(cid:88) hypothesizethatitsufficestouselowerdimension\\n\\ns = idf(t)hBM25(q,t)hBM25(d,t)\\n\\nBM25 q d tokenvectors. Weconfirmthisinsection5. Simi-\\n\\ntqd larly,weencodeadocumentdsj-thtokend with:\\n\\nj\\n\\ntf (1+k )\\n\\nhB qM25(q,t) = tt f,q 22 (2)\\n\\nt,q +k v jd = W tokLM(d,j)+b tok (4)\\n\\ntf (1+k )\\n\\nhBM25(d,t) = t,d 1 Wethendefinethecontextualizedexactlexical\\n\\nd |d|\\n\\ntf +k (1b+b )\\n\\nt,d 1 avgdl match scoring function between query document\\n\\nbasedonvectorsimilaritiesbetweenexactmatched\\n\\nwhere tf refers to term frequency of term t in\\n\\nt,d\\n\\nquerydocumenttokenpairs:\\n\\ndocument d, tf refers to the term frequency in\\n\\nt,q\\n\\nquery,idf(t)isinversedocumentfrequency,andb, s (q,d) = (cid:88) max(vq(cid:124) vd) (5)\\n\\nk ,k arehyper-parameters. tok i j\\n\\n1 2 dj=qi\\n\\nqiqd\\n\\nOne key advantage of exact lexical match sys-\\n\\ntemsliesinefficiency. Withsummationoverexact Notethat,importantly,thesummationgoesthrough\\n\\nmatches,scoringofeachquerytermonlygoesto onlyoverlappingterms,q  qd. Foreachquery\\n\\ni', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='documentsthatcontainmatchingterms. Thiscan tokenq ,wefindsallsametokensd inthedocu-\\n\\ni j\\n\\nbedoneefficientlyusinginvertedlistindexing(Fig- ment, computes their similarity with q using the\\n\\ni\\n\\nure 2). The inverted list maps back from a term contextualized tokenvectors. Themaximumsim-\\n\\nto a list of documents where the term occurs. To ilarities are picked for query token q . Max op-\\n\\ni\\n\\ncompute Equation 1, the retriever only needs to erator is adopted to capture the most important\\n\\ntraverse the subset of documents in query terms signal(Kim,2014). Thisfitsinthegenerallexical\\n\\ninvertedlistsinsteadofgoingovertheentiredocu- matchformulation,withh givingrepresentation\\n\\nq\\n\\nmentcollection. forq ,h givingrepresentationsforalld = q ,and\\n\\ni t j i\\n\\nWhilerecentneuralIRresearchmainlyfocuses  computedotsimilaritiesbetweenqueryvector\\n\\nt\\n\\non breaking the exact match bottleneck with soft withdocumentvectorsandmaxpoolthescores. matchingoftext,wehypothesizethatexactmatch Aswithclassiclexicalsystems,s definedin\\n\\ntok\\n\\nitself can be improved by replacing semantic in-\\n\\nEquation5doesnottakeintoaccountsimilarities\\n\\ndependentfrequency-basedscoringwithsemantic\\n\\nbetweenlexical-differentterms,thusfacesvocabu-\\n\\nrich scoring. In the rest of this section, we show\\n\\nlarymismatch. ManypopularLMs(Devlinetal.,\\n\\nhowtomodifytheexactlexicalmatchframework\\n\\n2019; Yang et al., 2019; Liu et al., 2019) use a\\n\\nwith contextualized term representations to build\\n\\nspecialCLStokentoaggregatesequencerepresen-\\n\\neffectiveandefficientretrievalsystems. WeprojecttheCLSvectoswithWncn\\n\\ntation. lm\\n\\ncls\\n\\ntorepresenttheentirequeryordocument,\\n\\n3.2 ContextualizedExactLexicalMatch\\n\\nInstead of term frequency, we desire to encode vq = W LM(q,CLS)+b\\n\\ncls cls cls\\n\\n(6)\\n\\nthesemanticsoftermstofacilitatemoreeffective\\n\\nvd = W LM(d,CLS)+b\\n\\nmatching. Inspiredbyrecentadvancementsindeep cls cls cls\\n\\nLM,weencodebothqueryanddocumenttokens Thesimilaritybetweenvq andvd provideshigh-\\n\\ncls cls\\n\\nintocontextualizedvectorrepresentationsandcarry\\n\\nlevelsemanticmatchingandmitigatestheissueof\\n\\noutmatchingbetweenexactlexicalmatchedtokens. vocabularymismatch. ThefullformofCOILis:\\n\\nFigure1dillustratesthescoringmodelofCOIL. In this work, we use a Transformer language s (q,d) = s (q,d)+vq (cid:124) vd (7)\\n\\nfull tok cls cls\\n\\nmodel3 as the contextualization function. We en-\\n\\ncodeaqueryq withthelanguagemodel(LM)and In the rest of the paper, we refer to systems with', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='represent its i-th token by projecting the corre- CLSmatchingCOIL-fullandwithoutCOIL-tok. spondingoutput: COILsscoringmodel(Figure1d)isfullydiffer-\\n\\nentiable. Followingearlierwork(Karpukhinetal.,\\n\\nvq = W LM(q,i)+b (3)\\n\\ni tok tok 2020),wetrainCOILwithnegativeloglikelihood\\n\\n3Weusedthebase,uncasedvariantofBERT. definedoverqueryq,apositivedocumentd+ andasetofnegativedocuments{d,d,..d..}asloss. serveinparallel. Thescoresarethencombinedby\\n\\n1 2 l\\n\\nEquation5torankthedocuments. Readerscanfinddetailedillustrationfiguresin\\n\\nexp(s(q,d+))\\n\\nL = log theAppendixA,forindexbuildingandquerying,\\n\\nexp(s(q,d+))+(cid:80) exp(s(q,d))\\n\\nl Figure4andFigure5,respectively. l\\n\\n(8)\\n\\n3.4 ConnectiontoOtherRetrievers\\n\\nFollowingKarpukhinetal. (2020),weuseinbatch\\n\\nnegativesandhardnegativesgeneratedbyBM25. Deep LM based Lexical Index Models like\\n\\nDetailsarediscussedinimplementation,section4. DeepCT (Dai and Callan, 2019a, 2020) and\\n\\nDocT5Query(NogueiraandLin,2019)altertf\\n\\nt,d\\n\\n3.3 IndexandRetrievalwithCOIL indocumentswithdeepLMBERTorT5. Thisis\\n\\nCOILpre-computesthedocumentrepresentations similartoaCOIL-tokwithtokendimensionn t = 1.\\n\\nandbuildsupasearchindex,whichisillustratedin Asingledegreeoffreedomhowevermeasuresmore\\n\\nFigure3. Documentsinthecollectionareencoded ofatermimportancethansemanticagreement. offlineintotokenandCLSvectors. Formally,for\\n\\nDense Retriever Dense retrievers (Figure 1b)\\n\\na unique token t in the vocabulary V, we collect\\n\\nareequivalenttoCOIL-fullsCLSmatching. COIL\\n\\nitscontextualizedvectorsfromallofitsmentions\\n\\nmakes up for the lost token-level interactions in\\n\\nfromdocumentsincollectionC,buildingtokents\\n\\ndenseretrieverwithexactmatchingsignals. contextualizedinvertedlist:\\n\\nColBERT ColBERT (Figure 1c) computes rel-\\n\\nIt = {v jd | d j = t,d  C}, (9) evance by soft matching all query and document\\n\\ntermscontextualizedvectors. where vd is the BERT-based token encoding de-\\n\\nfined inj Equation 4. We define search index to s(q,d) = (cid:88) max (vq(cid:124) vd) (10)\\n\\ni j\\n\\nqi[cls;q;exp]dj[cls;d]\\n\\nstore inverted lists for all tokens in vocabulary,\\n\\nI = {It | t  V}. ForCOIL-full,wealsobuildan\\n\\nwhere interactions happen among query q, docu-\\n\\nindexfortheCLStokenIcls = {vd | d  C}. cls mentd,clsandsetofqueryexpansiontokensexp. As shown in Figure 3, in this work we im-\\n\\nTheall-to-allmatchcontrastsCOILthatonlyuses\\n\\nplement COILs by stacking vectors in each in-\\n\\nverted list It into a matrix Mnt|Ik|, so that sim- exactmatch. Itrequiresadenseretrievaloverall', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='document tokens representations as opposed to\\n\\nilarity computation that traverses an inverted list\\n\\nCOILwhichonlyconsidersquerysoverlappingto-\\n\\nand computes vector dot product can be done ef-\\n\\nkens,andarethereforemuchmorecomputationally\\n\\nficiently as one matrix-vector product with opti-\\n\\nexpensivethanCOIL. mizedBLAS(Blackfordetal.,2002)routineson\\n\\nCPUorGPU.Allvd vectorscanalsobeorganized\\n\\ncls 4 ExperimentMethodologies\\n\\nin a similarfashioninto matrix M and queried\\n\\ncls\\n\\nwith matrix product. The matrix implementation Datasets Weexperimentwithtwolargescalead\\n\\nhereisanexhaustiveapproachthatinvolvesallvec- hoc retrieval benchmarks from the TREC 2019\\n\\ntors in an inverted list. As a collection of dense Deep Learning (DL) shared task: MSMARCO\\n\\nvectors,itisalsopossibletoorganizeeachinverted passage (8M English passages of average length\\n\\nlistasanapproximatesearchindex(Johnsonetal., around60tokens)andMSMARCOdocument(3M\\n\\n2017;Guoetal.,2019)tofurtherspeedupsearch. Englishdocumentsofaveragelengtharound900\\n\\nWhen a query q comes in, we encode every of tokens)4. For each, we train models with the\\n\\nits token into vectors vq . The vectors are sent to MSMARCO Train queries, and record results on\\n\\ni\\n\\nthesubsetofCOILinvertedliststhatcorresponds MSMARCO Dev queries and TREC DL 2019\\n\\nquery tokens J = {It | t  q}. where the matrix test queries. We report mainly full-corpus re-\\n\\nproduct described above is carried out. This is trieval results but also include the rerank task on\\n\\nefficientas|J| << |I|,havingonlyasmallsubset MSMARCO Dev queries where we use neural\\n\\nof all inverted lists to be involved in search. For scorestoreorderBM25retrievalresultsprovided\\n\\nCOIL-full,wealsouseencodedCLSvectorsvq byMSMAROorganizers. Officialmetricsinclude\\n\\ncls\\n\\nto query the CLS index to get the CLS matching\\n\\n4Both datasets can be downloaded from https://\\n\\nscores. Thescoringoverdifferentinvertedlistscan microsoft.github.io/msmarco/MRR@1KandNDCG@10ontestandMRR@10 overcontextualizedinvertedlists,b)scattertomap\\n\\nonMSMARCODev. Wealsoreportrecallforthe tokenscoresbacktodocuments,andc)sorttorank\\n\\ndevqueriesfollowingpriorwork(DaiandCallan, the documents. Illustration can be found in the\\n\\n2019a;NogueiraandLin,2019). appendix,Figure5. Compared Systems Baselines include 1) tradi- 5 Results\\n\\ntionalexactmatchsystemBM25,2)deepLMaug-\\n\\nThis section studies the effectiveness of COIL\\n\\nmentedBM25systemsDeepCT(DaiandCallan,\\n\\nand how vector dimension in COIL affects the\\n\\n2019a)andDocT5Query(NogueiraandLin,2019),', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='effectiveness-efficiencytradeoff. Wealsoprovide\\n\\n3) dense retrievers, and 4) soft all-to-all retriever\\n\\nqualitativeanalysisoncontextualizedexactmatch. ColBERT.ForDeepCTandDocT5Query,weuse\\n\\nthe rankings provided by the authors. For dense\\n\\n5.1 MainResults\\n\\nretrievers, we report two dense retrievers trained\\n\\nTable 1 reports various systems performance on\\n\\nwith BM25 negatives or with mixed BM25 and\\n\\nthe MARCO passage collection. COIL-tok ex-\\n\\nrandomnegatives,publishedinXiongetal.(2020). act lexical match only system significantly out-\\n\\nHoweversincethesesystemsusearobustversion\\n\\nperforms all previous lexical retrieval systems. of BERT, RoBERTa (Liu et al., 2019) as the LM\\n\\nWith contextualized term similarities, COIL-tok\\n\\nandtraindocumentretrieveralsoonMSMARCO\\n\\nachievesaMRRof0.34comparedtoBM25sMRR\\n\\npassageset,weinadditionreproduceathirddense\\n\\n0.18. DeepCT and DocT5Query, which also use\\n\\nretriever,thatusestheexactsametrainingsetupas\\n\\ndeepLMslikeBERTandT5,areabletobreakthe\\n\\nCOIL.Alldenseretrieversuse768dimensionem-\\n\\nlimitofheuristictermfrequenciesbutarestilllim-\\n\\nbedding. ForColBERT,wereportitspublishedre-\\n\\nitedbysemanticmismatchissues. WeseeCOIL-\\n\\nsults(availableonlyonpassagecollection). BERT\\n\\ntokoutperformsbothsystemsbyalargemargin. rerankerisaddedinthereranktask. COIL-tokalsorankstopofthecandidatelistbet-\\n\\nWeinclude2COILsystems: 1)COIL-tok,the\\n\\nter than dense retrieves. It prevails in MRR and\\n\\nexacttokenmatchonlysystem,and2)COLL-full,\\n\\nNDCG while performs on par in recall with the\\n\\nthemodelwithbothtokenmatchandCLSmatch. best dense system, indicating that COILs token\\n\\nlevelinteractioncanimproveprecision. Withthe\\n\\nImplementation We build our models with Py-\\n\\nCLSmatchingadded,COIL-fullgainstheability\\n\\ntorch (Paszke et al., 2019) based on huggingface\\n\\nto handle mismatched vocabulary and enjoys an-\\n\\ntransformers (Wolf et al., 2019). COILs LM is\\n\\nother performance leap, outperforming all dense\\n\\nbasedonBERTsbasevariant. COILsystemsuse\\n\\nretrievers. tokendimensionn = 32andCOIL-fulluseCLS\\n\\nt\\n\\ndimension n = 768 as default, leading to 110M COIL-fullachievesaverynarrowperformance\\n\\nc\\n\\ngaptoColBERT.RecallthatColBERTcomputes\\n\\nparameters. WeaddaLayerNormalizationtoCLS\\n\\nall-to-allsoftmatchesbetweenalltokenpairs. For\\n\\nvector when useful. All models are trained for 5\\n\\nretrieval,itneedstoconsiderforeachquerytoken\\n\\nepochswithAdamWoptimizer,alearningrateof\\n\\nall mentions of all tokens in the collection (MS-\\n\\n3e-6, 0.1 warm-up ratio, and linear learning rate', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='MARCOpassagecollectionhasaround500Mto-\\n\\ndecay, which takes around 12 hours. Hard neg-\\n\\nkenmentions). COIL-fullisabletocapturematch-\\n\\natives are sampled from top 1000 BM25 results. ingpatternsaseffectivelywithexactmatchsignals\\n\\nEach query uses 1 positive and 7 hard negatives;\\n\\nfromonlyquerytokensmentionsandasingleCLS\\n\\neachbatchuses8queriesonMSMARCOpassage\\n\\nmatchingtobridgethevocabularygap. and4onMSMARCOdocument. Documentsare\\n\\ntruncated to the first 512 tokens to fit in BERT. Weobserveasimilarpatterninthereranktask. We conduct validation on randomly selected 512 COIL-tok is already able to outperform dense re-\\n\\nqueriesfromcorrespondingtrainset. Latencynum- triever and COIL-full further adds up to perfor-\\n\\nbers are measured on dual Xeon E5-2630 v3 for mancewithCLSmatching,beingon-parwithCol-\\n\\nCPU and RTX 2080 ti for GPU. We implement BERT.Meanwhile,previousBERTrerankershave\\n\\nlittleperformanceadvantageoverCOIL5.Inprac-\\n\\nCOILs inverted lists as matrices as described in\\n\\nsubsection3.3,usingNumPy(Harrisetal.,2020) tice, we found BERT rerankers to be much more\\n\\nonCPUandPytorchonGPU.Weperforma)aset\\n\\n5CloseperformancebetweenCOILandBERTrerankers\\n\\nof matrix products to compute token similarities ispartiallyduetothebottleneckofBM25candidates.Table1: MSMARCOpassagecollectionresults. Resultsnotapplicablearedenotedandnoavailablen.a..\\n\\nMSMARCOPassageRanking\\n\\nDevRerank DevRetrieval DL2019Retrieval\\n\\nModel MRR@10 MRR@10 Recall@1K NDCG@10 MRR@1K\\n\\nLexicalRetriever\\n\\nBM25  0.184 0.853 0.506 0.825\\n\\nDeepCT  0.243 0.909 0.572 0.883\\n\\nDocT5Query  0.278 0.945 0.642 0.888\\n\\nBM25+BERTreranker 0.347\\n\\nDenseRetriever\\n\\nDense(BM25neg) n.a. 0.299 0.928 0.600 n.a. Dense(rand+BM25neg) n.a. 0.311 0.952 0.576 n.a. Dense(ourtrain) 0.312 0.304 0.932 0.635 0.898\\n\\nColBERT 0.349 0.360 0.968 n.a. n.a. COIL-tok 0.336 0.341 0.949 0.660 0.915\\n\\nCOIL-full 0.348 0.355 0.963 0.704 0.924\\n\\nTable2: MSMARCOdocumentcollectionresults. Resultsnotapplicablearedenotedandnoavailablen.a..\\n\\nMSMARCODocumentRanking\\n\\nDevRerank DevRetrieval DL2019Retrieval\\n\\nModel MRR@10 MRR@10 Recall@1K NDCG@10 MRR@1K\\n\\nLexicalRetriever\\n\\nBM25  0.230 0.886 0.519 0.805\\n\\nDeepCT  0.320 0.942 0.544 0.891\\n\\nDocT5Query  0.288 0.926 0.597 0.837\\n\\nBM25+BERTreranker 0.383\\n\\nDenseRetriever\\n\\nDense(BM25neg) n.a. 0.299 0.928 0.600 n.a. Dense(rand+BM25neg) n.a. 0.311 0.952 0.576 n.a. Dense(ourtrain) 0.358 0.340 0.883 0.546 0.785\\n\\nCOIL-tok 0.381 0.385 0.952 0.626 0.921\\n\\nCOIL-full 0.388 0.397 0.962 0.636 0.913', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='expensive, requiring over 2700 ms for reranking 5.2 AnalysisofDimensionality\\n\\ncomparedtoaround10msinthecaseofCOIL. ThesecondexperimenttestshowvaryingCOILs\\n\\nTable2reportstheresultsonMSMARCOdocu-\\n\\ntokendimensionn andCLSdimensionn affect\\n\\nmentcollection. Ingeneral,weobserveasimilar t c\\n\\nmodeleffectivenessandefficiency. Werecordre-\\n\\npattern as with the passage case. COIL systems\\n\\ntrievalperformanceandlatencyonMARCOpas-\\n\\nsignificantlyoutperformbothlexicalanddensesys-\\n\\nsagecollectioninTable3. temsinMRRandNDCGandretainasmalladvan-\\n\\ntage measured in recall. The results suggest that InCOIL-fullsystems,reducingCLSdimension\\n\\nCOILcanbeapplicabletolongerdocumentswith from 768 to 128 leads to a small drop in perfor-\\n\\naconsistentadvantageineffectiveness. mance on the Dev set, indicating that a full 768\\n\\ndimensionmaynotbenecessaryforCOIL.Keep-\\n\\nTheresultsindicateexactlexicalmatchmecha-\\n\\ning CLS dimension at 128, systems with token\\n\\nnismcanbegreatlyimprovedwiththeintroduction\\n\\ndimension32and8haveverysmallperformance\\n\\nofcontextualizedrepresentationinCOIL.COILs\\n\\ndifference,suggestingthattoken-specificsemantic\\n\\ntoken-level match also yields better fine-grained\\n\\nconsumesmuchfewerdimensions. Similarpattern\\n\\nsignalsthandenseretrieversglobalmatchsignal. inn isalsoobservedinCOIL-tok(n = 0). COIL-fullfurthercombinesthelexicalsignalswith t c\\n\\ndenseCLSmatch,formingasystemthatcandeal OntheDL2019queries,weobservethatreduc-\\n\\nwithbothvocabularyandsemanticmismatch,be- ingdimensionactuallyachievesbetterMRR.We\\n\\ningaseffectiveasall-to-allsystem. believe this is due to a regulatory effect, as theTable3: PerformanceandlatencyofCOILsystemswithdifferentrepresentationdimensions. Resultsnotapplica-\\n\\nblearedenotedandnoavailablen.a.. Heren denotesCOILCLSdimensionandn tokenvectordimension. c t\\n\\n: ColBERTuseapproximatesearchandquantization. WeexcludeI/Otimefrommeasurements. DevRetrieval DL2019Retrieval Latency/ms\\n\\nModel MRR@10 Recall@1K NDCG@10 MRR CPU GPU\\n\\nBM25 0.184 0.853 0.506 0.825 36 n.a. Dense 0.304 0.932 0.635 0.898 293 32\\n\\nColBERT 0.360 0.968 n.a. n.a. 458*\\n\\nCOIL\\n\\nn n\\n\\nc t\\n\\n768 32 0.355 0.963 0.704 0.924 380 41\\n\\n128 32 0.350 0.953 0.692 0.956 125 23\\n\\n128 8 0.347 0.956 0.694 0.977 113 21\\n\\n0 32 0.341 0.949 0.660 0.915 67 18\\n\\n0 8 0.336 0.940 0.678 0.953 55 16\\n\\nTable4:SamplequerydocumentpairswithsimilarityscoresproducedbyCOIL.Tokensinexaminationarecolored', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='blue. Numbersinbracketsarequery-documentvectorsimilaritiescomputedwithvectorsgeneratedbyCOIL. QueryToken COILContextualizedExactMatchScore Relevance\\n\\nCabinet [16.28] (government) A cabinet [16.75] is a body of high-\\n\\n+\\n\\nwhatisacabinetingovt rankingstateofficials,typicallyconsistingofthetopleadersofthe.... Cabinet[7.23]is20x60andtopis28x72.....Ihada2cmgranitecounter-\\n\\ntopinstalledwitha10inchoverhangononesideanda14inch....\\n\\nPriorityPass[11.61]isanindependentairportloungeaccessprogram.A\\n\\n+\\n\\nwhatisprioritypass membershipprovidesyouwithaccesstotheirnetworkofover700....\\n\\nSnoqualmiePass[7.98]isamountainpass[6.83]thatcarriesInterstate\\n\\n90throughtheCascadeRangeintheU.S.StateofWashington....\\n\\nNJSTARTis[1.25]aself-serviceonlineplatformthatallowsvendorsto\\n\\n+\\n\\nwhatisnjstart manageforms,certifications,submitproposals,accesstraining....\\n\\nContractawardeeswillreceivetheirBlanketP.O.onceitis[-0.10]con-\\n\\nverted,anddetailsregardingthatprocesswillalsobesent...\\n\\ntestquerieswerelabeleddifferentlyfromtheMS- 5.3 CaseStudy\\n\\nMARCOtrain/devqueries(Craswelletal.,2020). COILdiffersfromallpreviousembedding-based\\n\\nmodelsinthatitdoesnotuseasingleunifiedem-\\n\\nWe also record CPU and GPU search latency\\n\\nbeddingspace. Instead,foraspecifictoken,COIL\\n\\nin Table 3. Lowering COIL-fulls CLS dimen-\\n\\nlearnsanembeddingspacetoencodeandmeasure\\n\\nsionfrom768to128givesabigspeedup,making\\n\\nthe semantic similarity of the token in different\\n\\nCOIL faster than DPR system. Further dropping\\n\\ncontexts. Inthissection,weshowexampleswhere\\n\\ntokendimensionsprovidesomeextraspeedup. The\\n\\nCOILdifferentiatesdifferentsensesofawordun-\\n\\nCOIL-toksystemsrunfasterthanCOIL-full,witha\\n\\nder different contexts. In Table 4, we show how\\n\\nlatencyofthesameorderofmagnitudeasthetradi-\\n\\nthetokensimilarityscoresdifferacrosscontextsin\\n\\ntionalBM25system. Importantly,lowerdimension\\n\\nrelevantandirrelevantquerydocumentpairs. COILsystemsstillretainaperformanceadvantage\\n\\nover dense systems while being much faster. We Thefirstquerylooksforcabinetinthecontext\\n\\nincludeColBERTslatencyreportedintheoriginal of govt (abbreviation for government). The\\n\\npaper,whichwasoptimizedbyapproximatesearch twodocumentsbothincludequerytoken\"cabinet\"\\n\\nand quantization. All COIL systems have lower but of a different concept. The first one refers to\\n\\nlatencythanColBERTeventhoughourcurrentim- the government cabinet and the second to a case\\n\\nplementationdoesnotusethoseoptimizationtech- orcupboard. COILmanagestomatchcabinetin', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='niques. Wehowevernotethatapproximatesearch the query to cabinet in the first document with\\n\\nandquantizationareapplicabletoCOIL,andleave amuchhigherscore. Inthesecondquery,\"pass\"\\n\\nthestudyofspeedingupCOILtofuturework. inbothdocumentsrefertotheconceptofpermis-sion. However, through contextualization, COIL WithourCOILsystemsshowingviablesearch\\n\\ncapturesthevariationofthesameconceptandas- latency, we believe this paper makes a solid step\\n\\nsignsahigherscoretopassinthefirstdocument. towardsbuildingnext-generationindexthatstores\\n\\nStop words like it, a, and the are com- semantics. Attheintersectionoflexicalandneural\\n\\nmonlyremovedinclassicexactmatchIRsystems systems,efficientalgorithmsproposedforbothcan\\n\\nas they are not informative on their own. In the pushCOILtowardsreal-worldsystems. third query, on the other hand, we observe that\\n\\nCOILisabletodifferentiateisinanexplanatory\\n\\nsentenceandisinapassiveform,assigningthe\\n\\nfirsthigherscoretomatchquerycontext. All examples here show that COIL can go be-\\n\\nyond matching token surface form and introduce\\n\\nrichcontextinformationtoestimatematching. Dif-\\n\\nferencesinsimilarityscoresacrossmentionsunder\\n\\ndifferentcontextsdemonstratehowCOILsystems\\n\\ngainstrengthoverlexicalsystems. 6 ConclusionandFutureWork\\n\\nExactlexicalmatchsystemshavebeenwidelyused\\n\\nfordecadesinclassicalIRsystemsandprovetobe\\n\\neffectiveandefficient. Inthispaper,wepointout\\n\\nacriticalproblem,semanticmismatch,thatgener-\\n\\nally limits all IR systems based on surface token\\n\\nfor matching. To fix semantic mismatch, we in-\\n\\ntroducecontextualizedexactmatchtodifferentiate\\n\\nthesametokenindifferentcontexts,providingef-\\n\\nfective semantic-aware token match signals. We\\n\\nfurtherproposecontextualizedinvertedlist(COIL)\\n\\nsearch index which swaps token statistics in in-\\n\\nvertedlistswithcontextualizedvectorrepresenta-\\n\\ntionstoperformeffectivesearch. Ontwolarge-scaleadhocretrievalbenchmarks,\\n\\nwe find COIL substantially improves lexical re-\\n\\ntrieval and outperforms state-of-the-art dense re-\\n\\ntrievalsystems. Theseresultsindicatelargehead-\\n\\nroomofthesimple-but-efficientexactlexicalmatch\\n\\nscheme. When the introduction of contextualiza-\\n\\ntionhandlestheissueofsemanticmismatch,exact\\n\\nmatchsystemgainsthecapabilityofmodelingcom-\\n\\nplicatedmatchingpatternsthatwerenotcaptured\\n\\nbyclassicalsystems. Vocabulary mismatch in COIL can also be\\n\\nlargely mitigated with a high-level CLS vector\\n\\nmatching. The full system performs on par with\\n\\nmore expensive and complex all-to-all match re-', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='trievers. Thesuccessofthefullsystemalsoshows\\n\\nthatdenseretrievalandCOILsexacttokenmatch-\\n\\ninggivecomplementaryeffects,withCOILmaking\\n\\nupdensesystemslosttokenlevelmatchingsignals\\n\\nanddensesolvingthevocabularymismatchproba-\\n\\nblyforCOIL.References ECIR2021,VirtualEvent,March28-April1,2021,\\n\\nProceedings,PartI. S.Blackford,J.Demmel,J.Dongarra,I.Duff,S.Ham-\\n\\nmarling, Greg Henry, M. Hroux, L. Kaufman, An-\\n\\nJ. Guo, Y. Fan, Qingyao Ai, and W. Croft. 2016. A\\n\\ndrewLumsdaine,A.Petitet,R.Pozo,K.Remington,\\n\\ndeeprelevancematchingmodelforad-hocretrieval. andC.Whaley.2002. Anupdatedsetofbasiclinear\\n\\nProceedingsofthe25thACMInternationalonCon-\\n\\nalgebra subprograms (blas). ACM Transactions on\\n\\nference on Information and Knowledge Manage-\\n\\nMathematicalSoftware,28. ment. Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel\\n\\nCampos, and Ellen M Voorhees. 2020. Overview R.Guo,PhilipY.Sun,E.Lindgren,QuanGeng,David\\n\\nofthetrec2019deeplearningtrack. arXivpreprint Simcha, Felix Chern, and S. Kumar. 2019. Accel-\\n\\narXiv:2003.07820. eratinglarge-scaleinferencewithanisotropicvector\\n\\nquantization. arXiv: Learning. Zhuyun Dai and J. Callan. 2019a. Context-aware sen-\\n\\ntence/passage term importance estimation for first Charles R. Harris, K. Jarrod Millman, Stfan J\\n\\nstageretrieval. ArXiv,abs/1910.10687. vanderWalt,RalfGommers,PauliVirtanen,David\\n\\nCournapeau, Eric Wieser, Julian Taylor, Sebas-\\n\\nZhuyunDaiandJ.Callan.2020. Context-awaredocu- tian Berg, Nathaniel J. Smith, Robert Kern, Matti\\n\\nmenttermweightingforad-hocsearch. Proceedings Picus, Stephan Hoyer, Marten H. van Kerkwijk,\\n\\nofTheWebConference2020. MatthewBrett,AllanHaldane,JaimeFernndezdel\\n\\nRo, Mark Wiebe, Pearu Peterson, Pierre Grard-\\n\\nZhuyunDaiandJamieCallan.2019b. Deepertextun-\\n\\nMarchant, Kevin Sheppard, Tyler Reddy, Warren\\n\\nderstanding for IR with contextual neural language\\n\\nWeckesser, Hameer Abbasi, Christoph Gohlke, and\\n\\nmodeling. InProceedingsofthe42ndInternational\\n\\nTravisE.Oliphant.2020. Arrayprogrammingwith\\n\\nACM SIGIR Conference on Research and Develop-\\n\\nNumPy. Nature. ment in Information Retrieval, SIGIR 2019, Paris,\\n\\nFrance,July21-25,2019,pages985988.ACM. Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng,\\n\\nAlex Acero, and Larry Heck. 2013. Learning deep\\n\\nJ.Devlin,Ming-WeiChang,KentonLee,andKristina\\n\\nstructured semantic models for web search using\\n\\nToutanova.2019. Bert: Pre-trainingofdeepbidirec-\\n\\nclickthroughdata. InProceedingsofthe22ndACM\\n\\ntional transformers for language understanding. In', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='international conference on Information & Knowl-\\n\\nNAACL-HLT. edgeManagement. Fernando Diaz, Bhaskar Mitra, and Nick Craswell. 2016. Query expansion with locally-trained word Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux,\\n\\nembeddings. In Proceedings of the 54th Annual and J. Weston. 2020. Poly-encoders: Architec-\\n\\nMeeting of the Association for Computational Lin- turesandpre-trainingstrategiesforfastandaccurate\\n\\nguistics. multi-sentencescoring. InICLR. Debasis Ganguly, Dwaipayan Roy, Mandar Mitra, J. Johnson, M. Douze, and H. Jgou. 2017. Billion-\\n\\nand Gareth J. F. Jones. 2015. Word embedding scale similarity search with gpus. ArXiv,\\n\\nbased generalized language model for information abs/1702.08734. retrieval. In Proceedings of the 38th International\\n\\nACM SIGIR Conference on Research and Develop- V. Karpukhin, Barlas Oguz, Sewon Min, Patrick\\n\\nmentinInformationRetrieval. Lewis, Ledell Yu Wu, Sergey Edunov, Danqi\\n\\nChen, and W. Yih. 2020. Dense passage re-\\n\\nLuyuGao,ZhuyunDai,andJamieCallan.2020. Mod-\\n\\ntrievalforopen-domainquestionanswering. ArXiv,\\n\\nularized transfomer-based ranking framework. In\\n\\nabs/2004.04906. Proceedings of the 2020 Conference on Empirical\\n\\nMethods in Natural Language Processing, EMNLP\\n\\nO. Khattab and M. Zaharia. 2020. Colbert: Efficient\\n\\n2020, Online, November 16-20, 2020. Association\\n\\nandeffectivepassagesearchviacontextualizedlate\\n\\nforComputationalLinguistics. interactionoverbert. Proceedingsofthe43rdInter-\\n\\nnational ACM SIGIR Conference on Research and\\n\\nLuyuGao,ZhuyunDai,andJamieCallan.2021a. Re-\\n\\nDevelopmentinInformationRetrieval. think training of BERT rerankers in multi-stage re-\\n\\ntrieval pipeline. In Advances in Information Re-\\n\\ntrieval-43rdEuropeanConferenceonIRResearch, Yoon Kim. 2014. Convolutional neural networks for\\n\\nECIR2021,VirtualEvent,March28-April1,2021, sentenceclassification. InEMNLP. Proceedings,PartII. JohnLaffertyandChengxiangZhai.2001. Document\\n\\nLuyuGao,ZhuyunDai,TongfeiChen,ZhenFan,Ben- languagemodels,querymodels,andriskminimiza-\\n\\njamin Van Durme, and Jamie Callan. 2021b. Com- tionforinformationretrieval. InProceedingsofthe\\n\\nplementlexicalretrievalmodelwithsemanticresid- 24th Annual International ACM SIGIR Conference\\n\\nual embeddings. In Advances in Information Re- on Research and Development in Information Re-\\n\\ntrieval-43rdEuropeanConferenceonIRResearch, trieval.VictorLavrenkoandW.BruceCroft.2001. Relevance- model for probabilistic weighted retrieval. In Pro-', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='basedlanguagemodels. InProceedingsofthe24th ceedings of the 17th Annual International ACM-\\n\\nAnnualInternationalACMSIGIRConferenceonRe- SIGIRConferenceonResearchandDevelopmentin\\n\\nsearchandDevelopmentinInformationRetrieval. InformationRetrieval. Y. Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\\n\\nJoshi, Danqi Chen, Omer Levy, M. Lewis, Luke Uszkoreit,LlionJones,AidanN.Gomez,L.Kaiser,\\n\\nZettlemoyer, and Veselin Stoyanov. 2019. Roberta: andIlliaPolosukhin.2017. Attentionisallyouneed. A robustly optimized bert pretraining approach. InNIPS. ArXiv,abs/1907.11692. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien\\n\\nChaumond, ClementDelangue, AnthonyMoi, Pier-\\n\\nYi Luan, Jacob Eisenstein, Kristina Toutanova, and\\n\\nric Cistac, Tim Rault, Rmi Louf, Morgan Funtow-\\n\\nM. Collins. 2020. Sparse, dense, and atten-\\n\\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\\n\\ntional representations for text retrieval. ArXiv,\\n\\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\\n\\nabs/2005.00181. Teven Le Scao, Sylvain Gugger, Mariama Drame,\\n\\nQuentin Lhoest, and Alexander M. Rush. 2019. SeanMacAvaney,F.Nardini,R.Perego,N.Tonellotto,\\n\\nHuggingfacestransformers: State-of-the-artnatural\\n\\nNazliGoharian,andO.Frieder.2020. Efficientdoc-\\n\\nlanguageprocessing. ArXiv,abs/1910.03771. umentre-rankingfortransformersbyprecomputing\\n\\ntermrepresentations. Proceedingsofthe43rdInter-\\n\\nChenyan Xiong, Zhuyun Dai, J. Callan, Zhiyuan Liu,\\n\\nnational ACM SIGIR Conference on Research and\\n\\nandR.Power.2017. End-to-endneuralad-hocrank-\\n\\nDevelopmentinInformationRetrieval. ing with kernel pooling. Proceedings of the 40th\\n\\nInternational ACM SIGIR Conference on Research\\n\\nDonaldMetzlerandW.BruceCroft.2005. Amarkov\\n\\nandDevelopmentinInformationRetrieval. randomfieldmodelfortermdependencies. InSIGIR\\n\\n2005: Proceedingsofthe28thAnnualInternational\\n\\nLee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang,\\n\\nACM SIGIR Conference on Research and Develop-\\n\\nJ.Liu,P.Bennett,JunaidAhmed,andArnoldOver-\\n\\nmentinInformationRetrieval. wijk.2020. Approximatenearestneighbornegative\\n\\ncontrastive learning for dense text retrieval. ArXiv,\\n\\nTomas Mikolov, Ilya Sutskever, Kai Chen, G. S. Cor-\\n\\nabs/2007.00808. rado,andJ.Dean.2013. Distributedrepresentations\\n\\nofwordsandphrasesandtheircompositionality. In Z. Yang, Zihang Dai, Yiming Yang, J. Carbonell,\\n\\nNIPS. R. Salakhutdinov, and Quoc V. Le. 2019. Xlnet:\\n\\nGeneralizedautoregressivepretrainingforlanguage', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='RodrigoNogueiraandKyunghyunCho.2019. Passage understanding. InNeurIPS. re-rankingwithbert. ArXiv,abs/1901.04085. Rodrigo Nogueira and Jimmy Lin. 2019. From\\n\\ndoc2querytodoctttttquery. Adam Paszke, Sam Gross, Francisco Massa, Adam\\n\\nLerer, James Bradbury, Gregory Chanan, Trevor\\n\\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\\n\\nAntiga, Alban Desmaison, Andreas Kopf, Edward\\n\\nYang, ZacharyDeVito, MartinRaison, AlykhanTe-\\n\\njani,SasankChilamkurthy,BenoitSteiner,LuFang,\\n\\nJunjie Bai, and Soumith Chintala. 2019. Py-\\n\\ntorch: An imperative style, high-performance deep\\n\\nlearning library. In H. Wallach, H. Larochelle,\\n\\nA.Beygelzimer,F.d\\'Alch-Buc,E.Fox,andR.Gar-\\n\\nnett, editors, Advances in Neural Information Pro-\\n\\ncessingSystems32.CurranAssociates,Inc. Jeffrey Pennington, R. Socher, and Christopher D.\\n\\nManning.2014. Glove:Globalvectorsforwordrep-\\n\\nresentation. InEMNLP. MatthewE.Peters,MarkNeumann,MohitIyyer,Matt\\n\\nGardner, Christopher Clark, Kenton Lee, and Luke\\n\\nZettlemoyer.2018. Deepcontextualizedwordrepre-\\n\\nsentations. ArXiv,abs/1802.05365. Stephen E Robertson and Steve Walker. 1994. Some\\n\\nsimple effective approximations to the 2-poissonA Appendix\\n\\nA.1 IndexBuildingIllustration\\n\\nThe following figure demonstrates how the document \"apple pie baked ...\" is indexed by COIL. The\\n\\ndocumentisfirstprocessedbyafine-tuneddeepLMtoproduceforeachtokenacontextualizedvector. Thevectorsofeachterm\"apple\"and\"juice\"arecollectedtothecorrespondinginvertedlistindexalong\\n\\nwiththedocumentidforlookup. Document #10 - apple pie baked ...\\n\\napple pie baked\\n\\nLM\\n\\nu apple v pie w baked\\n\\n10\\n\\nuv\\n\\n10\\n\\napple\\n\\nvv\\n\\n10\\n\\npie\\n\\nwv\\n\\nbaked\\n\\nFigure4: COILIndexBuildingofdocument\"applepiebaked...\"A.2 SearchIllustration\\n\\nThefollowingfiguredemonstrateshowthequery\"applejuice\"isprocessedbyCOIL.Contextualized\\n\\nvectorsofeachterm\"apple\"and\"juice\"gotothecorrespondinginvertedlistindexconsistingofalookup\\n\\nidarrayandamatrixstackedfromdocumenttermvectors. Foreachindex,amatrixvectorproductisrun\\n\\ntoproduceanarrayofscores. Afterwardsamax-scatterofscoresfollowedbyasortproducesthefinal\\n\\nranking. Noteforeachindex,weshowonlyoperationsforasubsetofvectors(3vectors)intheindex\\n\\nmatrix. Query: apple juice\\n\\nIndex Index\\n\\napple juice\\n\\n677 579\\n\\nv u v w\\n\\nMatrix Vector Product\\n\\nxyz Score pqr Score\\n\\n677 Idx 579 Idx\\n\\nxyz Score pqr Score\\n\\nMax Scatter\\n\\nSort\\n\\nSorting\\n\\nFigure5: COILSearchofquery\"applejuice\".A Few Brief Notes on DeepImpact, COIL, and a Conceptual\\n\\nFramework for Information Retrieval Techniques\\n\\nJimmyLin and XueguangMa', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='DavidR.CheritonSchoolofComputerScience\\n\\nUniversityofWaterloo\\n\\nAbstract Dense Sparse\\n\\nSupervised DPR,ANCE DeepImpact,COIL\\n\\nUnsupervised LSI,LDA BM25,tfidf\\n\\nRecentdevelopmentsinrepresentationallearn-\\n\\ningforinformationretrievalcanbeorganized Table 1: Our conceptual framework for organizing re-\\n\\ninaconceptualframeworkthatestablishestwo centdevelopmentsininformationretrieval. 1202\\n\\npairsofcontrasts:sparsevs.denserepresenta-\\n\\ntionsandunsupervisedvs.learnedrepresenta-\\n\\ntions. Sparse learned representations can fur- et al., 2021), can be understood as learned dense\\n\\nther be decomposed into expansion and term\\n\\nrepresentations for retrieval. This is formulated nuJ\\n\\nweighting components. This framework al-\\n\\nas a representational learning problem where the\\n\\nlowsustounderstandtherelationshipbetween\\n\\ntaskistolearn(transformer-based)encodersthat\\n\\nrecently proposed techniques such as DPR, 82\\n\\nmapqueriesanddocumentsintodensefixed-width\\n\\nANCE,DeepCT,DeepImpact,andCOIL,and\\n\\nfurthermore, gaps revealed by our analysis vectors(768dimensionsistypical)inwhichinner\\n\\n]RI.sc[\\n\\npoint to low hanging fruit in terms of tech- productsbetweenqueriesandrelevantdocuments\\n\\nniquesthathaveyettobeexplored.Wepresent aremaximized,basedonsupervisionsignalsfrom\\n\\nanoveltechniquedubbeduniCOIL,asimple\\n\\na large dataset such as the MS MARCO passage\\n\\nextensionofCOILthatachievestoourknowl-\\n\\nrankingtestcollection(Bajajetal.,2018). SeeLin\\n\\nedge the current state-of-the-art in sparse re-\\n\\netal.(2020)forasurvey. trieval on the popular MS MARCO passage 1v70841.6012:viXra\\n\\nDense retrieval techniques are typically com-\\n\\nranking dataset. Our implementation using\\n\\nthe Anserini IR toolkit is built on the Lucene paredagainstabag-of-wordsexactmatchranking\\n\\nsearch library and thus fully compatible with modelsuchasBM25,whichinthiscontextcanbe\\n\\nstandardinvertedindexes. understood as unsupervised sparse retrieval. Al-\\n\\nthough it may be unnatural to describe BM25 in\\n\\n1 Introduction\\n\\nthisway,itistechnicallyaccurate:eachdocument\\n\\nisrepresentedbyasparsevectorwhereeachdimen-\\n\\nWepresentanovelconceptualframeworkforun-\\n\\nsioncorrespondstoauniqueterminthevocabulary,\\n\\nderstandingrecentdevelopmentsininformationre-\\n\\nandthescoringfunctionassignsaweighttoeachdi-\\n\\ntrievalthatorganizestechniquesalongtwodimen-\\n\\nmension. Aswithdenseretrieval,querydocument\\n\\nsions. Thefirstdimensionestablishesthecontrast\\n\\nscoresarecomputedviainnerproducts. between sparse and dense vector representations', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='for queries and documents.1 The second dimen- Whataboutlearnedsparseretrieval? Themost\\n\\nsionestablishesthecontrastbetweenunsupervised prominentrecentexampleofthisintheliterature\\n\\nandlearned(supervised)representations. Figure1 is DeepCT (Dai and Callan, 2019), which uses\\n\\nillustratesourframework. atransformertolearntermweightsbasedonare-\\n\\ngressionmodel,withthesupervisionsignalcoming\\n\\nRecentproposalsfordenseretrieval,exemplified\\n\\nfromtheMSMARCOpassagerankingtestcollec-\\n\\nbyDPR(Karpukhinetal.,2020)andANCE(Xiong\\n\\ntion.2 DeepCThasaninterestingquirk:intruth,\\n\\net al., 2021), but also encompassing many other\\n\\nit only learns the term frequency (tf) component\\n\\ntechniques (Gao et al., 2021b; Hofsttter et al.,\\n\\nof term weights, but still relies on the remaining\\n\\n2020;Quetal.,2021;Hofsttteretal.,2021;Lin\\n\\n1Consistent with parlance in information retrieval, we use 2Learningsparserepresentationsisbynomeansanewidea. documentthroughoutthispaperinagenericsensetoreferto TheearliestexampleweareawareofisWilbur(2001),who\\n\\ntheunitofretrievedtext.Tobemoreprecise,ourexperiments attemptedtolearnglobaltermweightsusingTRECdata,but\\n\\nareinfactfocusedonpassageretrieval. theidealikelydatesbackevenfurther.parts of the BM25 scoring function via the gen- LDA(WeiandCroft,2006),whichhavebeenprevi-\\n\\nerationofpseudo-documents. Thisapproachalso ouslyexplored. Thus,allquadrantsinourproposed\\n\\nhas a weakness: it only assigns weights to terms conceptualframeworkarepopulatedwithknown\\n\\nthat are already present in the document, which examplesfromtheliterature. limits retrieval to exact match. This is an impor-\\n\\n2 CommentsandObservations\\n\\ntantlimitationthatisaddressedbytheuseofdense\\n\\nrepresentations,whicharecapableofcapturingse-\\n\\nBasedonthisframework,wecanmakeanumberof\\n\\nmanticmatches. interestingobservationsthathighlightobviousnext\\n\\nThesetwoissueswereresolvedbytherecently steps in the development of retrieval techniques. proposedDeepImpactmodel(Malliaetal.,2021), Wediscussasfollows:\\n\\nwhichalsobelongsinthefamilyoflearnedsparse Choiceofbases. Retrievaltechniquesusinglearned\\n\\nrepresentations. DeepImpactbroughttogethertwo denserepresentationsandlearnedsparserepresen-\\n\\nkeyideas:theuseofdocumentexpansiontoiden- tations present an interesting contrast. Nearly all\\n\\ntify dimensions in the sparse vector that should recentproposalstakeadvantageoftransformers,so', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='havenon-zeroweightsandatermweightingmodel thataspectofthedesignisnotasalientdifference. basedonapairwiselossbetweenrelevantandnon- Thecriticalcontrastisthebasisofthevectorrep-\\n\\nrelevant texts with respect to a query. Expansion resentations:Insparseapproaches,thebasisofthe\\n\\ntermswereidentifiedbydoc2queryT5(Nogueira vectorspaceremainsfixedtothecorpusvocabulary,\\n\\nandLin,2019),asequence-to-sequencemodelfor and thus techniques such as DeepCT, COIL, and\\n\\ndocumentexpansionthatpredictsqueriesforwhich DeepImpactcanbeunderstoodastermweighting\\n\\na text would be relevant. Since the DeepImpact models. In dense approaches, the model is given\\n\\nscoringmodeldirectlypredictstermweightsthat the freedom to choose a new basis derived from\\n\\nare then quantized, it would be more accurate to transformerrepresentations. Thischangeinbasis\\n\\ncall these weights learned impacts, since query allowstheencodertorepresentthemeaningof\\n\\ndocumentscoresaresimplythesumofweightsof textsinrelativelysmallfixed-widthvectors(com-\\n\\ndocumenttermsthatarefoundinthequery. Calling paredtosparsevectorsthatmayhavemillionsof\\n\\ntheseimpactscoresdrawsanexplicitconnectionto dimensions). This leads us to the next important\\n\\nathreadofresearchininformationretrievaldating observation:\\n\\nbacktwodecades(Anhetal.,2001). Expansions for sparse representation. Without\\n\\nTherecentlyproposedCOILarchitecture(Gao someformofexpansion,learnedsparserepresen-\\n\\netal.,2021a)presentsaninterestingcaseforthis tations remain limited to (better) exact matching\\n\\nconceptualframework. Wheredoesitbelong? The between queries and documents. The nature of\\n\\nauthors themselves describe COIL as a new ex- sparserepresentationsmeansthatitisimpractical\\n\\nactlexicalmatchretrievalarchitecturearmedwith to consider non-zero weights for all elements in\\n\\ndeepLMrepresentations. COILproducesrepre- thevector(i.e.,thevocabularyspace). Thus,docu-\\n\\nsentations for each document token that are then mentexpansionservesthecriticalroleofproposing\\n\\ndirectly stored in the inverted index, where the a set of candidate terms that should receive non-\\n\\nterm frequency usually goes in an inverted list. zeroweights;sincethenumberofcandidateterms\\n\\nAlthough COIL is perhaps best described as the is small compared to the vocabulary size, the re-\\n\\nintellectualdescendantofColBERT(Khattaband sultingvectorremainssparse. Withoutexpansion,\\n\\nZaharia,2020),anotherwaytothinkaboutitwithin learnedsparserepresentationscannotaddressthe', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='ourconceptualframeworkisthatinsteadofassign- vocabularymismatchproblem(Furnasetal.,1987),\\n\\ningscalarweightstotermsinaquery,thescoring becausedocumenttermsnotpresentinthequery\\n\\nmodelassignseachtermavectorweight. Query cannotcontributeanyscore. ForDeepImpact,this\\n\\nevaluation in COIL involves accumulating inner expansion is performed bydoc2queryT5, but in\\n\\nproductsinsteadofscalarweights. principlewecanimagineothermethodsalso. This\\n\\nOur conceptual framework highlights a final leadsustothenextimportantobservation:\\n\\nclassoftechniques:unsuperviseddenserepresen- RelatingDeepCT,DeepImpact,andCOIL.Theup-\\n\\ntations. Whilethereislittleworkinthisspaceof shot of the above analysis is that retrieval tech-\\n\\nlate,itdoesdescribetechniquessuchasLSI(Deer- niques based on learned sparse representations\\n\\nwester et al., 1990; Atreya and Elkan, 2010) and should be divided into an expansion model andSparseRepresentations MRR@10 Notes\\n\\nTermWeighting Expansion\\n\\n(1a) BM25 None 0.184 copiedfrom(NogueiraandLin,2019)\\n\\n(1b) BM25 doc2queryT5 0.277 copiedfrom(NogueiraandLin,2019)\\n\\n(2a) DeepCT None 0.243 copiedfrom(DaiandCallan,2019)\\n\\n(2b) DeepCT doc2queryT5 ? nopubliclyreportedfigure\\n\\n(2c) DeepImpact None ? nopubliclyreportedfigure\\n\\n(2d) DeepImpact doc2queryT5 0.326 copiedfrom(Malliaetal.,2021)\\n\\n(2e) COIL-tok(d=32) None 0.341 copiedfrom(Gaoetal.,2021a)\\n\\n(2f) COIL-tok(d=32) doc2queryT5 0.361 ourexperiment\\n\\n(2g) uniCOIL None 0.315 ourexperiment\\n\\n(2h) uniCOIL doc2queryT5 0.352 ourexperiment\\n\\nDenseRepresentations MRR@10 Notes\\n\\n(3a) ColBERT 0.360 copiedfrom(KhattabandZaharia,2020)\\n\\n(3b) ANCE 0.330 copiedfrom(Xiongetal.,2021)\\n\\n(3c) DistillBERT 0.323 copiedfrom(Hofsttteretal.,2020)\\n\\n(3d) RocketQA 0.370 copiedfrom(Quetal.,2021)\\n\\n(3e) TAS-B 0.347 copiedfrom(Hofsttteretal.,2021)\\n\\n(3f) TCT-ColBERTv2 0.359 copiedfrom(Linetal.,2021)\\n\\nDenseSparseHybrids MRR@10 Notes\\n\\n(4a) CLEAR 0.338 copiedfrom(Gaoetal.,2021b)\\n\\n(4b) COIL-full 0.355 copiedfrom(Gaoetal.,2021a)\\n\\n(4c) TCT-ColBERTv2+BM25(1a) 0.369 copiedfrom(Linetal.,2021)\\n\\n(4d) TCT-ColBERTv2+doc2queryT5(1b) 0.375 copiedfrom(Linetal.,2021)\\n\\n(4e) TCT-ColBERTv2+DeepImpact(2d) 0.378 ourexperiment\\n\\n(4f) TCT-ColBERTv2+uniCOIL(2h) 0.378 ourexperiment\\n\\n(4g) TCT-ColBERTv2+COIL(2f) 0.382 ourexperiment\\n\\nTable2: ResultsonthedevelopmentqueriesoftheMSMARCOpassagerankingtask. a term weighting model. For example, DeepCT andhenceunsupervised. Learnedsparseretrieval\\n\\nperformsnoexpansionandusesaregression-based techniques are shown in row group (2). Separat-', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='scoringmodel. DeepImpactperformsdocumentex- ing the term weighting component from the ex-\\n\\npansionandusesapairwisescoringmodel. COIL pansion component allows us to identify gaps in\\n\\nperformsnoexpansionandusesascoringmodel modelconfigurationsthatwouldbeinterestingto\\n\\nthatgeneratesacontextualizedweightvector(in- explore. For example, in row (2a), DeepCT pro-\\n\\nsteadofascalarweight). Thisbreakdownsuggests posed a regression-based term weighting model,\\n\\nanumberofobviousexperimentsthathelpusun- but performed no expansion. However, the term\\n\\nderstand the contributions of these components, weightingmodelcanbeappliedtoexpandeddoc-\\n\\nwhichwereportnext. uments, as in row (2b); to our knowledge, this\\n\\nconfigurationhasnotbeenpubliclyreported. 3 Experiments\\n\\nSimilarly,DeepImpactcombineddoc2queryT5\\n\\nOurproposedconceptualframeworkcanbeused asanexpansionmodelandatermweightingmodel\\n\\nto organize results from the literature, which are trained with pairwise loss. To better understand\\n\\nshown in Table 2 on the development queries of the contributions of each component, we could\\n\\ntheMSMARCOpassagerankingtask(Bajajetal., run the term weighting model without document\\n\\n2018). Someoftheseentriesrepresentfiguresdi- expansion, as outlined in row (2c). This ablation\\n\\nrectlycopiedfrompreviouspapers(withreferences experimentwasnotreportedinMalliaetal. (2021),\\n\\nshown),whileothersarenovelexperimentalcondi- butwouldbeinterestingtoconduct. tionsthatwereport. In row (2e) we report the published results of\\n\\nThefirstmainblockofthetableshowsretrieval COIL-tok(tokendimensiond = 32),whichisthe\\n\\nwith sparse representations. Row (1a) shows the sparsecomponentinthefullCOILmodel(which\\n\\nBM25baseline,androw(1b)providestheeffective- is a densesparse hybrid). Through the lens of\\n\\nnessofdoc2queryT5expansion. Inbothcases,the ourconceptualframework,anumberofextensions\\n\\ntermweightsarefromtheBM25scoringfunction, becomeimmediatelyobvious. COILcanbecom-binedwithdoc2queryT5. Usingsourcecodepro- that ColBERT (Khattab and Zaharia, 2020) uses\\n\\nvided by the authors,3 we trained such a model themoreexpressiveMaxSimoperatortocompare\\n\\nfrom scratch, using the same hyperparameters as queryanddocumentrepresentations;allothertech-\\n\\ntheauthors. Thisvariantleadstoanearlytwo-point niquesuseinnerproducts. gainineffectiveness,asshowninrow(2f). ThefinalblockofTable2presentstheresultsof\\n\\nInanotherinterestingextension,ifwereducethe densesparse hybrids. Lin et al. (2021) reported', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='tokendimensionofCOILtoone,themodeldegen- the results of densesparse hybrids when TCT-\\n\\nerates into producing scalar weights, which then ColBERTv2, row (3f), is combined with BM25,\\n\\nbecomesdirectlycomparabletoDeepCT,row(2a) row (1a), and doc2queryT5, row (1b). To this,\\n\\nandtheno-expansionvariantofDeepImpact,row weaddedfusionwithDeepImpact,uniCOIL,and\\n\\n(2c). Thesecomparisonsisolatetheeffectsofdiffer- COIL-tok(d = 32). Forafaircomparison,wefol-\\n\\nenttermweightingmodels. Wedubthisvariantof lowedthesametechniqueforcombiningdenseand\\n\\nCOILuniCOIL,ontopofwhichwecanalsoadd sparseresultsasLinetal. (2021),whichisfromMa\\n\\ndoc2queryT5,whichproducesafaircomparison etal.(2021). Foreachqueryq,weusedthecorre-\\n\\ntoDeepImpact,row(2d). Theoriginalformulation sponding dense and sparse techniques to retrieve\\n\\nof COIL, even with a token dimension of one, is top-1kdocuments. Thefinalfusionscoreofeach\\n\\nnot directly amenable to retrieval using inverted documentiscalculatedbys +s . Since\\n\\ndense sparse\\n\\nindexes because weights can be negative. To ad- therangeofthetwodifferentscoresarequitediffer-\\n\\ndress this issue, we added a ReLU operation on ent,wefirstnormalizedthescoresintorange(0,1). theoutputtermweightsofthebaseCOILmodelto The wastunedintherange(0, 2)withasimple\\n\\nforcethemodeltogeneratenon-negativeweights. linesearchonasubsetoftheMSMARCOpassage\\n\\nOnceagain, weretrainedthemodelfromscratch trainingset. using the same hyperparameters provided by the With these hybrid combinations, we are able\\n\\nauthors. Whenencodingthecorpus,wequantized toachieve,toourknowledge,thehighestreported\\n\\nthese weights into 8 bits to obtain impact scores; scoresontheMSMARCOpassagerankingtaskfor\\n\\nqueryweightsaresimilarlyquantized. Afterthese single-stagetechniques(i.e.,noreranking). Note\\n\\nmodifications,uniCOILisdirectlycompatiblewith that, as before, uniCOIL is compatible with stan-\\n\\ninvertedindexes. Ourexperimentalresultsarere- dardinvertedindexes,unlikeCOIL-tok,whichre-\\n\\nportedwiththeAnserinitoolkit(Yangetal.,2017, quirescustominfrastructure. 2018),whichisbuiltonLucene. ItisnosurprisethatuniCOILwithoutdoc2query 4 NextSteps\\n\\nT5,row(2g),islesseffectivethanCOIL-tok(d =\\n\\nInmostrecentwork,denseretrievaltechniquesare\\n\\n32),row(2e). However,uniCOILwithdoc2query\\n\\ncomparedtoBM25andexperimentsshowthatthey\\n\\nT5,row(2h),outperformsCOIL-tokwithoutneed-\\n\\nhandily win. However, this is not a fair compari-\\n\\ning any specialized retrieval infrastructurethe\\n\\nson, sinceBM25isunsupervised, whereasdense', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='weightsarejustimpactscores,likeinDeepImpact. retrieval techniques exploit supervised relevance\\n\\nTheseresultssuggestthatcontextualizedweight\\n\\nsignals from large datasets. A more appropriate\\n\\nvectorsinCOILarentnecessarytoachievegood\\n\\ncomparison would be between learned dense vs.\\n\\neffectivenessaddingexpansionappearssufficient\\n\\nsparse representationsand there, no clear win-\\n\\ntomakeupforthelostexpressivityofweightvec-\\n\\nner emerges at present. However, it seems clear\\n\\ntors, as shown in row (2h) vs. row (2e). To our\\n\\nthattheyarecomplementary,ashybridapproaches\\n\\nknowledge, our uniCOIL model, row(2h), repre-\\n\\nappeartobemoreeffectivethaneitheralone. sents the state of the art in sparse retrieval using\\n\\nAn important point to make here is that neu-\\n\\nlearned impact weights, beating DeepImpact by\\n\\nral networks, particularly transformers, have not\\n\\naroundtwopoints. madesparserepresentationsobsolete. Bothdense\\n\\nThe second main block of Table 2 provides a\\n\\nandsparselearnedrepresentationsclearlyexploit\\n\\nnumberofcomparabledenseretrievalresultsfrom\\n\\ntransformersthe trick is that the latter class of\\n\\ntheliterature. Thehighestscorethatweareaware\\n\\ntechniquesthenprojectsthelearnedknowledge\\n\\nofisRocketQA(Quetal.,2021),whoseeffective-\\n\\nback into the sparse vocabulary space. This al-\\n\\nness beatsall knownsparse configurations. Note\\n\\nlowsustoreusedecadesofinnovationininverted\\n\\n3https://github.com/luyug/COIL indexes (e.g., integer coding techniques to com-pressinvertedlists)andefficientqueryevaluation Indexing by latent semantic analysis. Journal of\\n\\nalgorithms (e.g., smart skipping to reduce query theAssociationforInformationScience,41(6):391\\n\\n407.\\n\\nlatency): for example, the Lucene index used in\\n\\nour uniCOIL experiments is only 1.3 GB, com- George W. Furnas, Thomas K. Landauer, Louis M.\\n\\npared to 40 GB for COIL-tok, 26 GB for TCT- Gomez, and Susan T. Dumais. 1987. The vo-\\n\\ncabularyprobleminhuman-systemcommunication. ColBERTv2,and154GBforColBERT.Wenote,\\n\\nCommunicationsoftheACM,30(11):964971.\\n\\nhowever,thatwithdenseretrievaltechniques,fixed-\\n\\nwidth vectors can be approximated with binary Luyu Gao, Zhuyun Dai, and Jamie Callan. 2021a. hashcodes,yieldingfarmorecompactrepresenta- COIL: Revisit exact lexical match in information\\n\\nretrieval with contextualized inverted list. In Pro-\\n\\ntionswithsacrificingmucheffectiveness(Yamada\\n\\nceedingsofthe2021ConferenceoftheNorthAmer-\\n\\netal.,2021). Onceagain,noclearwinneremerges ican Chapter of the Association for Computational', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='atpresent. Linguistics: Human Language Technologies, pages\\n\\nThecompletedesignspaceofmoderninforma- 30303042.\\n\\ntionretrievaltechniquesrequiresproperaccounting\\n\\nLuyuGao,ZhuyunDai,TongfeiChen,ZhenFan,Ben-\\n\\nofthetradeoffsbetweenoutputquality(effective- jamin Van Durme, and Jamie Callan. 2021b. Com-\\n\\nness),time(querylatency),andspace(indexsize). plementing lexical retrieval with semantic residual\\n\\nembedding. In Proceedings of the 43rd European\\n\\nHere, we have only focused on the first aspect. Conference on Information Retrieval (ECIR 2021),\\n\\nLearned representations for information retrieval\\n\\nPartI,pages146160. areclearlythefuture, buttheadvantagesanddis-\\n\\nadvantages of dense vs. sparse approaches along Sebastian Hofsttter, Sophia Althammer, Michael\\n\\nSchrder, Mete Sertkan, and Allan Hanbury. thesedimensionsarenotyetfullyunderstood. Itll\\n\\n2020. Improving efficient neural ranking mod-\\n\\nbeexcitingtoseewhatcomesnext! els with cross-architecture knowledge distillation. arXiv:2010.02666. 5 Acknowledgments\\n\\nSebastian Hofsttter, Sheng-Chieh Lin, Jheng-Hong\\n\\nThisresearchwassupportedinpartbytheCanada Yang, Jimmy Lin, and Allan Hanbury. 2021. Ef-\\n\\nFirstResearchExcellenceFundandtheNaturalSci- ficiently teaching an effective dense retriever with\\n\\nbalanced topic aware sampling. In Proceedings of\\n\\nencesandEngineeringResearchCouncil(NSERC)\\n\\nthe 44th Annual International ACM SIGIR Confer-\\n\\nofCanada. Computationalresourceswereprovided\\n\\nence on Research and Development in Information\\n\\nbyComputeOntarioandComputeCanada. Retrieval(SIGIR2021). VladimirKarpukhin,BarlasOguz,SewonMin,Patrick\\n\\nLewis,LedellWu,SergeyEdunov,DanqiChen,and\\n\\nReferences\\n\\nWen-tau Yih. 2020. Dense passage retrieval for\\n\\nVo Ngoc Anh, Owen de Kretser, and Alistair Moffat. open-domainquestionanswering. InProceedingsof\\n\\n2001. Vector-spacerankingwitheffectiveearlyter- the 2020 Conference on Empirical Methods in Nat-\\n\\nmination. In Proceedings of the 24th Annual Inter- ural Language Processing (EMNLP), pages 6769\\n\\nnational ACM SIGIR Conference on Research and 6781. DevelopmentinInformationRetrieval(SIGIR2001),\\n\\nOmarKhattabandMateiZaharia.2020. ColBERT:Ef-\\n\\npages3542,NewOrleans,Louisiana. ficient and effective passage search via contextual-\\n\\nAvinash Atreya and Charles Elkan. 2010. Latent se- ized late interaction over BERT. In Proceedings of\\n\\nmantic indexing (LSI) fails for TREC collections. the 43rd International ACM SIGIR Conference on\\n\\nSIGKDDExplorations,12(2):510. ResearchandDevelopmentinInformationRetrieval', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='(SIGIR2020),pages3948. Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng,\\n\\nJianfeng Gao, Xiaodong Liu, Rangan Majumder, Jimmy Lin, Rodrigo Nogueira, and Andrew Yates. Andrew McNamara, Bhaskar Mitra, Tri Nguyen, 2020. Pretrained transformers for text ranking:\\n\\nMirRosenberg,XiaSong,AlinaStoica,SaurabhTi- BERTandbeyond. arXiv:2010.06467.\\n\\nwary, and Tong Wang. 2018. MS MARCO: A Hu-\\n\\nman Generated MAchine Reading COmprehension Sheng-Chieh Lin, Jheng-Hong Yang, and Jimmy Lin. Dataset. arXiv:1611.09268v3. 2021. In-batchnegativesforknowledgedistillation\\n\\nwithtightly-coupledteachersfordenseretrieval. In\\n\\nZhuyun Dai and Jamie Callan. 2019. Context-aware Proceedingsofthe6thWorkshoponRepresentation\\n\\nsentence/passage term importance estimation for LearningforNLP. firststageretrieval. arXiv:1910.10687. Xueguang Ma, Kai Sun, Ronak Pradeep, and Jimmy\\n\\nScottDeerwester,SusanT.Dumais,GeorgeW.Furnas, Lin.2021. Areplicationstudyofdensepassagere-\\n\\nThomasK.Landauer,andRichardHarshman.1990. triever. arXiv:2104.05740.Antonio Mallia, Omar Khattab, Torsten Suel, and\\n\\nNicolaTonellotto. 2021. Learningpassage impacts\\n\\nforinvertedindexes. InProceedingsofthe44thAn-\\n\\nnual International ACM SIGIR Conference on Re-\\n\\nsearch and Development in Information Retrieval\\n\\n(SIGIR2021). Rodrigo Nogueira and Jimmy Lin. 2019. From\\n\\ndoc2querytodocTTTTTquery. Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang\\n\\nRen, Wayne Xin Zhao, Daxiang Dong, Hua Wu,\\n\\nand Haifeng Wang. 2021. RocketQA: An opti-\\n\\nmized training approach to dense passage retrieval\\n\\nfor open-domain question answering. In Proceed-\\n\\nings of the 2021 Conference of the North Ameri-\\n\\ncan Chapter of the Association for Computational\\n\\nLinguistics: Human Language Technologies, pages\\n\\n58355847. XingWeiandW.BruceCroft.2006. LDA-baseddoc-\\n\\nument models for ad-hoc retrieval. In Proceedings\\n\\nof the 29th Annual International ACM SIGIR Con-\\n\\nference on Research and Development in Informa-\\n\\ntionRetrieval(SIGIR2006),pages178185,Seattle,\\n\\nWashington. W. John Wilbur. 2001. Global term weights for docu-\\n\\nmentretrievallearnedfromTRECdata. Journalof\\n\\nInformationScience,27(5):303310. Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang,\\n\\nJialin Liu, Paul N. Bennett, Junaid Ahmed, and\\n\\nArnoldOverwijk.2021. Approximatenearestneigh-\\n\\nbor negative contrastive learning for dense text re-\\n\\ntrieval. InProceedingsofthe9thInternationalCon-\\n\\nferenceonLearningRepresentations(ICLR2021). Ikuya Yamada, Akari Asai, and Hannaneh Ha-\\n\\njishirzi. 2021. Efficient passage retrieval with', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='hashing for open-domain question answering. arXiv:2106.00882. PeilinYang,HuiFang,andJimmyLin.2017. Anserini:\\n\\nenablingtheuseofLuceneforinformationretrieval\\n\\nresearch. In Proceedings of the 40th Annual Inter-\\n\\nnational ACM SIGIR Conference on Research and\\n\\nDevelopmentinInformationRetrieval(SIGIR2017),\\n\\npages12531256,Tokyo,Japan. PeilinYang,HuiFang,andJimmyLin.2018. Anserini:\\n\\nreproduciblerankingbaselinesusingLucene. Jour-\\n\\nnal of Data and Information Quality, 10(4):Article\\n\\n16.Doc2Query--: When Less is More\\n\\nMitko Gospodinov1, Sean MacAvaney2, and Craig Macdonald2\\n\\nUniversity of Glasgow\\n\\n12024810G@student.gla.ac.uk\\n\\n2{first}. {last}@glasgow.ac.uk\\n\\n3202\\n\\nAbstract. Doc2Query  the process of expanding the content of a\\n\\ndocument before indexing using a sequence-to-sequence model  has\\n\\nemergedasaprominenttechniqueforimprovingthefirst-stageretrieval\\n\\nbeF\\n\\neffectivenessofsearchengines.However,sequence-to-sequencemodelsare\\n\\nknown to be prone to hallucinating content that is not present in the\\n\\nsource text. We argue that Doc2Query is indeed prone to hallucination,\\n\\nwhichultimatelyharmsretrievaleffectivenessandinflatestheindexsize. 72\\n\\nInthiswork,weexploretechniquesforfilteringouttheseharmfulqueries\\n\\npriortoindexing.Wefindthatusingarelevancemodeltoremovepoor-\\n\\n]RI.sc[\\n\\nquality queries can improve the retrieval effectiveness of Doc2Query by\\n\\nupto16%,whilesimultaneouslyreducingmeanqueryexecutiontimeby\\n\\n23% and cutting the index size by 33%. We release the code, data, and\\n\\nalivedemonstrationtofacilitatereproductionandfurtherexploration.1\\n\\n1 Introduction 3v66230.1032:viXra\\n\\nNeural network models, particularly those based on contextualised language\\n\\nmodels, have been shown to improve search effectiveness [3]. While some ap-\\n\\nproaches focus on re-ranking document sets from a first-stage retrieval function\\n\\nto improve precision [27], others aim to improve the first stage itself [4]. In this\\n\\nwork, we focus on one of these first-stage approaches: Doc2Query [29]. This ap-\\n\\nproachtrainsasequence-to-sequencemodel(e.g.,T5[33])topredictqueriesthat\\n\\nmay be relevant to a particular text. Then, when indexing, this model is used\\n\\nto expand the document by generating a collection of queries and appending\\n\\nthem to the document. Though computationally expensive at index time [34],\\n\\nthis approach has been shown to be remarkably effective even when retrieving\\n\\nusing simple lexical models like BM25 [28]. Numerous works have shown that', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='the approach can produce a high-quality pool of results that are effective for\\n\\nsubsequent stages in the ranking pipeline [19,20,23,40]. However, sequence-to-sequence models are well-known to be prone to gener-\\n\\nate content that does not reflect the input text  a defect known in literature\\n\\nas hallucination [25]. We find that existing Doc2Query models are no excep-\\n\\ntion. Figure 1 provides example generated queries from the state-of-the-art T5\\n\\nDoc2Query model [28]. In this example, we see that many of the generated\\n\\nqueries cannot actually be answered by the source passage (score  1). 1 https://github.com/terrierteam/pyterrier_doc2query2 Gospodinov et al. Original Passage: Barley (Hordeum vulgare L.), aGeneratedQueries:(1)wheredoesbarleyoriginate\\n\\nmemberofthegrassfamily,isamajorcerealgrain.Itfrom(2)whatisthenameofthecerealgrainused\\n\\nwasoneofthefirstcultivatedgrainsandisnowgrownintibetancooking? (3)whatisbarleyusedfor(1)\\n\\nwidely.BarleygrainisastapleinTibetancuisineandwhatisbarleyinfood(0)whatisbarewheat(3)\\n\\nwaseatenwidelybypeasantsinMedievalEurope.Bar-whatfamilyoforganismsisbarleyin(1)whyisbar-\\n\\nleyhasalsobeenusedasanimalfodder,asasourceley important in tibetan diet  (3) what is barley\\n\\noffermentablematerialforbeerandcertaindistilled(2)whereisbarleygrown(1)wherewasbarleyfirst\\n\\nbeverages,andasacomponentofvarioushealthfoods.grownandeaten(1)wherewasbarleyfirstused...\\n\\nFig.1. Example passage from MS MARCO and generated queries using the T5\\n\\nDoc2Query model. The relevance of each query to the passage is scored by the au-\\n\\nthors on a scale of 03 using the TREC Deep Learning passage relevance criteria. Based on this observation, we hypothesise that retrieval performance of\\n\\nDoc2Querywouldimproveifhallucinatedquerieswereremoved.Inthispaper,we\\n\\nconduct experiments where we apply a new filtering phase that aims to remove\\n\\npoor queries prior to indexing. Given that this approach removes queries, we\\n\\ncalltheapproachDoc2Query--(Doc2Query-minus-minus).Ratherthantraining\\n\\na new model for this task, we identify that relevance models are already fit for\\n\\nthis purpose: they estimate how relevant a passage is to a query. We therefore\\n\\nexplore filtering strategies that make use of existing neural relevance models. Through experimentation on the MS MARCO dataset, we find that our fil-\\n\\ntering approach can improve the retrieval effectiveness of indexes built using\\n\\nDoc2Query-- by up to 16%; less can indeed be more. Meanwhile, filtering nat-', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='urally reduces the index size, lowering storage and query-time computational\\n\\ncosts.Finally,weconductanexplorationoftheindex-timeoverheadsintroduced\\n\\nbythefilteringprocessandconcludethatthegainsfromfilteringmorethanmake\\n\\nupfortheadditionaltimespentgeneratingmorequeries.Theapproachalsohas\\n\\na positive impact on the environmental costs of applying Doc2Query; the same\\n\\nretrieval effectiveness can be achieved with only about a third of the compu-\\n\\ntational cost when indexing. To facilitate last-metre, last-mile, and complete\\n\\nreproduction efforts [36], we release the code, indices, and filtering scores.1 In\\n\\nsummary, we contribute a technique to improve the effectiveness and efficiency\\n\\nof Doc2Query by filtering out queries that do not reflect the original passage. 2 Related Work\\n\\nThe classical lexical mismatch problem is a key one in information retrieval -\\n\\ndocuments that do not contain the query terms may not be retrieved. In the\\n\\nliterature,variousapproacheshaveaddressedthis:queryreformulationinclud-\\n\\ning stemming, query expansion models (e.g. Rocchio, Bo1 [1], RM3 [12])  and\\n\\ndocument expansion [9,30,35]. Classically, query expansion models have been\\n\\npopular, as they avoid the costs associated with making additional processing\\n\\nfor each document needed for document expansion. However, query expansion\\n\\nmay result in reduced performance [11], as queries are typically short and the\\n\\nnecessary evidence to understand the context of the user is limited.Doc2Query--: When Less is More 3\\n\\nThe application of latent representations of queries and documents, such\\n\\nas using latent semantic indexing [8] allow retrieval to not be driven directly\\n\\nby lexical signals. More recently, transformer-based language models (such as\\n\\nBERT [6]) have resulted in representations of text where the contextualised\\n\\nmeaning of words are accounted for. In particular, in dense retrieval, queries\\n\\nand documents are represented in embeddings spaces [14,37], often facilitated\\n\\nby Approximate Nearest Neighbour (ANN) data structures [13]. However, even\\n\\nwhen using ANN, retrieval can still be inefficient or insufficiently effective [15]. Othershaveexploredapproachesforaugmentinglexicalrepresentationswith\\n\\nadditionaltermsthatmayberelevant.Inthiswork,weexploreDoc2Query[29],\\n\\nwhich uses a sequence-to-sequence model that maps a document to queries that\\n\\nit might be able to answer. By appending these generated queries to a docu-', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='ments content before indexing, the document is more likely to be retrieved for\\n\\nuser queries when using a model like BM25. An alternative style of document\\n\\nexpansion, proposed by MacAvaney et al. [19] and since used by several other\\n\\nmodels (e.g., [10,39,40]), uses the built-in Masked Language Modelling (MLM)\\n\\nmechanism.MLMexpansiongeneratesindividualtokenstoappendtothedocu-\\n\\nmentasabagofwords(ratherthanasasequence).AlthoughMLMexpansionis\\n\\nalso prone to hallucination,2 the bag-of-words nature of MLM expansion means\\n\\nthat individual expansion tokens may not have sufficient context to apply fil-\\n\\ntering effectively. We therefore focus only on sequence-style expansion and leave\\n\\nthe exploration of MLM expansion for future work. 3 Doc2Query--\\n\\nDoc2Query-- consists of two phases: a generation phrase and a filtering phase. In the generation phase, a Doc2Query model generates a set of n queries that\\n\\neach document might be able to answer. However, as shown in Figure 1, not\\n\\nall of the queries are necessarily relevant to the document. To mitigate this\\n\\nproblem, Doc2Query-- then proceeds to a filtering phase, which is responsible\\n\\nfor eliminating the generated queries that are least relevant to the source doc-\\n\\nument. Because hallucinated queries contain details not present in the original\\n\\ntext (by definition), we argue that hallucinated queries are less useful for re-\\n\\ntrieval than non-hallucinated ones. Filtering is accomplished by retaining only\\n\\nthe most relevant p proportion of generated queries over the entire corpus. The\\n\\nretained queries are then concatenated to their corresponding documents prior\\n\\nto indexing, as per the existing Doc2Query approach. More formally, consider an expansion function e that maps a document to n\\n\\nqueries: e : D (cid:55) Qn. In Doc2Query, each document in corpus D are concate-\\n\\nnatedwiththeirexpansionqueries,forminganewcorpusD(cid:48) ={Concat(d,e(d))|\\n\\ndD},whichisthenindexedbyaretrievalsystem.Doc2Query--addsafiltering\\n\\nmechanism that uses a relevance model that maps a query and document to a\\n\\nreal-valued relevance score s:QD(cid:55)R (with larger values indicating higher\\n\\n2 Forinstance,wefindthatSPLADE[10]generatesthefollowingseemingly-unrelated\\n\\nterms for the passage in Figure 1 in the top 20 expansion terms: reed, herb, and troy.4 Gospodinov et al. relevance). The relevance scoring function is used to filter down the queries to\\n\\nthose that meet a certain score threshold t as follows:', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='D(cid:48) =(cid:110) Concat(cid:0) d,(cid:8) q |q e(d)s(q,d)t(cid:9)(cid:1) |dD(cid:111) (1)\\n\\nThe relevance threshold t is naturally dependent upon the relevance scoring\\n\\nfunction. It can be set empirically, chosen based on operational criteria (e.g.,\\n\\ntargetindexsize),or(forawell-calibratedrelevancescoringfunction)determined\\n\\na priori. In this work, we combine the first two strategies: we pick t based on\\n\\nthe distribution of relevance scores across all expansion queries. For instance,\\n\\nat p = 0.3 we only keep queries with relevance scores in the top 30%, which is\\n\\nt=3.215fortheELECTRA[31]scoringmodelontheMSMARCOdataset[26]. 4 Experimental Setup\\n\\nWe conduct experiments to answer the following research questions:\\n\\nRQ1 Does Doc2Query-- improve the effectiveness of document expansion? RQ2 Whatarethetrade-offsintermsofeffectiveness,efficiency,andstoragewhen\\n\\nusing Doc2Query--? Datasets and Measures. We conduct tests using the MS MARCO [26] v1\\n\\npassage corpus. We use five test collections:3 (1) the MS MARCO Dev (small)\\n\\ncollection, consisting of 6,980 queries (1.1 qrels/query); (2) the Dev2 collection,\\n\\nconsistingof4,281(1.1qrels/query);(3)theMSMARCOEvalset,consistingof\\n\\n6,837queries(held-outleaderboardset);(4/5)theTRECDL19/20collections,\\n\\nconsisting of 43/54 queries (215/211 qrels/query). We evaluate using the official\\n\\ntask evaluation measures: Reciprocal Rank at 10 (RR@10) for Dev/Dev2/Eval,\\n\\nnDCG@10 for DL19/20. We tune systems4 on Dev, leaving the remaining col-\\n\\nlections as held-out test sets. Models.WeusetheT5Doc2QuerymodelfromNogueiraandLin[28],mak-\\n\\ning use of the inferred queries released by the authors (80 per passage). To the\\n\\nbest of our knowledge, this is the highest-performing Doc2Query model avail-\\n\\nable. We consider three neural relevance models for filtering: ELECTRA5 [31],\\n\\nMonoT56[32],andTCT-ColBERT7[16],coveringtwostrongcross-encodermod-\\n\\nels and one strong bi-encoder model. We also explored filters that use the prob-\\n\\nabilities from the generation process itself but found them to be ineffective and\\n\\ntherefore omit these results due to space constraints. ToolsandEnvironment.WeusethePyTerriertoolkit[22]withaPISA[24,17]\\n\\nindex to conduct our experiments. We deploy PISAs Block-Max WAND [7] im-\\n\\nplementation for BM25 retrieval. Inference was conducted on an NVIDIA 3090\\n\\nGPU. Evaluation was conducted using the ir-measures package [18]. 3 ir-datasets [21] IDs: msmarco-passage/dev/small, msmarco-passage/dev/2,', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='msmarco-passage/eval/small, msmarco-passage/trec-dl-2019/judged,\\n\\nmsmarco-passage/trec-dl-2020/judged 4 BM25s k1, b, and whether to\\n\\nremove stopwords were tuned for all systems; the filtering percentage (p)\\n\\nwas also tuned for filtered systems. 5 crystina-z/monoELECTRA_LCE_nneg31\\n\\n6 castorini/monot5-base-msmarco 7 castorini/tct_colbert-v2-hnp-msmarcoDoc2Query--: When Less is More 5\\n\\nTable 1. Effectiveness and efficiency measurements for Doc2Query-- and baselines. Significant differences between Doc2Query and their corresponding filtered versions\\n\\nfor Dev,Dev2, DL19 and DL20 areindicated with * (paired t-test,p<0.05). Values\\n\\nmarkedwitharetakenfromthecorrespondingsubmissionstothepublicleaderboard. RR@10 nDCG@10 ms/q GB\\n\\nSystem Dev Dev2 Eval DL19 DL20 MRT Index\\n\\nBM25 0.185 0.182 0.186 0.499 0.479 5 0.71\\n\\nDoc2Query (n=40) 0.277 0.265 0.272 0.626 0.607 30 1.17\\n\\nw/ ELECTRA Filter (30%) *0.316 *0.310 - 0.667 0.611 23 0.89\\n\\nw/ MonoT5 Filter (40%) *0.308 *0.298 0.306 0.650 0.611 29 0.93\\n\\nw/ TCT Filter (50%) *0.287 *0.280 - 0.640 0.599 30 0.94\\n\\nDoc2Query (n=80) 0.279 0.267 - 0.627 0.605 30 1.41\\n\\nw/ ELECTRA Filter (30%) *0.323 *0.316 0.325 0.670 0.614 23 0.95\\n\\nw/ MonoT5 Filter (40%) *0.311 *0.298 - 0.665 0.609 28 1.04\\n\\nw/ TCT Filter (50%) *0.293 *0.283 - 0.642 0.588 28 1.05\\n\\n5 Results\\n\\nWe first explore RQ1: whether relevance filtering can improve the retrieval of\\n\\nDoc2Query models. Table 1 compares the effectiveness of Doc2Query with var-\\n\\nious filters. We observe that all the filters significantly improve the retrieval\\n\\neffectiveness on the Dev and Dev2 datasets at both n=40 and n=80. We also\\n\\nobserve a large boost in performance on the Eval dataset.8 Though the differ-\\n\\nences inDL19 andDL20 appearto beconsiderable (e.g.,0.627 to0.670), these\\n\\ndifferences are not statistically significant. Diggingalittledeeper,Figure2showstheretrievaleffectivenessofDoc2Query\\n\\nwithvariousnumbersofgeneratedqueries(indottedblack)andthecorrespond-\\n\\ning performance when filtering using the top-performing ELECTRA scorer (in\\n\\nsolid blue). We observe that performing relevance filtering at each value of n\\n\\nimproves the retrieval effectiveness. For instance, keeping only 30% of expan-\\n\\nsion queries at n = 80, performance is increased from 0.279 to 0.323  a 16%\\n\\nimprovement. In aggregate, results from Table 1 and Figure 2 answer RQ1: Doc2Query--\\n\\nfilteringcansignificantlyimprovetheretrievaleffectivenessofDoc2Queryacross', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='various scoring models, numbers of generated queries (n) and thresholds (p). Next,weexplorethetrade-offsintermsofeffectiveness,efficiency,andstorage\\n\\nwhen using Doc2Query--. Table 1 includes the mean response time and index\\n\\nsizes for each of the settings. As expected, filtering reduces the index size since\\n\\nfewertermsarestored.Forthebest-performingsetting(n=80withELECTRA\\n\\n8 Significancecannotbedeterminedduetotheheld-outnatureofthedataset.Further,\\n\\ndue to restrictions on the number of submissions to the leaderboard, we only are able\\n\\ntosubmittworuns.ThefirstaimstobeafaircomparisonwiththeexistingDoc2Query\\n\\nEval result, using the same number of generated queries and same base T5 model for\\n\\nscoring. The second is our overall best-performing setting, using the ELECTRA filter\\n\\nat n=80 generated queries.6 Gospodinov et al. 0.325 30% 40% 50%\\n\\n60%\\n\\n70% 80%Filte\\n\\n0.300 9r 0in %g Phase 01@RR\\n\\n0.275 n=40 n=80\\n\\nn=20\\n\\nn=10 Generation Phase\\n\\n0.250\\n\\nn=5\\n\\n0.225\\n\\n0 1 2 3 4 5\\n\\nTotal Tokens 1e9\\n\\nFig.2. Effectiveness (RR@10) on the Dev set, compared with the total number of\\n\\nindexed tokens. The generation phase is shown in dotted black (at various values of\\n\\nn), and the ELECTRA filtering phase is shown in solid blue (at various values of p). filter),thisamountstoa33%reductioninindexsize(1.41GBdownto0.95GB). Naturally, such a reduction has an impact on query processing time as well; it\\n\\nyields a 23% reduction in mean response time (30ms down to 23ms). Doc2Query-- filtering adds substantial cost an indexing time, mostly due to\\n\\nscoring each of the generated queries. Table 2 reports the cost (in hours of GPU\\n\\ntime) of the generation and filtering phases. We observe that ELECTRA filter-\\n\\ningcanyielduptoa78%increaseinGPUtime(n=10).However,wefindthat\\n\\nthe improved effectiveness makes up for this cost. To demonstrate this, we al-\\n\\nlocate the time spent filtering to generating additional queries for each passage. For instance, the 15 hours spent scoring n = 5 queries could instead be spent\\n\\ngenerating6morequeriesperpassage(foratotalofn=11).Wefindthatwhen\\n\\ncomparingagainstanunfilterednthatcloselyapproximatesthetotaltimewhen\\n\\nTable 2. Retrieval effectiveness comparison for comparable indexing computational\\n\\nbudgets(inhoursofGPUtime).Valuesofnwithoutafilterarechosentobestapprox-\\n\\nimate the total compute hours or the Dev effectiveness of the corresponding filtered\\n\\nversion. Significant differences between in RR@10 performance are indicated with *\\n\\n(paired t-test, p<0.05). GPU Hours RR@10', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='n Filter Gen+Filt=Tot Dev Dev2 Comment\\n\\n5 ELECTRA 20 + 15 = 34 0.273 0.270\\n\\n11 None 34 + 0 = 34 *0.261 *0.256 4% Dev RR for sim. GPU hrs\\n\\n31 None 99 + 0 = 99 0.273 0.265 2.9 GPU hrs to match Dev RR\\n\\n10 ELECTRA 32 + 25 = 57 0.292 0.292\\n\\n18 None 59 + 0 = 59 *0.270 *0.260 8% Dev RR for sim. GPU hrs\\n\\n20 ELECTRA 66 + 47 = 113 0.307 0.303\\n\\n36 None 113 + 0 = 113 *0.275 *0.265 10% Dev RR for sim. GPU hrs\\n\\n40 ELECTRA 128 + 86 = 214 0.316 0.310\\n\\n68 None 216 + 0 = 216 *0.279 *0.267 12% Dev RR for sim. GPU hrsDoc2Query--: When Less is More 7\\n\\nfiltering, the filtered results consistently yield significantly higher retrieval effec-\\n\\ntiveness. As the computational budget increases, so does the margin between\\n\\nDoc2Query and Doc2Query--, from 4% at 34 hours up to 12% at 216 hours. From the opposite perspective, Doc2Query consumes 2.9 or more GPU\\n\\ntime than Doc2Query-- to achieve similar effectiveness (n = 13 with no filter\\n\\nvs. n = 5 with ELECTRA filter). Since the effectiveness of Doc2Query flattens\\n\\nout between n = 40 and n = 80 (as seen in Figure 2), it likely requires a\\n\\nmassiveamountofadditionalcomputetoreachtheeffectivenessofDoc2Query--\\n\\nat n10, if that effectiveness is achievable at all. These comparisons show that\\n\\nif a deployment is targeting a certain level of effectiveness (rather than a target\\n\\ncompute budget), Doc2Query-- is also preferable to Doc2Query. TheseresultscollectivelyanswerRQ2:Doc2Query--provideshighereffective-\\n\\nnessatlowerquery-timecosts,evenwhencontrollingfortheadditionalcompute\\n\\nrequired at index time. 6 Conclusions\\n\\nThisworkdemonstratedthatthereareuntappedadvantagesingeneratingnatural-\\n\\nlanguagefordocumentexpansion.Specifically,wepresentedDoc2Query--,which\\n\\nisanewapproachforimprovingtheeffectivenessandefficiencyoftheDoc2Query\\n\\nmodel by filtering out the least relevant queries. We observed that a 16% im-\\n\\nprovement in retrieval effectiveness can be achieved, while reducing the index\\n\\nsize by 33% and mean query execution time by 23%. The technique of filtering text generated from language models using rel-\\n\\nevance scoring is ripe for future work. For instance, relevance filtering could\\n\\npotentially apply to approaches that generate alternative forms of queries [38],\\n\\ntraining data [2], or natural language responses to queries [5]  all of which\\n\\narepotentiallyaffectedbyhallucinatedcontent.Furthermore,futureworkcould\\n\\nexplore approaches for relevance filtering over masked language modelling ex-', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='pansion [19], rather than sequence-to-sequence expansion. Acknowledgements\\n\\nSeanMacAvaneyandCraigMacdonaldacknowledgeEPSRCgrantEP/R018634/1:\\n\\nClosed-LoopDataScienceforComplex,Computationally-&Data-IntensiveAn-\\n\\nalytics. References\\n\\n1. Amati, G., Van Rijsbergen, C.J. : Probabilistic models of information retrieval\\n\\nbasedonmeasuringthedivergencefromrandomness.ACMTrans.Inf.Syst.20(4)\\n\\n(2002)\\n\\n2. Bonifacio,L.,Abonizio,H.,Fadaee,M.,Nogueira,R. :InPars:Unsuperviseddataset\\n\\ngeneration for information retrieval. In: Proceedings of SIGIR (2022)8 Gospodinov et al. 3. Dai, Z., Callan, J.: Deeper text understanding for IR with contextual neural lan-\\n\\nguage modeling. In: Proceedings of SIGIR (2019)\\n\\n4. Dai,Z.,Callan,J. :Context-awaredocumenttermweightingforad-hocsearch.In:\\n\\nProceedings of The Web Conference (2020)\\n\\n5. Das, R., Dhuliawala, S., Zaheer, M., McCallum, A.: Multi-step retriever-reader\\n\\ninteractionforscalableopen-domainquestionanswering.In:ProceedingsofICLR\\n\\n(2019)\\n\\n6. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of deep\\n\\nbidirectionaltransformersforlanguageunderstanding.In:ProceedingsofNAACL-\\n\\nHLT (2019)\\n\\n7. Ding, S., Suel, T.: Faster top-k document retrieval using block-max indexes. In:\\n\\nProceedings of SIGIR (2011)\\n\\n8. Dumais,S.T.,Furnas,G.W.,Landauer,T.K.,Deerwester,S.,Harshman,R. :Using\\n\\nlatentsemanticanalysistoimproveaccesstotextualinformation.In:Proceedings\\n\\nof SIGCHI CHI (1988)\\n\\n9. Efron, M., Organisciak, P., Fenlon, K.: Improving retrieval of short texts through\\n\\ndocument expansion. In: Proceedings of SIGIR (2012)\\n\\n10. Formal,T.,Piwowarski,B.,Clinchant,S. :SPLADE:Sparselexicalandexpansion\\n\\nmodel for first stage ranking. In: Proceedings of SIGIR (2021)\\n\\n11. He,B.,Ounis,I. :Studyingqueryexpansioneffectiveness.In:ProceedingsofECIR\\n\\n(2009)\\n\\n12. Jaleel,N.A.,Allan,J.,Croft,W.B.,Diaz,F.,Larkey,L.S.,Li,X.,Smucker,M.D.,\\n\\nWade, C.: Umass at TREC 2004: Novelty and HARD. In: TREC (2004)\\n\\n13. Johnson,J.,Douze,M.,Jegou,H. :Billion-scalesimilaritysearchwithGPUs.IEEE\\n\\nTransactions on Big Data 7(03) (2021)\\n\\n14. Khattab, O., Zaharia, M.: ColBERT: Efficient and effective passage search via\\n\\ncontextualized late interaction over BERT. In: Proceedings of SIGIR (2020)\\n\\n15. Lin,J.,Ma,X.,Mackenzie,J.,Mallia,A. :Ontheseparationoflogicalandphysical\\n\\nrankingmodelsfortextretrievalapplications.In:ProceedingsofDESIRES(2021)\\n\\n16. Lin, S.C., Yang, J.H., Lin, J.: In-batch negatives for knowledge distillation with', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='tightly-coupled teachers for dense retrieval. In: Proceedings of RepL4NLP (2021)\\n\\n17. MacAvaney, S., Macdonald, C.: A Python interface to PISA! In: Proceedings of\\n\\nSIGIR (2022)\\n\\n18. MacAvaney,S.,Macdonald,C.,Ounis,I.:Streamliningevaluationwithir-measures. In: Proceedings of ECIR (2022)\\n\\n19. MacAvaney, S., Nardini, F.M., Perego, R., Tonellotto, N., Goharian, N., Frieder,\\n\\nO.:Expansionviapredictionofimportancewithcontextualization.In:Proceedings\\n\\nof SIGIR (2020)\\n\\n20. MacAvaney, S., Tonellotto, N., Macdonald, C.: Adaptive re-ranking with a corpus\\n\\ngraph. In: Proceedings of CIKM (2022)\\n\\n21. MacAvaney, S., Yates, A., Feldman, S., Downey, D., Cohan, A., Goharian, N.:\\n\\nSimplified data wrangling with ir_datasets. In: Proceedings of SIGIR (2021)\\n\\n22. Macdonald, C., Tonellotto, N.: Declarative experimentation in information re-\\n\\ntrieval using PyTerrier. In: Proceedings of ICTIR (2020)\\n\\n23. Mallia, A., Khattab, O., Suel, T., Tonellotto, N.: Learning passage impacts for\\n\\ninverted indexes. In: Proceedings of SIGIR (2021)\\n\\n24. Mallia, A., Siedlaczek, M., Mackenzie, J., Suel, T.: PISA: performant indexes and\\n\\nsearch for academia. In: Proceedings of OSIRRC@SIGIR (2019)\\n\\n25. Maynez,J.,Narayan,S.,Bohnet,B.,McDonald,R. :Onfaithfulnessandfactuality\\n\\nin abstractive summarization. In: Proceedings of ACL (2020)Doc2Query--: When Less is More 9\\n\\n26. Nguyen, T., Rosenberg, M., Song, X., Gao, J., Tiwary, S., Majumder, R., Deng,\\n\\nL.:MSMARCO:Ahumangeneratedmachinereadingcomprehensiondataset.In:\\n\\nProceedings of CoCo@NIPS (2016)\\n\\n27. Nogueira, R., Cho, K.: Passage re-ranking with BERT. ArXiv abs/1901.04085\\n\\n(2019)\\n\\n28. Nogueira, R., Lin, J.: From doc2query to doctttttquery (2019)\\n\\n29. Nogueira,R.,Yang,W.,Lin,J.J.,Cho,K. :Documentexpansionbyquerypredic-\\n\\ntion. ArXiv abs/1904.08375 (2019)\\n\\n30. Pickens, J., Cooper, M., Golovchinsky, G.: Reverted indexing for feedback and\\n\\nexpansion. In: Proceedings of CIKM (2010)\\n\\n31. Pradeep,R.,Liu,Y.,Zhang,X.,Li,Y.,Yates,A.,Lin,J. :Squeezingwaterfroma\\n\\nstone:Abagoftricksforfurtherimprovingcross-encodereffectivenessforrerank-\\n\\ning. In: Proceedings of ECIR (2022)\\n\\n32. Pradeep,R.,Nogueira,R.,Lin,J. :Theexpando-mono-duodesignpatternfortext\\n\\nranking with pretrained sequence-to-sequence models. ArXiv abs/2101.05667\\n\\n(2021)\\n\\n33. Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y.,\\n\\nLi, W., Liu, P.J., et al. : Exploring the limits of transfer learning with a unified\\n\\ntext-to-text transformer. J. Mach. Learn. Res. 21(140) (2020)', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='34. Scells, H., Zhuang, S., Zuccon, G.: Reduce, reuse, recycle: Green information re-\\n\\ntrieval research. In: Proceedings of SIGIR (2022)\\n\\n35. Tao, T., Wang, X., Mei, Q., Zhai, C.: Language model information retrieval with\\n\\ndocument expansion. In: Proceedings of HLT-NAACL (2006)\\n\\n36. Wang, X., MacAvaney, S., Macdonald, C., Ounis, I.: An inspection of the repro-\\n\\nducibility and replicability of TCT-ColBERT. In: Proceedings of SIGIR (2022)\\n\\n37. Xiong, L., Xiong, C., Li, Y., Tang, K.F., Liu, J., Bennett, P.N., Ahmed, J., Over-\\n\\nwijk,A. :Approximatenearestneighbornegativecontrastivelearningfordensetext\\n\\nretrieval. In: Proceedings of ICLR (2021)\\n\\n38. Yu, S.Y., Liu, J., Yang, J., Xiong, C., Bennett, P.N., Gao, J., Liu, Z.: Few-shot\\n\\ngenerative conversational query rewriting. In: Proceedings of SIGIR (2020)\\n\\n39. Zhao,T.,Lu,X.,Lee,K. :SPARTA:Efficientopen-domainquestionansweringvia\\n\\nsparse transformer matching retrieval. arXiv abs/2009.13013 (2020)\\n\\n40. Zhuang, S., Zuccon, G.: TILDE: Term independent likelihood model for passage\\n\\nre-ranking. In: Proceedings of SIGIR (2021)Query2doc: Query Expansion with Large Language Models\\n\\nLiangWang and NanYang and FuruWei\\n\\nMicrosoftResearch\\n\\n{wangliang,nanya,fuwei}@microsoft.com\\n\\nAbstract 2009)haveonlyshownlimitedsuccessonpopular\\n\\ndatasets (Camposetal.,2016),andmoststate-of-\\n\\nThis paper introduces a simple yet effec-\\n\\nthe-artdenseretrieversdonotadoptthistechnique. tive query expansion approach, denoted as\\n\\nInthemeantime,documentexpansionmethodslike\\n\\nquery2doc, to improve both sparse and dense\\n\\n3202\\n\\nretrieval systems. The proposed method doc2query (Nogueiraetal.,2019)haveprovento\\n\\nfirstgeneratespseudo-documentsbyfew-shot beeffectiveforsparseretrieval. promptinglargelanguagemodels(LLMs),and Inthispaper,wedemonstratetheeffectiveness\\n\\nthenexpandsthequerywithgeneratedpseudo- of LLMs (Brown et al., 2020) as query expan- raM\\n\\ndocuments. LLMs are trained on web-scale\\n\\nsionmodelsbygeneratingpseudo-documentscon-\\n\\ntextcorporaandareadeptatknowledgemem-\\n\\nditioned on few-shot prompts. Given that search\\n\\norization. Thepseudo-documentsfromLLMs\\n\\n41\\n\\nqueriesareoftenshort,ambiguous,orlackneces-\\n\\noften contain highly relevant information that\\n\\ncan aid in query disambiguation and guide sarybackgroundinformation, LLMscanprovide\\n\\nthe retrievers. Experimental results demon- relevantinformationtoguideretrievalsystems,as ]RI.sc[\\n\\nstrate that query2doc boosts the performance theymemorizeanenormousamountofknowledge\\n\\nofBM25by3%to15%onad-hocIRdatasets,', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='andlanguagepatternsbypre-trainingontrillions\\n\\nsuch as MS-MARCO and TREC DL, with-\\n\\noftokens. out any model fine-tuning. Furthermore, our\\n\\nOur proposed method, called query2doc, gen-\\n\\nmethod also benefits state-of-the-art dense re-\\n\\n1v87670.3032:viXra\\n\\ntrieversintermsofbothin-domainandout-of- erates pseudo-documents by few-shot prompting\\n\\ndomainresults. LLMs and concatenates them with the original\\n\\nquerytoformanewquery. Thismethodissimple\\n\\n1 Introduction\\n\\ntoimplementanddoesnotrequireanychangesin\\n\\nInformation retrieval (IR) aims to locate relevant trainingpipelinesormodelarchitectures,makingit\\n\\ndocuments from a large corpus given a user is- orthogonaltotheprogressinthefieldofLLMsand\\n\\nsued query. It is a core component in modern information retrieval. Future methods can easily\\n\\nsearch engines and researchers have invested for builduponourqueryexpansionframework. decades in this field. There are two mainstream For in-domain evaluation, we adopt the MS-\\n\\nparadigms for IR: lexical-based sparse retrieval, MARCOpassageranking (Camposetal.,2016),\\n\\nsuch as BM25, and embedding-based dense re- TREC DL 2019 and 2020 datasets. Pseudo-\\n\\ntrieval (Xiong et al., 2021; Qu et al., 2021). Al- documents are generated by prompting an im-\\n\\nthoughdenseretrieversperformbetterwhenlarge proved version of GPT-3 text-davinci-003 from\\n\\namountsoflabeleddataareavailable (Karpukhin OpenAI (Brown et al., 2020). Results show that\\n\\netal.,2020),BM25remainscompetitiveonout-of- query2docsubstantiallyimprovestheoff-the-shelf\\n\\ndomaindatasets (Thakuretal.,2021). BM25 algorithm without fine-tuning any model,\\n\\nQuery expansion (Rocchio, 1971; Lavrenko particularly for hard queries from the TREC DL\\n\\nand Croft, 2001) is a long-standing technique track. Strong dense retrievers, including DPR\\n\\nthatrewritesthequerybasedonpseudo-relevance (Karpukhin et al., 2020), SimLM (Wang et al.,\\n\\nfeedback or external knowledge sources such as 2022a), and E5 (Wang et al., 2022b) also bene-\\n\\nWordNet. For sparse retrieval, it can help bridge fitfromquery2doc,althoughthegainstendtobe\\n\\nthe lexical gap between the query and the docu- diminishing when distilling from a strong cross-\\n\\nments. However, query expansion methods like encoderbasedre-ranker. Experimentsinzero-shot\\n\\nRM3 (Lavrenko and Croft, 2001; Lv and Zhai, OOD settings demonstrate that our method out-performs strong baselines on most datasets. Fur-\\n\\ntheranalysisalsorevealstheimportanceofmodel q+ = concat({q}n, d(cid:48)) (1)', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='scales: query2docworksbestwhencombinedwith\\n\\nHere, concat denotes the string concatenation\\n\\nthemostcapableLLMswhilesmalllanguagemod- function. q+ is used as the new query for\\n\\nelsonlyprovidemarginalimprovementsoverbase-\\n\\nBM25 retrieval. We find that n = 5 is a gener-\\n\\nlines. allygoodvalueanddonottuneitonadatasetbasis. To aid reproduction, we release all\\n\\nthe generations from text-davinci-003 Dense Retrieval The new query q+ is a sim-\\n\\nat https://huggingface.co/datasets/\\n\\nple concatenation of the original query q and the\\n\\nintfloat/query2doc_msmarco. pseudo-documentd(cid:48) separatedby[SEP]:\\n\\n2 Method q+ = concat(q, [SEP], d(cid:48)) (2)\\n\\nFortrainingdenseretrievers,severalfactorscan\\n\\ninfluencethefinalperformance,suchashardnega-\\n\\nLLM Prompts tivemining (Xiongetal.,2021),intermediatepre-\\n\\ntraining (GaoandCallan,2021),andknowledge\\n\\nWrite a passage that answers the given query:\\n\\ndistillation from a cross-encoder based re-ranker\\n\\nQuery:what state is this zip code 85282 (Quetal.,2021). Inthispaper,weinvestigatetwo\\n\\nPassage:Welcome to TEMPE, AZ 85282.\\n\\nsettingstogainamorecomprehensiveunderstand-\\n\\n85282 is a rural zip code in Tempe, Arizona. The population is primarily white ingofourmethod. ThefirstsettingistrainingDPR\\n\\n(Karpukhin et al., 2020) models initialized from\\n\\nQuery:when was pokemongreen released\\n\\nBERT withBM25hardnegativesonly. Theop-\\n\\nPassage: base\\n\\ntimizationobjectiveisastandardcontrastiveloss:\\n\\nLLM Output ehqh d\\n\\nL = log (3)\\n\\nP Feo bke rum ao ryn 2G 7r te he n 9w 9a 6s r Ie l wea as se td ein iJ ra sp a inn to hn cont ehqh d +(cid:80) diNehqh di\\n\\n, 1 . t h f t e\\n\\nPokemonseries of games and served as the whereh andh representtheembeddingsforthe\\n\\nq d\\n\\nbasis for PokemonRed and Blue, which were query and document, respectively. N denotes the\\n\\nreleased in the US in 1998. The original\\n\\nsetofhardnegatives. PokemonGreen remains a beloved classic\\n\\namong fans of the series. Thesecondsettingistobuilduponstate-of-the-\\n\\nartdenseretrieversanduseKLdivergencetodistill\\n\\nfromacross-encoderteachermodel. Figure1:Illustrationofquery2docfew-shotprompting. Weomitsomein-contextexamplesforspacereasons. min D (p ,p )+L (4)\\n\\nKL ce stu cont\\n\\np and p are the probabilities from the cross-\\n\\nce stu\\n\\nGivenaqueryq,weemployfew-shotprompting encoderandourstudentmodel,respectively. is\\n\\nto generate a pseudo-document d(cid:48) as depicted in a coefficient to balance the distillation loss and', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='Figure 1. Thepromptcomprisesabriefinstruction contrastiveloss. Write a passage that answers the given query:\\n\\nand k labeled pairs randomly sampled from a Comparison with Pseudo-relevance Feedback\\n\\ntrainingset. Weusek = 4throughoutthis paper. Our proposed method can be viewed as a variant\\n\\nSubsequently, we rewrite q to a new query q+ of pseudo-relevance feedback (PRF) (Lavrenko\\n\\nby concatenating with the pseudo-document d(cid:48). and Croft, 2001; Lv and Zhai, 2009). In conven-\\n\\nThere are slight differences in the concatenation tionalPRF,thefeedbacksignalsforqueryexpan-\\n\\noperation for sparse and dense retrievers, which sion come from the top-k documents obtained in\\n\\nweelaborateoninthefollowingsection. theinitialretrievalstep,whileourmethodprompts\\n\\nLLMstogeneratepseudo-documents. Ourmethod\\n\\nSparse Retrieval Since the query q is typically doesnotrelyonthequalityoftheinitialretrievalre-\\n\\nmuchshorterthanpseudo-documents,weboostthe sults,whichareoftennoisyorirrelevant. Rather,it\\n\\nquerytermweightsbyrepeatingthequeryntimes exploitscutting-edgeLLMstogeneratedocuments\\n\\nbeforeconcatenatingwiththepseudo-documentd(cid:48): thataremorelikelytocontainrelevantterms.MSMARCOdev TRECDL19 TRECDL20\\n\\nMethod Fine-tuning\\n\\nMRR@10 R@50 R@1k nDCG@10 nDCG@10\\n\\nSparseretrieval\\n\\nBM25 (cid:55) 18.4 58.5 85.7 51.2 47.7\\n\\n+query2doc (cid:55) 21.4+3.0 65.3+6.8 91.8+6.1 66.2+15.0 62.9+15.2\\n\\nBM25+RM3 (cid:55) 15.8 56.7 86.4 52.2 47.4\\n\\ndocT5query (NogueiraandLin) (cid:51) 27.7 75.6 94.7 64.2 -\\n\\nDenseretrievalw/odistillation\\n\\nANCE (Xiongetal.,2021) (cid:51) 33.0 - 95.9 64.5 64.6\\n\\nHyDE (Gaoetal.,2022) (cid:55) - - - 61.3 57.9\\n\\nDPR (ourimpl.) (cid:51) 33.7 80.5 95.9 64.7 64.1\\n\\nbert-base\\n\\n+query2doc (cid:51) 35.1+1.4 82.6+2.1 97.2+1.3 68.7+4.0 67.1+3.0\\n\\nDenseretrievalw/distillation\\n\\nRocketQAv2 (Renetal.,2021) (cid:51) 38.8 86.2 98.1 - -\\n\\nAR2 (Zhangetal.,2021) (cid:51) 39.5 87.8 98.6 - -\\n\\nSimLM (Wangetal.,2022a) (cid:51) 41.1 87.8 98.7 71.4 69.7\\n\\n+query2doc (cid:51) 41.5+0.4 88.0+0.2 98.8+0.1 72.9+1.5 71.6+1.9\\n\\nE5 +KD (Wangetal.,2022b) (cid:51) 40.7 87.6 98.6 74.3 70.7\\n\\nbase\\n\\n+query2doc (cid:51) 41.5+0.8 88.1+0.5 98.7+0.1 74.9+0.6 72.5+1.8\\n\\nTable1: MainresultsontheMS-MARCOpassagerankingandTRECdatasets. TheFine-tuningcolumnindi-\\n\\ncateswhetherthemethodrequiresfine-tuningmodelonlabeleddataornot. : ourreproduction. 3 Experiments arelong-tailedentity-centricqueries,whichbenefit\\n\\nmorefromtheexactlexicalmatch. Thetraditional\\n\\n3.1 Setup\\n\\nquery expansion method RM3 only marginally', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='Evaluation Datasets For in-domain evaluation, improves the R@1k metric. Although the docu-\\n\\nweutilizetheMS-MARCOpassageranking (Cam- mentexpansionmethoddocT5queryachievesbet-\\n\\nposetal.,2016),TRECDL2019 (Craswelletal., ternumbersontheMS-MARCOdevset,itrequires\\n\\n2020a)and2020 (Craswelletal.,2020b)datasets. training a T5-based query generator with all the\\n\\nForzero-shotout-of-domainevaluation,weselect availablelabeleddata,whileBM25+query2doc\\n\\nfive low-resource datasets from the BEIR bench- doesnotrequireanymodelfine-tuning. mark (Thakur et al., 2021). The evaluation met- Fordenseretrieval,themodelvariantsthatcom-\\n\\nricsincludeMRR@10,R@k(k  {50,1k}),and bine with query2doc also outperform the corre-\\n\\nnDCG@10. sponding baselines on all metrics. However, the\\n\\nHyperparameters Forsparseretrievalincluding gainbroughtbyquery2doctendstodiminishwhen\\n\\nBM25andRM3,weadoptthedefaultimplementa- usingintermediatepre-trainingorknowledgedistil-\\n\\ntionfromPyserini (Linetal.,2021). Whentraining lationfromcross-encoderre-rankers,asshownby\\n\\ndense retrievers, we use mostly the same hyper- theSimLM+query2docandE5+query2doc\\n\\nparametersas SimLM(Wanget al.,2022a), with results. the exception of increasing the maximum query Forzero-shotout-of-domainretrieval,theresults\\n\\nlengthto144toincludepseudo-documents. When are mixed as shown in Table 2. Entity-centric\\n\\nprompting LLMs, we include 4 in-context exam- datasetslikeDBpediaseethelargestimprovements. plesandusethedefaulttemperatureof1tosample OntheNFCorpusandScifactdatasets,weobserve\\n\\natmost128tokens. Forfurtherdetails,pleaserefer aminordecreaseinrankingquality. Thisislikely\\n\\ntoAppendix A. duetothedistributionmismatchbetweentraining\\n\\nandevaluation. 3.2 MainResults\\n\\n4 Analysis\\n\\nInTable 1,welisttheresultsontheMS-MARCO\\n\\npassagerankingandTRECDLdatasets. Forsparse Scaling up LLMs is Critical For our proposed\\n\\nretrieval, BM25 + query2doc beats the BM25 method, a question that naturally arises is: how\\n\\nbaseline with over 15% improvements on TREC does the model scale affect the quality of query\\n\\nDL2019and2020datasets. Ourmanualinspection expansion? Table 3 shows that the performance\\n\\nrevealsthatmostqueriesfromtheTRECDLtrack steadily improves as we go from the 1.3B modelDBpedia NFCorpus Scifact Trec-Covid Touche2020\\n\\nBM25 31.3 32.5 66.5 65.6 36.7\\n\\n+query2doc 37.0+5.7 34.9+2.4 68.6+2.1 72.2+6.6 39.8+3.1\\n\\nSimLM (Wangetal.,2022a) 34.9 32.7 62.4 55.0 18.9\\n\\n+query2doc 38.3+3.4 32.1-0.6 59.5-2.9 59.9+4.9 25.6+6.7', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='E5 +KD (Wangetal.,2022b) 40.7 35.0 70.4 74.1 30.9\\n\\nbase\\n\\n+query2doc 42.4+1.7 35.2+0.2 67.5-2.9 75.1+1.0 31.7+0.8\\n\\nTable 2: Zero-shot out-of-domain results on 5 low-resource datasets from the BEIR benchmark (Thakur et al.,\\n\\n2021). ThereportednumbersarenDCG@10. Forafaircomparison,thein-contextexamplesforpromptingLLMs\\n\\ncomefromtheMS-MARCOtrainingset. #params TREC19 TREC20 contributionisorthogonaltothecontinualscaling\\n\\nBM25 - 51.2 47.7 upofsupervisionsignals. w/babbage 1.3B 52.0 50.2\\n\\nw/curie 6.7B 55.1 50.1\\n\\nw/davinci-001 175B 63.5 58.2 TREC19 TREC20\\n\\nw/davinci-003 175B 66.2 62.9 BM25+query2doc 66.2 62.9\\n\\nw/queryonly 51.2 47.7\\n\\nTable3: Queryexpansionwithdifferentmodelsizes. w/pseudo-doconly 48.7 44.5\\n\\nto175Bmodels. Empirically,thetextsgenerated Table4: Usingtheconcatenationoftheoriginalquery\\n\\nandthegeneratedpseudo-documentsperformsubstan-\\n\\nbysmallerlanguagemodelstendtobeshorterand\\n\\ntiallybetter. containmorefactualerrors. Also,thedavinci-003\\n\\nmodeloutperformsitsearlierversiondavinci-001\\n\\nHow to Use Pseudo-documents In this paper,\\n\\nby using better training data and improved\\n\\nwe concatenate the original query and pseudo-\\n\\ninstructiontuning. documentsasthenewquery. Alternatively,onecan\\n\\nsolely use the pseudo-documents, as done in the\\n\\napproachofHyDE (Gaoetal.,2022). Theresults\\n\\npresentedinTable 4demonstratethattheoriginal\\n\\n36 35.1 queryandpseudo-documentsarecomplementary,\\n\\n34.1\\n\\n34 andtheircombinationleadstosubstantiallybetter\\n\\n32.1 33.7\\n\\n32 32.8 performanceinsparseretrieval. tes\\n\\n31.4 30 ved\\n\\n28.5\\n\\n28 CaseAnalysis InTable 5,weshowtwoqueries no\\n\\n27.3 alongwiththeirrespectivepseudo-documentsand RRM\\n\\n26\\n\\ngroundtruth. The pseudo-documents, which are\\n\\n24\\n\\n22.7\\n\\nDPR w/o query2doc generatedbyLLMs,offerdetailedandmostlyac-\\n\\n22\\n\\nDPR w/ query2doc curate information, thereby reducing the lexical\\n\\n21.4\\n\\n20\\n\\n1 10 30 50 100 mismatch between the query and documents. In\\n\\n% labeled data for fine-tuning\\n\\nsomecases,thepseudo-documentsaresufficientto\\n\\nFigure 2: MRR on MS-MARCO dev set w.r.t the per-\\n\\nmeet the users information needs, rendering the\\n\\ncentageoflabeleddatausedforfine-tuning. retrieval step unnecessary. However, it is worth\\n\\nnotingthattheLLMgenerationsmaycontainfac-\\n\\nPerformance Gains are Consistent across Data tualerrors. Forinstance,inthesecondquery,the\\n\\nScales Figure 2 presents a comparison between themesong\"ItsaJungleOutThere\"wasusedas\\n\\ntwo variants of DPR models, which differ in the ofseasontwoin2003,not2002 1. Althoughsuch', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='amount of labeled data used. The results show errorsmayappearsubtleanddifficulttoverify,they\\n\\nthat the DPR + query2doc variant consistently poseasignificantchallengetobuildingtrustworthy\\n\\noutperforms the DPR baseline by approximately systemsusingLLMs. 1%, regardless of the amount of data used for\\n\\n1Refer to https://en.wikipedia.org/wiki/Its_a_\\n\\nfine-tuning. This observation highlights that our Jungle_Out_There_(song)query whokillednicholasiiofrussia\\n\\nLLMgeneration NicholasIIofRussia,thelastTsarofRussia,wasexecutedbyBolshevikrevolutionarieson\\n\\nJuly17th,1918,alongwithhiswifeAlexandraandtheirfivechildren. Theexecutionwas\\n\\norderedbyVladimirLenin,theleaderoftheBolshevikParty.Theactualexecutionwascarried\\n\\noutbyafiringsquadofBolsheviktroops,andthebodieswerelaterburiedinamassgrave...\\n\\nGroundtruth (1868-1918). Nicholas II was the last emperor, or tsar, of Russia, serving from 1894 to\\n\\n1917.Nicholas,hiswife,andtheirfivechildrenwerekilledbytheBolsheviks,membersofa\\n\\nrevolutionarygroup(ledbyLenin)whoseizedcontrolofthegovernmentinRussiaduring\\n\\ntheOctoberRevolution(seeRussianRevolution)of1917. query whosingsmonkthemesong\\n\\nLLMgeneration ThethemesongforthetelevisionshowMonkisentitled\"ItsaJungleOutThere\"andis\\n\\nsungbyAmericansinger-songwriterRandyNewman.Thesongwaswrittenspecificallyfor\\n\\ntheshow,andithasbeenusedasthethemesongsincetheseriespremieredin2002. Ithas\\n\\nbeenpraisedbycriticsandfansalikeandisoftenregardedasoneofthebestthemesongsin\\n\\ntelevisionhistory. Groundtruth existsandisanalternateof. TheMonkthemesongisItsaJungleOutTherebyRandy\\n\\nNewman.TheMonkthemesongisItsaJungleOutTherebyRandyNewman. Table5: ExamplesfromtheTRECDL2020dataset. Boldtextsaretheoverlappingwordsbetweengroundtruth\\n\\nandpseudo-documentsgeneratedfromLLMs. Theitalicizedredsentencedemonstratesafactualerrorinlanguage\\n\\nmodelgenerations. 5 RelatedWork across various tasks. LLMs can follow instruc-\\n\\ntionsinazero-shotmannerorconductin-context\\n\\nQuery Expansion and Document Expansion\\n\\nlearningthroughfew-shotprompting. Labelinga\\n\\nare two classical techniques to improve retrieval\\n\\nfewhigh-qualityexamplesonlyrequiresminimal\\n\\nquality, particularly for sparse retrieval systems. human effort. In this paper, we employ few-shot\\n\\nBothtechniquesaimtominimizethelexicalgapbe-\\n\\nprompting to generate pseudo-documents from a\\n\\ntweenthequeryandthedocuments. Queryexpan-\\n\\ngivenquery. AcloselyrelatedrecentworkHyDE\\n\\nsion typically involves rewriting the query based\\n\\n(Gao et al., 2022) instead focuses on the zero-', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='onrelevancefeedback (LavrenkoandCroft,2001;\\n\\nshot setting and uses embeddings of the pseudo-\\n\\nRocchio,1971)orlexicalresourcessuchasWord-\\n\\ndocumentsforsimilaritysearch. HyDEimplicitly\\n\\nNet (Miller, 1992). In cases where labeled rele-\\n\\nassumesthatthegroundtruthdocumentandpseudo-\\n\\nvancefeedbackisnotavailable,thetop-kretrieved\\n\\ndocumentsexpressthesamesemanticsindifferent\\n\\ndocumentscanserveaspseudo-relevancefeedback\\n\\nwords,whichmaynotholdforsomequeries. Inthe\\n\\nsignals (LvandZhai,2009). fieldofquestionanswering,RECITE (Sunetal.,\\n\\nIn contrast, document expansion enriches the\\n\\n2022) and GENREAD (Yu et al., 2022) demon-\\n\\ndocumentrepresentationbyappendingadditional\\n\\nstratethatLLMsarepowerfulcontextgenerators\\n\\nrelevantterms. Doc2query (Nogueiraetal.,2019)\\n\\nandcanencodeabundantfactualknowledge. How-\\n\\ntrains a seq2seq model to predict pseudo-queries\\n\\never,asouranalysisshows,LLMscansometimes\\n\\nbased on documents and then adds generated\\n\\ngeneratefalseclaims,hinderingtheirpracticalap-\\n\\npseudo-queries to the document index. Learned\\n\\nplicationincriticalareas. sparseretrievalmodelssuchasSPLADE (Formal\\n\\net al., 2021) and uniCOIL (Lin and Ma, 2021)\\n\\n6 Conclusion\\n\\nalsolearndocumenttermweightinginanend-to-\\n\\nendfashion. However,moststate-of-the-artdense This paper presents a simple method query2doc\\n\\nretrievers (Ren et al., 2021; Wang et al., 2022a) to leverage LLMs for query expansion. It first\\n\\ndo not adopt any expansion techniques. Our pa- prompts LLMs with few-shot examples to gener-\\n\\nperdemonstratesthatstrongdenseretrieversalso atepseudo-documentsandthenintegrateswithex-\\n\\nbenefitfromqueryexpansionusingLLMs. isting sparse or dense retrievers by augmenting\\n\\nLargeLanguageModels(LLMs) suchasGPT-3 querieswithgeneratedpseudo-documents. Theun-\\n\\n(Brown et al., 2020), PaLM (Chowdhery et al., derlyingmotivationistodistilltheLLMsthrough\\n\\n2022), and LLaMA (Touvron et al., 2023) are prompting. Despiteitssimplicity,empiricalevalua-\\n\\ntrainedontrillionsoftokenswithbillionsofparam- tionsdemonstrateconsistentimprovementsacross\\n\\neters,exhibitingunparalleledgeneralizationability variousretrievalmodelsanddatasets.Limitations Majumder, Li Deng, and Bhaskar Mitra. 2016. Ms\\n\\nmarco: A human generated machine reading com-\\n\\nprehensiondataset. ArXiv,abs/1611.09268. LLMcall Indexsearch\\n\\nBM25 - 16ms Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,\\n\\n+query2doc >2000ms 177ms Maarten Bosma, Gaurav Mishra, Adam Roberts,\\n\\nPaul Barham, Hyung Won Chung, Charles Sutton,', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='Sebastian Gehrmann, Parker Schuh, Kensen Shi,\\n\\nTable6:Latencyanalysisforretrievalsystemswithour\\n\\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\\n\\nproposedquery2doc.Weretrievethetop100resultsfor\\n\\nRao,ParkerBarnes,YiTay,NoamM.Shazeer,Vin-\\n\\nMS-MARCOdevquerieswithasinglethreadandthen\\n\\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben-\\n\\naverageoverallthequeries. ThelatencyforLLMAPI\\n\\ntonC.Hutchinson,ReinerPope,JamesBradbury,Ja-\\n\\ncallsdependsonserverloadandisdifficulttoprecisely\\n\\ncobAustin,MichaelIsard,GuyGur-Ari,Pengcheng\\n\\nmeasure. Yin, Toju Duke, Anselm Levskaya, Sanjay Ghe-\\n\\nmawat, Sunipa Dev, Henryk Michalewski, Xavier\\n\\nGarca, Vedant Misra, Kevin Robinson, Liam Fe-\\n\\nAn apparent limitation is the efficiency of re-\\n\\ndus, Denny Zhou, Daphne Ippolito, David Luan,\\n\\ntrieval. Ourmethodrequiresrunninginferencewith\\n\\nHyeontaekLim,BarretZoph,AlexanderSpiridonov,\\n\\nLLMswhichcanbeconsiderablyslowerduetothe RyanSepassi,DavidDohan,ShivaniAgrawal,Mark\\n\\ntoken-by-tokenautoregressivedecoding. Moreover, Omernick,AndrewM.Dai,ThanumalayanSankara-\\n\\nwithquery2doc,searchingtheinvertedindexalso narayana Pillai, Marie Pellat, Aitor Lewkowycz,\\n\\nErica Moreira, Rewon Child, Oleksandr Polozov,\\n\\nbecomesslowerasthenumberofquerytermsin-\\n\\nKatherineLee,ZongweiZhou,XuezhiWang,Bren-\\n\\ncreases afterexpansion. This issupported by the nanSaeta,MarkDaz,OrhanFirat,MicheleCatasta,\\n\\nbenchmarkingresultsinTable 6. Real-worldde- Jason Wei, Kathleen S. Meier-Hellstern, Douglas\\n\\nploymentofourmethodshouldtakethesefactors Eck,JeffDean,SlavPetrov,andNoahFiedel.2022. Palm: Scaling language modeling with pathways. intoconsideration. ArXiv,abs/2204.02311. Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel\\n\\nReferences\\n\\nCampos, and Ellen M Voorhees. 2020a. Overview\\n\\nofthetrec2019deeplearningtrack. ArXivpreprint,\\n\\nAlexander Bondarenko, Maik Frbe, Johannes Kiesel,\\n\\nabs/2003.07820. Shahbaz Syed, Timon Gurcke, Meriem Beloucif,\\n\\nAlexanderPanchenko,ChrisBiemann,BennoStein,\\n\\nNick Craswell, Bhaskar Mitra, Emine Yilmaz,\\n\\nHenning Wachsmuth, et al. 2022. Overview of\\n\\nDaniel Fernando Campos, and Ellen M. Voorhees. touch 2022: argument retrieval. In Interna-\\n\\n2020b. Overview of the trec 2020 deep learning\\n\\ntional Conference of the Cross-Language Evalua-\\n\\ntrack. ArXiv,abs/2003.07820. tion Forum for European Languages, pages 311\\n\\n336.Springer. ThibaultFormal,BenjaminPiwowarski,andStphane\\n\\nClinchant.2021. Splade: Sparselexicalandexpan-\\n\\nVera Boteva, Demian Gholipour, Artem Sokolov, and\\n\\nsion model for first stage ranking. Proceedings of', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='Stefan Riezler. 2016. A full-text learning to rank\\n\\nthe 44th International ACM SIGIR Conference on\\n\\ndataset for medical information retrieval. In Euro-\\n\\nResearchandDevelopmentinInformationRetrieval. pean Conference on Information Retrieval, pages\\n\\n716722.Springer. Luyu Gao and Jamie Callan. 2021. Condenser: a pre-\\n\\nTomB.Brown,BenjaminMann,NickRyder,Melanie trainingarchitecturefordenseretrieval. InProceed-\\n\\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind ings of the 2021 Conference on Empirical Methods\\n\\nNeelakantan,PranavShyam,GirishSastry,Amanda in Natural Language Processing, pages 981993,\\n\\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, OnlineandPuntaCana,DominicanRepublic.Asso-\\n\\nGretchen Krueger, Tom Henighan, Rewon Child, ciationforComputationalLinguistics. Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\\n\\nClemens Winter, Christopher Hesse, Mark Chen, Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie\\n\\nEric Sigler, Mateusz Litwin, Scott Gray, Benjamin Callan.2022. Precisezero-shotdenseretrievalwith-\\n\\nChess, Jack Clark, Christopher Berner, Sam Mc- outrelevancelabels. ArXiv,abs/2212.10496. Candlish, Alec Radford, Ilya Sutskever, and Dario\\n\\nAmodei.2020. Languagemodelsarefew-shotlearn- Faegheh Hasibi, Fedor Nikolaev, Chenyan Xiong,\\n\\ners. InAdvancesinNeuralInformationProcessing Krisztian Balog, Svein Erik Bratsberg, Alexander\\n\\nSystems33: AnnualConferenceonNeuralInforma- Kotov, and Jamie Callan. 2017. Dbpedia-entity v2:\\n\\ntion Processing Systems 2020, NeurIPS 2020, De- A test collection for entity search. In Proceedings\\n\\ncember6-12,2020,virtual. ofthe40thInternationalACMSIGIRConferenceon\\n\\nResearchandDevelopmentinInformationRetrieval,\\n\\nDanielFernandoCampos,TriNguyen,MirRosenberg, Shinjuku, Tokyo, Japan, August 7-11, 2017, pages\\n\\nXia Song, Jianfeng Gao, Saurabh Tiwary, Rangan 12651268.ACM.VladimirKarpukhin,BarlasOguz,SewonMin,Patrick ZhiqingSun,XuezhiWang,YiTay,YimingYang,and\\n\\nLewis,LedellWu,SergeyEdunov,DanqiChen,and DennyZhou.2022. Recitation-augmentedlanguage\\n\\nWen-tau Yih. 2020. Dense passage retrieval for models. ArXiv,abs/2210.01296. open-domainquestionanswering. InProceedingsof\\n\\nthe 2020 Conference on Empirical Methods in Nat- Nandan Thakur, Nils Reimers, Andreas Rckl, Ab-\\n\\nural Language Processing (EMNLP), pages 6769 hishek Srivastava, and Iryna Gurevych. 2021. Beir:\\n\\n6781, Online. Association for Computational Lin- A heterogeneous benchmark for zero-shot evalua-\\n\\nguistics. tion of information retrieval models. In Thirty-fifth', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='Conference on Neural Information Processing Sys-\\n\\nVictorLavrenkoandW.BruceCroft.2001. Relevance- temsDatasetsandBenchmarksTrack(Round2). basedlanguagemodels. ACMSIGIRForum,51:260\\n\\n267. HugoTouvron,ThibautLavril,GautierIzacard,Xavier\\n\\nMartinet, Marie-Anne Lachaux, Timothe Lacroix,\\n\\nJimmy J. Lin and Xueguang Ma. 2021. A few brief\\n\\nBaptiste Rozire, Naman Goyal, Eric Hambro,\\n\\nnotes on deepimpact, coil, and a conceptual frame-\\n\\nFaisal Azhar, Aurelien Rodriguez, Armand Joulin,\\n\\nwork for information retrieval techniques. ArXiv,\\n\\nEdouard Grave, and Guillaume Lample. 2023.\\n\\nabs/2106.14807. Llama:Openandefficientfoundationlanguagemod-\\n\\nels. ArXiv,abs/2302.13971. JimmyJ.Lin,XueguangMa,Sheng-ChiehLin,Jheng-\\n\\nHongYang,RonakPradeep,RodrigoNogueira,and\\n\\nEllen Voorhees, Tasmeer Alam, Steven Bedrick, Dina\\n\\nDavidR.Cheriton.2021. Pyserini:Apythontoolkit\\n\\nDemner-Fushman,WilliamRHersh,KyleLo,Kirk\\n\\nforreproducibleinformationretrievalresearchwith\\n\\nRoberts, Ian Soboroff, and Lucy Lu Wang. 2021.\\n\\nsparseanddenserepresentations. Proceedingsofthe\\n\\nTrec-covid: constructingapandemicinformationre-\\n\\n44th International ACM SIGIR Conference on Re-\\n\\ntrieval test collection. In ACM SIGIR Forum, vol-\\n\\nsearchandDevelopmentinInformationRetrieval. ume54,pages112.ACMNewYork,NY,USA. YuanhuaLvandChengXiangZhai.2009. Acompara-\\n\\ntivestudyofmethodsforestimatingquerylanguage David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu\\n\\nmodels with pseudo feedback. Proceedings of the Wang, Madeleine van Zuylen, Arman Cohan, and\\n\\n18th ACM conference on Information and knowl- Hannaneh Hajishirzi. 2020. Fact or fiction: Verify-\\n\\nedgemanagement. ing scientific claims. In Proceedings of the 2020\\n\\nConference on Empirical Methods in Natural Lan-\\n\\nGeorgeA.Miller.1992. WordNet: Alexicaldatabase guageProcessing(EMNLP),pages75347550,On-\\n\\nforEnglish. InSpeechandNaturalLanguage: Pro- line.AssociationforComputationalLinguistics. ceedings of a Workshop Held at Harriman, New\\n\\nYork,February23-26,1992. LiangWang,NanYang,XiaolongHuang,BinxingJiao,\\n\\nLinjun Yang, Daxin Jiang, Rangan Majumder, and\\n\\nRodrigoNogueiraandJimmyLin. Fromdoc2queryto Furu Wei. 2022a. Simlm: Pre-training with rep-\\n\\ndoctttttquery. resentation bottleneck for dense passage retrieval. ArXiv,abs/2207.02578. Rodrigo Nogueira, Wei Yang, Jimmy J. Lin, and\\n\\nKyunghyun Cho. 2019. Document expansion by\\n\\nLiang Wang, Nan Yang, Xiaolong Huang, Binx-\\n\\nqueryprediction. ArXiv,abs/1904.08375. ing Jiao, Linjun Yang, Daxin Jiang, Rangan Ma-\\n\\njumder, andFuruWei.2022b. Textembeddingsby', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang\\n\\nweakly-supervised contrastive pre-training. ArXiv,\\n\\nRen, Wayne Xin Zhao, Daxiang Dong, Hua Wu,\\n\\nabs/2212.03533. and Haifeng Wang. 2021. RocketQA: An opti-\\n\\nmized training approach to dense passage retrieval\\n\\nLee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang,\\n\\nfor open-domain question answering. In Proceed-\\n\\nJialin Liu, Paul N. Bennett, Junaid Ahmed, and\\n\\nings of the 2021 Conference of the North Ameri-\\n\\nArnoldOverwijk.2021. Approximatenearestneigh-\\n\\ncan Chapter of the Association for Computational\\n\\nbor negative contrastive learning for dense text re-\\n\\nLinguistics: Human Language Technologies, pages\\n\\ntrieval. In9thInternationalConferenceonLearning\\n\\n58355847, Online. Association for Computational\\n\\nRepresentations,ICLR2021,VirtualEvent,Austria,\\n\\nLinguistics. May3-7,2021.OpenReview.net. Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao,\\n\\nQiaoQiaoShe,HuaWu,HaifengWang,andJi-Rong W.Yu,DanIter,ShuohangWang,YichongXu,Mingx-\\n\\nWen. 2021. RocketQAv2: A joint training method uan Ju, Soumya Sanyal, Chenguang Zhu, Michael\\n\\nfor dense passage retrieval and passage re-ranking. Zeng, and Meng Jiang. 2022. Generate rather than\\n\\nIn Proceedings of the 2021 Conference on Empiri- retrieve: Large language models are strong context\\n\\ncalMethodsinNaturalLanguageProcessing,pages generators. ArXiv,abs/2209.10063. 28252835,OnlineandPuntaCana,DominicanRe-\\n\\npublic.AssociationforComputationalLinguistics. Hang Zhang, Yeyun Gong, Yelong Shen, Jiancheng\\n\\nLv, Nan Duan, and Weizhu Chen. 2021. Adversar-\\n\\nJ.J.Rocchio.1971. Relevancefeedbackininformation ial retriever-ranker for dense text retrieval. ArXiv\\n\\nretrieval. preprint,abs/2110.03611.query whosingsheygoodlooking\\n\\nLLMgeneration HeyGoodLookinwasoriginallywrittenandrecordedbythecountrymusicsingerHank\\n\\nWilliams in 1951. The song has since been covered by several other artists and bands,\\n\\nincludingJimmyBuffett,ConwayTwitty,andWillieNelson. Groundtruth Hey,GoodLookin. (1951)Hey,GoodLookinisa1951songwrittenandrecordedbyHank\\n\\nWilliams, andhisversionwasinductedintotheGrammyHallofFamein2001. Sinceits\\n\\noriginal1951recordingithasbeencoveredbyavarietyofartists. query trumbullmarriottfaxnumber\\n\\nLLMgeneration ThefaxnumberfortheTrumbullMarriottSheltonis203-378-4444. Groundtruth Businessname: TrumbullMarriottMerrittParkway;Address: 180HawleyLaneTrumbull,\\n\\nConnecticut 06611; Phone number: 203-378-4958; Fax number: 203-378-1400; Business\\n\\nhours:24;Creditcardsaccepted:Yes;Numberofemployees:10-19;Map:', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='query whatishraandhsa\\n\\nLLMgeneration HRAstandsforHealthReimbursementArrangement. Itisatypeofbenefitplanwherean\\n\\nemployerreimbursesemployeesforqualifyingmedicalexpenses.Italsoallowsemployers\\n\\ntosetasidemoneytax-freetoreimburseemployeesformedicalexpensesthatarenotcovered\\n\\nundertheemployershealthinsuranceplan. HSAstandsforHealthSavingsAccount. Itis\\n\\nasavingsaccountthatisusedinconjunctionwithaqualifiedHighDeductibleHealthPlan\\n\\n(HDHP).AnHSAenablesanindividualtopayforcurrenthealthexpensesandsaveforfuture\\n\\nhealthexpensesonatax-freebasis.Contributionstotheaccountaretax\\n\\nGroundtruth ThekeydifferencebetweenHRAandHSAisthatHRAisanemployerfundedhealthbenefit\\n\\nplanthatreimbursesformedicalexpensesincludingpersonalhealthinsurancepolicypre-\\n\\nmiumsofemployeeswhereasHSAisalsoatax-advantagedhealthbenefitplanexclusively\\n\\navailabletotaxpayersintheUnitedStateswhoareenrolledinaHigh-DeductibleHealthPlan\\n\\n(HDHP). Table7: MoreexamplesofLLMgenerations. TheformatisthesameasinTable 5. A ImplementationDetails DPR w/distillation\\n\\nlearningrate 2105 3105\\n\\nFor dense retrieval experiments in Table 1, we PLM BERT base SimLM/E5 base-unsup\\n\\nlist the hyperparameters in Table 8. When #ofGPUs 4 4\\n\\nwarmupsteps 1000 1000\\n\\ntraining dense retrievers with distillation from\\n\\nbatchsize 64 64\\n\\ncross-encoder, we use the same teacher score\\n\\nepoch 3 6\\n\\nreleased by Wang et al.. The SimLM and\\n\\nn.a. 0.2\\n\\nE5 checkpoints for initialization are pub-\\n\\nnegativesdepth 1000 200\\n\\nlicly available at https://huggingface. querylength 144 144\\n\\nco/intfloat/simlm-base-msmarco and passagelength 144 144\\n\\nhttps://huggingface.co/intfloat/ #ofnegatives 15 23\\n\\ne5-base-unsupervised. To compute the\\n\\nTable8: Hyper-parametersfortrainingdenseretrievers\\n\\ntext embeddings, we utilize the [CLS] vector for\\n\\nonMS-MARCOpassagerankingdataset. SimLMandmeanpoolingforE5. Thismakessure\\n\\nthat the pooling mechanisms remain consistent\\n\\nbetweenintermediatepre-trainingandfine-tuning. For ablation experiments in Figure 2, we fine-\\n\\nWhenpromptingLLMs,weinclude4in-context tune for 40 epochs or 18k steps, whichever is\\n\\nexamples from the MS-MARCO training set. To reachedfirst. increase prompt diversity, we randomly select 4\\n\\nexamplesforeachAPIcall. Acompletepromptis\\n\\nshowninTable 9. Regardingout-of-domainevaluationsonDBpe-\\n\\ndia (Hasibietal.,2017),NFCorpus (Botevaetal.,\\n\\n2016),Scifact (Waddenetal.,2020),Trec-Covid\\n\\n(Voorhees et al., 2021), and Touche2020 (Bon-\\n\\ndarenko et al., 2022), SimLMs results are based', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'}), Document(page_content='onthereleasedcheckpointby Wangetal..Writeapassagethatanswersthegivenquery:\\n\\nQuery:whatstateisthiszipcode85282\\n\\nPassage:WelcometoTEMPE,AZ85282.85282isaruralzipcodeinTempe,Arizona.Thepopulation\\n\\nisprimarilywhite, andmostlysingle. At$200,200theaveragehomevaluehereisabithigherthan\\n\\naverageforthePhoenix-Mesa-Scottsdalemetroarea,sothisprobablyisnttheplacetolookforhousing\\n\\nbargains.5282ZipcodeislocatedintheMountaintimezoneat33degreeslatitude(FunFact:thisisthe\\n\\nsamelatitudeasDamascus,Syria!)and-112degreeslongitude. Query:whyisgibbsmodelofreflectiongood\\n\\nPassage:Inthisreflection,IamgoingtouseGibbs(1988)ReflectiveCycle.Thismodelisarecognised\\n\\nframeworkformyreflection. Gibbs(1988)consistsofsixstagestocompleteonecyclewhichisable\\n\\ntoimprovemynursingpracticecontinuouslyandlearningfromtheexperienceforbetterpracticeinthe\\n\\nfuture.nconclusionofmyreflectiveassignment,ImentionthemodelthatIchose,Gibbs(1988)Reflective\\n\\nCycleasmyframeworkofmyreflective.IstatethereasonswhyIamchoosingthemodelaswellassome\\n\\ndiscussionontheimportantofdoingreflectioninnursingpractice. prompts\\n\\nQuery:whatdoesathousandpardonsmeans\\n\\nPassage: Oh, thatsallright, thatsallright, giveusarest; nevermindaboutthedirection, hangthe\\n\\ndirection-Ibegpardon,Ibegathousandpardons,Iamnotwellto-day;paynoattentionwhenIsoliloquize,\\n\\nitisanoldhabit,anold,badhabit,andhardtogetridofwhenonesdigestionisalldisorderedwitheating\\n\\nfoodthatwasraisedforeverandeverbeforehewasborn;goodland! amancantkeephisfunctions\\n\\nregularonspringchickensthirteenhundredyearsold. Query:whatisamacrowarning\\n\\nPassage: Macro virus warning appears when no macros exist in the file in Word. When you open\\n\\na Microsoft Word 2002 document or template, you may receive the following macro virus warning,\\n\\neventhoughthedocumentortemplatedoesnotcontainmacros:C:\\\\<path>\\\\<filename>containsmacros. Macrosmaycontainviruses. Query:whenwaspokemongreenreleased\\n\\nPassage:\\n\\nPokemonGreenwasreleasedinJapanonFebruary27th,1996.ItwasthefirstinthePokemonseriesof\\n\\noutput gamesandservedasthebasisforPokemonRedandBlue,whichwerereleasedintheUSin1998.The\\n\\noriginalPokemonGreenremainsabelovedclassicamongfansoftheseries. Table9: ThefullpromptusedfortheexampleinFigure 1.', metadata={'source': '/content/drive/MyDrive/chatgpt/fai.txt'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this line calls the above code function and give the answer to the question which hve been asked about the url(research paper)\n",
        "query('what is lln')\n",
        "query('what is colbert')\n",
        "query('Analysis of Dimensionality')\n"
      ],
      "metadata": {
        "id": "MDIicJyZCmKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8ebac5-6425-431c-c02b-8280646f7c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: what is lln\n",
            "Answer:  LLN stands for Large Language Models. These are large neural networks trained on large datasets to learn the structure of natural language. LLMs are used in a variety of tasks, such as natural language understanding, question answering, and document retrieval.\n",
            "Query: what is colbert\n",
            "Answer:  Colbert is an efficient and effective passage search system via contextualized late interaction over BERT. It is a model proposed by Khattab and Zaharia in 2020.\n",
            "Query: Analysis of Dimensionality\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-fWnP6tkzIvuWjW7nwkIJdGN7 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  The first dimension in the framework established the contrast between sparse and dense vector representations. Sparse learned representations can further be decomposed into expansion and term weighting components. Dense retrieval techniques are typically compared against a bag-of-words exact match ranking model such as BM25, which in this context can be understood as unsupervised sparse retrieval. Expansion terms for sparse representation are needed to identify dimensions in the vector that should have non-zero weights.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
